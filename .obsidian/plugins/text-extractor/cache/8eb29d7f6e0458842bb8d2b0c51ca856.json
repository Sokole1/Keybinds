{"path":".obsidian/plugins/text-extractor/cache/8eb29d7f6e0458842bb8d2b0c51ca856.json","text":"Introduction to Partial Diﬀerential Equations Math 257/316 University of British Columbia Draft and still in progress Year: 2024-2025 Some materials are adapted from lecture notes by Prof. Peirce (available here) and Prof. Rahmani. Contents 1 Review of techniques to solve Ordinary Diﬀerential Equations 2 1.1 Separable equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 1.2 Linear ﬁrst-order equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 1.3 Second-order linear homogeneous equations with constant coeﬃcients . . . . . . . . . 5 1.4 Second-order Euler equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 2 Series solutions of variable coeﬃcient ordinary diﬀerential equations 11 2.1 Power series method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 2.2 Power series solution of general variable coeﬃcient linear ODE . . . . . . . . . . . . . 18 2.2.1 Homogeneous case . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18 2.2.2 Non-homogeneous case . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 2.2.3 Series solutions at singular points . . . . . . . . . . . . . . . . . . . . . . . . . 27 2.3 Bessel functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36 2.3.1 Bessel’s function of order ν /∈ {. . . , −2, −1, 0, 1, 2 . . .} . . . . . . . . . . . . . . 36 2.3.2 Bessel’s function of order ν = 0: repeated roots . . . . . . . . . . . . . . . . . 37 2.3.3 Bessel’s Function of Order ν = 1 2 : . . . . . . . . . . . . . . . . . . . . . . . . . 39 3 Introduction to partial diﬀerential equations 42 3.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42 3.2 Classiﬁcation of PDEs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42 3.3 A one dimensional conservation law . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43 3.4 The heat/diﬀusion equation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46 3.5 The Wave Equation: . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48 3.6 Laplace’s equation: Flow in porous media . . . . . . . . . . . . . . . . . . . . . . . . 49 4 Introduction to numerical methods for partial diﬀerential equations 51 4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51 4.2 Approximating the derivatives of a function by ﬁnite diﬀerences . . . . . . . . . . . . 51 4.3 Solving the heat equation using the method of ﬁnite diﬀerences . . . . . . . . . . . . 53 4.3.1 Dirichlet boundary conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . 53 4.3.2 Neumann boundary conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . 55 4.4 Solving the Wave equation using the method of ﬁnite diﬀerences . . . . . . . . . . . . 55 4.4.1 Dirichlet boundary conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . 55 4.4.2 Neumann Boundary conditions . . . . . . . . . . . . . . . . . . . . . . . . . . 56 4.4.3 Initial conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57 4.5 Solving the Laplace’s equation using the method of ﬁnite diﬀerences . . . . . . . . . . 58 4.5.1 Dirichlet boundary conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . 58 1 Chapter 1 Review of techniques to solve Ordinary Diﬀerential Equations The aim of this ﬁrst lecture is to provide you with a warm-up on some techniques for solving Ordinary Diﬀerential Equations (ODEs). You are likely already familiar with these techniques, as they were introduced in Math 215, 255, and 256. We will brieﬂy review some of them. 1.1 Separable equations Deﬁnition 1.1.1 We say that a ﬁrst-order ODE is separable when it can be written on the form: dy dx = g(x)h(y), (1.1) where g is a function of x only and h is a function of y only. Method 1.1.1 To solve the ODE (1.1), we proceed as follows: • Bring all terms involving x to one side, and all terms involving y and dy to the other side. • Integrate both sides with respect to their respective variables (dont forget an arbitrary constant). • Solve the resulting equation for y(x). When it is clear from the context, we may sometimes write y′ to denote dy dx . Example 1.1.1 Solve the following equation (x ̸= 0): x3y′ = e 3y. 2 We can separate the variables because y′ = dy dx ; this gives e−3y dy = 1 x3 dx. By integrating, we obtain e −3y 3 = 1 2x2 + C. Thus, y = −1 3 ln \f \f \f \f 3 2x2 + ˜C\f \f \f \f , where ˜C ∈ R. Example 1.1.2 Solve the diﬀerential equation: dy dx = 2x(y2 + 1). We rewrite the equation to separate the variables x and y: 1 y2 + 1 dy = 2x dx. Now, if we integrate both sides of the latter equation, we obtain arctan(y) = x2 + C, where C ∈ R. To solve for y, we take the tangent of both sides to obtain y = tan(x2 + C), where C ∈ R is an arbitrary constant. 1.2 Linear ﬁrst-order equations First-order linear diﬀerential equations are the most interesting because we encounter them in physics (electricity, mechanics, etc.). These are equations where y and y′ are of the ﬁrst degree. Deﬁnition 1.2.1: First-order linear diﬀerential equations The general form is: a(x)y′ + b(x)y = c(x), (1.2) where a, b, and c are functions of x. When a(x) ̸= 0, then equation (1.2) is said to be normalized. In this case, (1.2) reduces to the equation: 3 y′ + p(x)y = q(x), (1.3) where p(x) = b(x) a(x) and q(x) = c(x) a(x). If c(x) = 0 (equivalently q(x) = 0), then the equation obtained will be homogeneous, called a homogeneous linear equation. Method 1.2.1 To solve (1.3) using the integrator factor method, we proceed as follows: • We compute the integrating factor: µ(x) = e ∫ p(x) dx (Don’t worry about arbitrary constants here). • Multiply the equation (1.3) by the integrating factor. • Observe that, by the product rule, the left-hand side of the resulting equation can be rewritten as d dx [µ(x)y(x)], thus giving you the equation: d dx [µ(x)y(x)] = µ(x)q(x). • Integrate both sides of your last equation with respect to x, and solve for y(x). Don’t forget the arbitrary constant. Note that to obtain the expression for the integrating factor µ(x), we use the requirement that: d dx [µ(x)y(x)] = µ dy dx + dµ dx y = µ dy dx + µp(x)y. This means that µ must satisfy the simple diﬀerential equation: dµ dx = µp(x). Example 1.2.1 Solve the following equation: x dy dx + 2y = 10x2. For x ̸= 0, we rewrite the equation in standard linear form: dy dx + 2 xy = 10x. (1.4) This is now in the form: dy dx + p(x)y = q(x), 4 where p(x) = 2 x and q(x) = 10x. The integrating factor µ(x) is given by: µ(x) = e ∫ p(x) dx = e∫ 2 x dx = x2. Now, we multiply the diﬀerential equation (1.4) by µ(x) = x2 to obtain: x2 dy dx + 2xy = 10x3. The left-hand side can be written as the derivative of a product: d dx ( x2y) = 10x3. Now, if we integrate both sides with respect to x: ∫ d dx (x2y) dx = ∫ 10x3 dx, we obtain x2y = 5x4 2 + C, where C ∈ R. That is y = 5x2 2 + C x2 , x ̸= 0 where C ∈ R is an arbitrary constant. 1.3 Second-order linear homogeneous equations with con- stant coeﬃcients Deﬁnition 1.3.1: Homogeneous second-order ODE We call second-order linear homogeneous diﬀerential equation a ODE of the form: Ly := ay′′ + by′ + cy = 0, where a, b, and c are real constants. To solve this type of equation, we assume a solution of the form: y(x, r) = erx, where r is a constant to be determined. Substituting this expression for y(x) into the diﬀerential equation gives the corresponding characteristic equation: ar2 + br + c = 0. Solving this quadratic equation yields two possible values for r: r1 = −b + √b2 − 4ac 2a , r2 = −b − √ b2 − 4ac 2a . 5 Depending on the discriminant ∆ = b2 − 4ac, we consider the following cases: (a) Distinct real roots: If r1 and r2 are two distinct real values, then the general solution to the diﬀerential equation is: y(x) = c1e r1x + c2er2x, where c1 and c2 are arbitrary constants. (b) Repeated real roots: If r1 = r2, then the roots are real and equal, and the general solution is: y(x) = c1e r1x + c2xer1x. Wait a moment! In this case, we initially obtain only one solution, y(x) = e r1x. But how do we derive the second term, c2xe r1x? To understand this, consider the function: y(r, x) = e rx. When the linear diﬀerential operator L is applied to y(r, x), we have: Ly(r, x) = a(r − r1) 2e rx. Now, take the partial derivative of y(r, x) with respect to r, and evaluate it at r = r1: L [∂y ∂r (r, x) ] r=r1 = [ 2a(r − r1)e rx + a(r − r1) 2xe rx] r=r1 . At r = r1, this expression simpliﬁes to: L [∂y ∂r (r, x) ] r=r1 = 0. This demonstrates that the derivative: [ ∂y ∂r (r, x)] r=r1 = xer1x is also a valid solution to the diﬀerential equation. (c) Complex roots: If r1 and r2 are complex conjugates, i.e., r1 = α + iβ and r2 = α − iβ, where α and β are real constants, the general solution to the diﬀerential equation can be written as: y(x) = c1e(α+iβ)x + c2e(α−iβ)x. Using Euler’s formula e(α±iβ)x = e αx[cos(βx) ± i sin(βx)], the solution can also be expressed as: y(x) = C1eαx cos(βx) + C2e αx sin(βx), where C1 and C2 are arbitrary constants. This form is typically preferred in practice since it involves real-valued functions. 6 Example 1.3.1 Solve the following diﬀerential equations: 1. y′′ − 9y = 0 a) If we let y = erx, we obtain the characteristic equation: r2 − 9 = 0 b) Solving for r: r2 = 9 ⇒ r = ±3 c) The general solution is: y(x) = c1e3x + c2e−3x, where c1 and c2 are arbitrary constants. 2. y′′ + 9y = 0 a) If we let y = erx, we obtain the characteristic equation: r2 + 9 = 0 b) Solving for r: r2 = −9 ⇒ r = ±3i c) The general solution is: y(x) = c1 cos(3x) + c2 sin(3x), where c1 and c2 are arbitrary constants. 3. y′′ + 6y′ + 9y = 0 a) If we let y = erx, we obtain the characteristic equation: r2 + 6r + 9 = 0 b) Factorizing: (r + 3)2 = 0 ⇒ r = −3 c) The general solution is: y(x) = c1e −3x + c2xe−3x, where c1 and c2 are arbitrary constants. 4. y′′ + 6y′ − 9y = 0 a) If we let y = erx, we obtain the characteristic equation: r2 + 6r − 9 = 0 b) Solving using the quadratic formula: r = −6 ± √62 − 4(1)(−9) 2(1) = −3 ± 3 √ 2 c) The general solution is: y(x) = c1e(−3+3 √2)x + c2e(−3−3 √2)x, where c1 and c2 are arbitrary constants. 7 1.4 Second-order Euler equations Deﬁnition 1.4.1 A second-order Euler equation is a type of diﬀerential equation written as: x2y′′ + αxy′ + βy = 0, where α, and β are constants. To solve this equation, we guess a solution of the form: y(x) = xr, where r is a number we need to ﬁnd. Then, we substitute this guess into the equation and solve for r. We obtain: {r(r − 1) + αr + β}xr = 0. This simpliﬁes to the characteristic equation: f (r) = r2 + (α − 1)r + β = 0. The solutions for r are: r± = 1 − α ± √(α − 1)2 − 4β 2 . Case 1: Distinct real roots (∆ > 0) If ∆ = (α − 1) 2 − 4β > 0, the roots r1 and r2 are distinct real numbers. The general solution is: y(x) = c1xr1 + c2xr2. If either r1 or r2 is negative, the solution |y| → ∞ as x → 0. Case 2: Repeated roots (∆ = 0) If ∆ = 0, there is only one root r1. In this case, the solution is: y(x) = c1xr1. To ﬁnd a second independent solution, we proceed as above. We write L[xr] = (r − r1)2er ln x. If we diﬀerentiate with respect to the parameter r, and evaluate it at r = r1, we obtain: [ L [ ∂ ∂r xr]] r=r1 = [ ∂ ∂r L[xr]] r=r1 = 0. So, [ ∂ ∂r (xr)] r=r1 = xr1 ln x is also a solution. This leads to the general solution: y(x) = (c1 + c2 ln x)xr1, where c1 and c2 are arbitrary constants. Finally, using the Wronskian test, we can prove that the two solutions are linearly independent. 8 Case 3: Complex roots (∆ < 0) If ∆ = (α − 1) 2 − 4β < 0, the roots are complex: r± = 1 − α 2 ± i √ 4β − (α − 1)2 2 . Let λ = 1−α 2 and µ = √4β−(α−1)2 2 . The solution becomes: y(x) = xλ (A1 cos(µ ln x) + A2 sin(µ ln x)) . If x < 0, replace x with |x|. Example 1.4.1 Solve the following diﬀerential equations: 1. x2y′′ + xy′ − 9y = 0. We assume the solution in the form y = xr, and plug it into the diﬀerential equation: x2 d2 dx2 (xr) + x d dx (xr) − 9 (xr) = 0. Now, applying the derivatives, we get: x2 [ r(r − 1)xr−2] + x [ rxr−1] − 9xr = 0. Simplifying further: r2xr − rxr + rxr − 9xr = 0. This simpliﬁes to: r2 − 9 = 0. Solving for r, we get: r = ±3. Thus, the general solution to the diﬀerential equation is: y(x) = c1x3 + c2x−3, where c1 and c2 are arbitrary constants. 2. x2y′′ − 3xy′ + 4y = 0, y(1) = 1, y′(1) = 0. Assume a solution of the form y = xr. Substituting into the diﬀerential equation: r(r − 1)xr−2 − 3rxr−1 + 4xr = 0. 9 Multiplying through by x2, we get: r(r − 1) − 3r + 4 = 0, which simpliﬁes to: r2 − 4r + 4 = 0. Factoring, we get: (r − 2)2 = 0. Thus, r = 2 is a double root. The general solution to the diﬀerential equation is: y(x) = c1x2 + c2x2 ln x. Now, using the initial conditions y(1) = 1 and y′(1) = 0: From y(1) = 1, we get: c1 · 1 2 + c2 · 1 2 ln(1) = 1 ⇒ c1 = 1. To ﬁnd c2, we compute y′(x): y′(x) = d dx (c1x2 + c2x2 ln x) = 2c1x + c2 (2x ln x + x) . Evaluating at x = 1: y′(1) = 2c1 + c2 (2 · 1 · ln(1) + 1) = 2c1 + c2 = 0. Substituting c1 = 1, we get: 2 + c2 = 0 ⇒ c2 = −2. Thus, the solution is: y(x) = x2 − 2x2 ln x. If x < 0, we replace x by |x|. 10 Chapter 2 Series solutions of variable coeﬃcient ordinary diﬀerential equations In this part, we introduce a method to solve linear diﬀerential equations with variable coeﬃcients, which frequently arise in physical problems. They do not usually admit solutions expressible in terms of elementary functions. Such equations can often be solved using numerical methods, but in many cases, it is easier to ﬁnd solutions in the form of an inﬁnite series. We introduce the concepts of ordinary points about which Taylor series solutions are obtained and singular points about which more general solutions are required. 2.1 Power series method The power series method is the standard method for solving linear ODEs with variable coeﬃcients. It gives solutions in the form of power series. These series can be used for computing values, graphing curves, proving formulas, and exploring properties of solutions, as we shall see. In this section we begin by explaining the idea of the power series method. Deﬁnition 2.1.1: Power series A power series (in powers of x − x0 ) is an inﬁnite series of the form ∞∑ n=0 an (x − x0) n = a0 + a1 (x − x0) + a2 (x − x0) 2 + · · · (2.1) Here, x is a variable. a0, a1, a2, · · · are constants, called the coeﬃcients of the series. x0 is a constant, called the center of the series. In particular, if x0 = 0, we obtain a power series in powers of x ∞∑ n=0 anxn = a0 + a1x + a2x2 + a3x3 + · · · (2.2) We shall assume that all variables and constants are real. 11 Example 2.1.1 Familiar examples of power series are the Taylor-Maclaurin series 1 1 − x = ∞∑ m=0 xm = 1 + x + x2 + · · · (|x| < 1, geometric series ) e x = ∞∑ m=0 xm m! = 1 + x + x2 2! + x3 3! + · · · cos x = ∞∑ m=0 (−1) mx2m (2m)! = 1 − x2 2! + x4 4! − + · · · sin x = ∞∑ m=0 (−1)mx2m+1 (2m + 1)! = x − x3 3! + x5 5! − + · · · . More generally, if we know all the derivatives of a function f (x) at a single point x0, then we have the Taylor approximation: f (x) = ∞∑ k=0 f (k) (x0) k! (x − x0) k , for x near x0. We note that the term ”power series” usually refers to a series of the form (2.1) [or (2.2)] but does not include series of negative or fractional powers of x. We use m as the summation letter. Before moving further, we review relevant properties of power series. Deﬁnition 2.1.2: Convergence of a power series The power series (2.1) is said to converge for a given x if the limit lim N →∞ N∑ n=0 an(x − x0)n exists. Otherwise, the series diverges for the given x. For any power series (2.1), exactly one of the following statements is true: (a) The power series converges only for x = x0. (b) The power series converges for all values of x. (c) There is a positive number R such that the power series converges if |x − x0| < R and diverges if |x − x0| > R. In case (c), R is called the radius of convergence of the power series. For convenience, we include the other two cases in this deﬁnition by setting R = 0 in case (a) and R = ∞ in case (b). The open interval of convergence is deﬁned as: (x0 − R, x0 + R) if 0 < R < ∞, or (−∞, ∞) if R = ∞. If R is ﬁnite, no general statement can be made about convergence at the endpoints x = x0 ± R. The series may converge at one or both endpoints, or diverge at both. 12 Theorem 2.1.1: Ratio test Consider the series ∑∞ n=0 cn and suppose: lim n→∞ \f \f \f \f cn+1 cn \f \f \f \f = L. (a) If L < 1, then ∑∞ n=0 cn converges. (b) If L > 1 or the limit approaches ∞, then ∑∞ n=0 cn diverges. (c) If L = 1, the ratio test is inconclusive, and another test must be used. Example 2.1.2 1. Find the radius of convergence for the following series: ∞∑ n=0 n!xn. Here, cn = n!xn. Using the ratio test, lim n→∞ \f \f \f \f cn+1 cn \f \f \f \f = lim n→∞ \f \f \f \f(n + 1)!xn+1 n!xn \f \f \f \f = lim n→∞ (n + 1)|x| = ∞ for all x ̸= 0. Thus, the series converges only at x = 0, so R = 0. 2. Find the radius of convergence for the following series: ∞∑ n=1 (−1)nxn n! . Here, cn = (−1)nxn n! . Using the ratio test, lim n→∞ \f \f \f \fcn+1 cn \f \f \f \f = lim n→∞ \f \f \f \f xn+1/(n + 1)! xn/n! \f \f \f \f = |x| lim n→∞ 1 n + 1 = 0 for all x. Hence, R = ∞. 3. Find the radius of convergence for the following series: ∞∑ n=0 2 n n2 (x − 1) n. Here, cn = 2n n2 (x − 1) n. Using the ratio test, lim n→∞ \f \f \f \f cn+1 cn \f \f \f \f = lim n→∞ \f \f \f \f2 n+1(x − 1) n+1/(n + 1)2 2n(x − 1)n/n2 \f \f \f \f = 2|x − 1| lim n→∞ n2 (n + 1)2 = 2|x − 1|. The series converges when 2|x − 1| < 1, or |x − 1| < 1 2. Thus, R = 1 2. 13 4. Find the radius of convergence for the following series: ∞∑ m=0 (−1) m 8m x3m. Here, cn = (−1)m 8m x3m. Using the ratio test, lim n→∞ \f \f \f \f cn+1 cn \f \f \f \f = |x| 3 8 . The series converges when |x|3 8 < 1, or |x| < 2. Thus, R = 2. Idea of the power series method The idea of the power series method for solving ODEs is simple and natural. We describe the practical procedure and illustrate it for two ODEs whose solution we know, so that we can see what is going on. Important! For a given ODE P (x)y′′ + Q(x)y′ + R(x)y = 0, (2.3) we ﬁrst represent P (x), Q(x) and R(x) by power series in powers of x (or of x − x0 if solutions in powers of x − x0 are wanted). Next we assume a solution in the form of a power series with unknown coeﬃcients, y = ∞∑ m=0 amxm = a0 + a1x + a2x2 + a3x3 + · · · (2.4) and insert this series and the series obtained by termwise diﬀerentiation, y′ = ∞∑ m=1 mamxm−1 = a1 + 2a2x + 3a3x2 + · · · (2.5) y′′ = ∞∑ m=2 m(m − 1)amxm−2 = 2a2 + 3 · 2a3x + 4 · 3a4x2 + · · · (2.6) into the ODE. Then we collect like powers of x and equate the sum of the coeﬃcients of each occurring power of x to zero, starting with the constant terms, then taking the terms containing x, then the terms in x2, and so on. This gives equations from which we can determine the unknown coeﬃcients of (2.4) successively. Remark 2.1.1 Note that if the power series (2.4) has a positive radius of convergence R, then the radius of convergence of all its successive derivative series is also R. 14 Let us show this for three simple ODEs that can also be solved by elementary methods, so that we would not need power series. Example 2.1.3 1. Solve the following ODE by power series: y′ + 2y = 0. By substituting (2.4) and (2.5) into the ODE, we get: ∞∑ m=1 mamxm−1 + 2 ∞∑ m=0 amxm = 0. To obtain the same general power on both series, we let s = m − 1 (i.e. m = s + 1) in the ﬁrst series and s = m in the second. This gives . This gives: ∞∑ s=0 (s + 1)as+1xs + 2 ∞∑ s=0 asxs = 0. Combining terms, we have: ∞∑ s=0 [(s + 1)as+1 + 2as] xs = 0. For this equation to hold, we must have: (s + 1)as+1 + 2as = 0. Thus, we derive the recurrence relation: as+1 = − 2as s + 1 , s = 0, 1, 2, . . . Starting with a0 as arbitrary, we calculate the successive coeﬃcients: a1 = −2a0 1 , a2 = −2a1 2 = 2 2a0 2! , a3 = −2a2 3 = −2 3a0 3! . In general, the coeﬃcients are given by: as = (−1) s 2 sa0 s! . Substituting back into the power series, the solution becomes: y(x) = ∞∑ s=0 (−1) s 2 sa0 s! xs = a0 ∞∑ s=0 (−2x) s s! . 15 Recognizing the series for the exponential function, we have: y(x) = a0e −2x, where a0 is an arbitrary constant. 2. Solve the following ODE by power series: y′′ + y = 0. By inserting (2.4) and (2.6) into the ODE we have ∞∑ m=2 m(m − 1)amxm−2 + ∞∑ m=0 amxm = 0 To obtain the same general power on both series, we let s = m − 2 in the ﬁrst series and s = m in the second. This gives ∞∑ s=0 (s + 2)(s + 1)as+2xs + ∞∑ s=0 asxs = 0. Therefore, ∞∑ s=0 [(s + 2)(s + 1)as+2 + as] xs = 0. Hence (s + 2)(s + 1)as+2 + as = 0. This gives the recursion formula as+2 = − as (s + 2)(s + 1) (s = 0, 1, · · · ) We thus obtain successively a2 = − a0 2·1 = − a0 2! , a3 = − a1 3·2 = − a1 3! a4 = − a2 4·3 = a0 4! , a5 = − a3 5·4 = a1 5! and so on. a0 and a1 remain arbitrary. With these coeﬃcients the series becomes y = a0 + a1x − a0 2! x2 − a1 3! x3 + a0 4! x4 + a1 5! x5 + · · · . Reordering terms (which is permissible for a power series), we can write this in the form y = a0 (1 − x2 2! + x4 4! − + · · · ) + a1 ( x − x3 3! + x5 5! − + · · · ) 16 and we recognize the familiar general solution y = a0 cos x + a1 sin x, a0, a1 ∈ R. 2. Solve the following ODE by power series: y′ = 2xy We insert (2.4) and (2.5) into the given ODE, obtaining 1 · a1x0 + ∞∑ m=2 mamxm−1 = 2x ∞∑ m=0 amxm = ∞∑ m=0 2amxm+1 Now, to get the same general power on both sides, we make a ”shift of index” on the left by setting m = s + 2, thus m − 1 = s + 1. Then am becomes as+2 and xm−1 becomes xs+1. Also the summation, which started with m = 2, now starts with s = 0 because s = m − 2. On the right we simply make a change of notation m = s, hence am = as and xm+1 = xs+1; also the summation now starts with s = 0. This altogether gives a1 + ∞∑ s=0 (s + 2)as+2xs+1 = ∞∑ s=0 2asxs+1. Every occurring power of x must have the same coeﬃcient on both sides; hence a1 = 0 and (s + 2)as+2 = 2as or as+2 = 2 s + 2 as For s = 0, 1, 2, · · · we thus have a1 = 0, a2 = (2/2)a0, a3 = (2/3)a1 = 0, a4 = (2/4)a2, · · · . Hence a3 = 0, a5 = 0, · · · and for the coeﬃcients with even subscripts, a2 = a0, a4 = a2 2 = a0 2! , a6 = a4 3 = a0 3! , · · · ; a0 remains arbitrary. Hence, y = a0 ( 1 + x2 + x4 2! + x6 3! + x8 4! + · · · ) = a0ex2, a0 ∈ R. Remark 2.1.2 Note that we do not need power series method for these or similar ODEs? We used them just for explaining the idea of the method. What happens if we apply the method to an ODE not of the kind considered so far, even to an innocent-looking one such as y′′ + xy = 0 (”Airy’s equation”)? We most likely end up with new special functions given by power series. 17 2.2 Power series solution of general variable coeﬃcient lin- ear ODE In the last section we saw that the power series method gives solutions of ODEs in the form of power series. 2.2.1 Homogeneous case We consider solving the following variable linear ODE of the form P (x)y′′ + Q(x)y′ + R(x)y = 0. (2.7) If we divide the latter equation by P (x), we obtain Ly := y′′ + p(x)y′ + q(x)y = 0, (2.8) where p(x) = Q(x)/P (x) and q(x) = R(x)/P (x). In order to calculate the higher derivatives of y(x) to substitute into Taylors formula, we rewrite (2.8) as follows: y′′ = −p(x)y′ − q(x)y If y(x0) and y′(x0) are given, then y′′(x0) can be obtained directly from the ODE. Higher derivatives of y can, in turn, be obtained by diﬀerentiating the ODE repeatedly. This process will be successful provided p(x) and q(x) are inﬁnitely diﬀerentiable at x = x0. In this case, p(x) and q(x) are said to be analytic at x0 and have Taylor expansions of the form: p(x) = p0 + p1(x − x0) + · · · = ∞∑ k=0 pk(x − x0) k q(x) = q0 + q1(x − x0) + · · · = ∞∑ k=0 qk(x − x0)k Note that in the power series method we can diﬀerentiate, add, and multiply power series, in a ”suitable sense”. For example: consider two power series ∞∑ m=0 am (x − x0) m and ∞∑ m=0 bm (x − x0)m . Then the series obtained by multiplying each term of the ﬁrst series by each term of the second series and collecting like powers of x − x0 is ∞∑ m=0 (a0bm + a1bm−1 + · · · + amb0) (x − x0)m = a0b0 + (a0b1 + a1b0) (x − x0) + (a0b2 + a1b1 + a2b0) (x − x0) 2 + · · · . Ordinary points and singular points 18 Deﬁnition 2.2.1: Ordinary points and singular points The expansion point x0 is said to be an ordinary point of (2.8) if p(x) = Q(x)/P (x) and q(x) = R(x)/P (x) are analytic at x0. Otherwise, x0 is a singular point. Theorem 2.2.1 If x0 is an ordinary point, it is possible to obtain power series expansions of the solution y(x) of the form: y(x) = ∞∑ n=0 cn(x − x0) n (2.9) and to substitute the latter expansion (2.8) and solve for the unknown coeﬃcients cn in order to determine a solution. In addition, (2.9) converges at least on the open interval (x0 − R, x0 + R), where R is the the distance from x0 to the nearest singular point of (2.8). More precisely, the radius of convergence of (2.9) is at least as large as the radius of convergence of each of the series expansions for p(x) = Q(x)/P (x) and q(x) = R(x)/P (x), i.e., up to the closest singularity to x0. Example 2.2.1: Singular point An example of singular point: when P , Q, and R are polynomials and P (x0) = 0 while Q(x0) ̸= 0 or R(x0) ̸= 0, then x0 is a singular point. Another example is when: p(x) = √x, q(x) = 2, then x0 = 0 is a singular point because p(x) is not diﬀerentiable at x = 0. Observations • If P , Q, and R are polynomials, then a point x0 such that P (x0) ̸= 0 is an ordinary point. • If x0 = 0 is an ordinary point, then we assume: y = ∞∑ n=0 cnxn, y′ = ∞∑ n=1 cnnxn−1, y′′ = ∞∑ n=2 cnn(n − 1)xn−2. The substitution into the ODE 0 = Ly gives: 0 = ∞∑ n=2 cnn(n − 1)xn−2 + ( ∞∑ n=0 pnxn) ( ∞∑ n=1 ncnxn−1) + ( ∞∑ n=0 qnxn) ( ∞∑ n=0 cnxn) . Re-indexing the powers of x, this results in: ∞∑ m=0 {(m + 2)(m + 1)cm+2 + (p0(m + 1)cm+1 + · · · + pmc1) + (q0cm + · · · + qmc0)} xm = 0. This yields a non-degenerate recursion formula for the cm. At an ordinary point x0, we can obtain two linearly independent solutions of the form (2.9). 19 Example 2.2.2 Find the power series in x for the general solution of (1 + 2x2)y′′ + 6xy′ + 2y = 0 (2.10) The functions p(x) = 6x 1+2x2 and q(x) = 2 1+2x2 are analytic at x = 0. Hence, x0 = 0 is an ordinary point of (2.10). Next, we rewrite the given equation as: (1 + 2x2)y′′ + 6xy′ + 2y = y′′ + 2x2y′′ + 6xy′ + 2y = 0. Since x0 = 0 is an ordinary point of (2.10), we assume the general solution in the form of a power series: y = ∞∑ n=0 anxn, which will generate two linearly independent solutions. Now, diﬀerentiating y: y′ = ∞∑ n=1 nanxn−1, y′′ = ∞∑ n=2 n(n − 1)anxn−2. Substituting these into the diﬀerential equation: ∞∑ n=2 n(n − 1)anxn−2 + 2x2 ∞∑ n=2 n(n − 1)anxn−2 + 6x ∞∑ n=1 nanxn−1 + 2 ∞∑ n=0 anxn = 0, we can express the equation as: ∞∑ n=2 n(n − 1)anxn−2 + ∞∑ n=2 2n(n − 1)anxn + ∞∑ n=1 6nanxn + ∞∑ n=0 2anxn = 0. Let m = n − 2 in the ﬁrst sum then, n = m + 2 and when n = 2, m = 0. We thus obtain after taking n = m in the other sums: ∞∑ m=0 (m + 2)(m + 1)am+2xm + ∞∑ m=2 2m(m − 1)amxm + ∞∑ m=1 6mamxm + ∞∑ m=0 2amxm = 0. Reindexing: 2a2 + 6a3x + ∞∑ m=2 (m + 2)(m + 1)am+2xm + ∞∑ m=2 2m(m − 1)amxm + 6a1x + ∞∑ m=2 6mamxm +2a0 + 2a1x + ∞∑ m=2 2amxm = 0. Next, we collect like terms: (2a2 + 2a0) + (6a3 + 8a1)x + ∞∑ m=2 [ (m + 2)(m + 1)am+2 + (2m 2 + 4m + 2)am] xm = 0. 20 Equating the coeﬃcients of powers of x, we get the recurrence relations for am: a2 = −a0, a3 = −4 3 a1, am+2 = − 2(m + 1)2 (m + 1)(m + 2) am = −2(m + 1) (m + 2) am, m = 2, 3, 4, . . . . (2.11) Substituting m = 2, 3, 4, . . . into the recurrence relations: a4 = −3 2a2 = 3 2 a0, a5 = −8 5a3 = 32 15a1, a6 = −5 3a4 = −5 2a0, a7 = −12 7 a5 = −128 35 a1, . . . Thus, the general solution is: y = a0 ( 1 − x2 + 3 2x4 − 5 2x6 + · · · ) + a1 ( x − 4 3x3 + 32 15x5 − 128 35 x7 + · · · ) . (2.12) This is the power series in x for the general solution of equation (2.10). Now, let us compute the radius of convergence of this solution. We use the ratio test and the recurrence relation (2.11): lim m→∞ \f \f \f \f am+2xm+2 amxm \f \f \f \f = |x| 2 lim m→∞ \f \f \f \f−2(m + 1) (m + 2) \f \f \f \f = 2|x| 2. Therefore, the series converges if 2|x| 2 < 1 i.e., |x| < √2 2 . Hence, R = √2 2 . Another way to determine the radius of convergence is to ﬁnd the nearest singular point of (2.10) (which could be a complex number) and compute the distance from x0 = 0 to this nearest singular point. Since P is a polynomial, P (x) = 1 + 2x2, the singular points are the roots of P (x) = 0, i.e., 1 + 2x2 = 0 =⇒ x2 = −1 2 =⇒ x = ±i 1 √2. The singular points are therefore x = ±i √2 2 . To compute the distance from x0 = 0 to the nearest singular point, we calculate the modulus of x = i √2 2 (or of x = −i √ 2 2 ): |x| = \f \f \f \f \fi √2 2 \f \f \f \f \f = √2 2 . Hence according to Theorem 2.2.1, the series (2.12) converges at least on the open interval (− √2 2 , √2 2 ). Example 2.2.3: The Airy equation: Consider the Airy equation, which arises in Quantum Mechanics: Ly = y′′ − xy = 0 We observe that x = 0 is an ordinary point. 21 y = ∞∑ n=0 cnxn, y′ = ∞∑ n=1 cnnxn−1, y′′ = ∞∑ n=2 cnn(n − 1)xn−2. ∞∑ n=2 cnn(n − 1)xn−2 − ∞∑ n=0 cnxn+1 = 0. In the ﬁrst sum, let m + 1 = n − 2 n = m + 3 n = 2 ⇒ m = −1 c22x0 + ∞∑ m=0 [cm+3(m + 3)(m + 2) − cm] xm+1 = 0 c2 = 0, cm+3 = cm (m + 3)(m + 2) m = 0, 1, . . . (1) c0 → c3 → c6. c3 = c0 3.2 , c6 = c3 6.5 = c0 6.5.3.2, c9 = c0 9.8.6.5.3.2 c3n = c0 (3n)(3n − 1)(3n − 3)(3n − 4) . . . 9.8.6.5.3.2 y0(x) = 1 + x3 3.2 + x6 6.5.3.2 + · · · + x3n (3n)(3n − 1) . . . 3.2 + . . . (2) c1 → c4 → c7 →. c4 = c1 4.3 c7 = c1 7.6.4.3 c10 = c1 (10.9)(7.6)(4.3) c3n+1 = c1 (3n + 1)(3n)(3n − 2)(3n − 3) . . . (7.6)(4.3) y1(x) = x + x4 4.3 + x7 7.6.4.3 + · · · + x3n+1 (3n + 1)(3n) . . . 4.3 y(x) = c0y0(x) + c1y1(x) Radius of Convergence: lim m→∞ \f \f \f \f cm+3 cm x3\f \f \f \f = lim m→∞ |x| 3 (m + 3)(m + 2) = 0 < 1. R = ∞. Solutions near other points When looking for solutions near an ordinary point x0 ̸= 0, the calculations are generally simpler if we translate x0 to the origin by the change of variable t = x − x0. The solution to the resulting diﬀerential equation can be obtained by the method of power series near t = 0. The solution to the original equation is then obtained simply by performing the inverse translation. Example 2.2.4 To ﬁnd the solution of the diﬀerential equation in powers of (x − 1) of the ODE: y′′ − xy = 0 (2.13) 22 The point x0 = 1 is an ordinary point of the equation. The solution of the equation is written in the form: y = ∞∑ n=0 bn(x − 1) n (2.14) Let t = x − 1 and dt = dx. (2.15) Then the equation (2.13) becomes (we add t on the superscript of the second derivative to indicate that we derive with respect to the new variable t) y′′ t − (t + 1)y = 0, (2.16) and (2.16) becomes y = ∞∑ n=0 bnt n (2.17) Now y′ = ∞∑ n=1 nbnt n−1 and y′′ = ∞∑ n=2 n(n − 1)bnt n−2. Substituting into the equation: We obtain ∞∑ n=2 n(n − 1)bnt n−2 − (t + 1) ∞∑ n=0 bnt n = 0 ∞∑ n=0(n + 1)(n + 2)bn+2t n − ∞∑ n=0 bnt n − ∞∑ n=1 bn−1t n = 0. Then: (2 · 1b2 − b0) + ∞∑ n=1 [(n + 2)(n + 1)bn+2 − bn−1 − bn] t n = 0. Thus, { b2 = b0 2·1 bn+2 = 1 (n+2)(n+1) (bn−1 + bn) n ≥ 1. For n = 1 b3 = 1 3 · 2 (b0 + b1) = 1 3 · 2 b0 + 1 3 · 2b1 For n = 2 b4 = 1 4 · 3 (b1 + b2) = 1 4 · 3 · 2b0 + 1 4 · 3b1 For n = 3 b5 = 1 5 · 4 (b2 + b3) = 4 5 · 4 · 3 · 2 · 1b0 + 1 5 · 4 · 3 · 2b1 23 Thus, y = ∞∑ n=0 bnt n = b0 + b1t + b2t 2 + b3t 3 + b4t4 + b5t 5 + . . . y = b0 + b1t + b2t 2 + ( 1 3 · 2 b0 + 1 3 · 2 b1 ) t 3 + . . . y = b0 ( 1 + 1 2t 2 + 1 3 · 2 t 3 + . . .) + b1 (t + 1 3 · 2t 3 + . . .) Since t = x − 1, we get: y = b0 ( 1 + 1 2(x − 1)2 + 1 3 · 2(x − 1)3 + . . .) + b1 ((x − 1) + 1 3 · 2(x − 1) 3 + . . .) . 2.2.2 Non-homogeneous case Deﬁnition 2.2.2: Ordinary point and singular point Let y′′ + p(x)y′ + q(x)y = f (x). (2.18) We say that x0 is an ordinary point of equation (2.18) if p(x), q(x), and f (x) are all analytic at x0. Otherwise, x0 is a singular point. Theorem 2.2.2 Let x0 be an ordinary point of (2.18). Let R be the distance from x0 to the nearest singular point of (2.18). Then every solution of (2.18) can be represented by a power series: y = ∞∑ n=0 an(x − x0) n (2.19) that converges at least on the open interval (x0 − R, x0 + R). Furthermore, (2.19) will generate the two linearly independent solutions of the homogeneous part of (2.18) and a particular solution to the nonhomogeneous part of (2.18). Example 2.2.5 Find the power series in x for the general solution of y′′ + xy′ + y = 1 1 − x. (2.20) The functions p(x) = x, q(x) = 1 and f (x) = 1 1−x are analytic at x = 0. The series for 1 1−x is given by: 1 1 − x = ∞∑ n=0 xn, 24 which converges on (−1, 1). Since x = 0 is an ordinary point, Theorem 2.2.2 says we will generate both the homogeneous and the non-homogeneous solutions of (2.20) from: y = ∞∑ n=0 anxn, y′ = ∞∑ n=1 nanxn−1, y′′ = ∞∑ n=2 n(n − 1)anxn−2. Substituting these into (2.20), we get: ∞∑ n=2 n(n − 1)anxn−2 + x ∞∑ n=1 nanxn−1 + ∞∑ n=0 anxn = ∞∑ n=0 xn. Reindexing the sums, we obtain: 2a2 + ∞∑ n=1(n + 2)(n + 1)an+2xn + ∞∑ n=1 nanxn + a0 + ∞∑ n=1 anxn = 1 + ∞∑ n=1 xn. Collecting like terms: (2a2 + a0) + ∞∑ n=1 [(n + 2)(n + 1)an+2 + (n + 1)an] xn = 1 + ∞∑ n=1 xn. Equating coeﬃcients, we ﬁnd: a2 = 1 2(1 − a0), an+2 = − an n + 2 + 1 (n + 2)(n + 1) , n = 1, 2, 3, . . . Substituting n = 1, 2, 3, . . ., we ﬁnd: a3 = −1 3 a1 + 1 6 , a4 = −1 4 a2 + 1 12 = 1 8 a0 − 1 24, a5 = −1 5 a3 + 1 20 = 1 15a1 + 1 60, . . . Thus, the general solution is: y = a0 ( 1 − 1 2x2 + 1 8 x4 + · · · )+a1 ( x − 1 3x3 + 1 15x5 + · · · )+ ( 1 2 x2 + 1 6x3 − 1 24x4 + 1 60x5 + · · · ) . This is the power series in x for the general solution of Equation (2.20), deﬁned on (−1, 1). Example 2.2.6 Find a solution in series for the equation: y′′ − xy′ = e−x (2.21) We have: p(x) = −x and q(x) = 0 and f (x) = e −x, which are analytic at x0 = 0. Therefore, x0 = 0 is an ordinary point. Let 25 y = ∞∑ n=0 anxn y′ = ∞∑ n=1 nanxn−1 y′′ = ∞∑ n=2 n(n − 1)anxn−2 and since e −x = ∞∑ n=0 (−1)nxn n! . By substituting the series into equation (2.21), we obtain: ∞∑ n=2 n(n − 1)anxn−2 − ∞∑ n=1 nanxn = ∞∑ n=0 (−1) nxn n! . Thus, ∞∑ n=0(n + 2)(n + 1)an+2xn − ∞∑ n=1 nanxn = ∞∑ n=0 (−1)nxn n! . Now, 2 · 1a2x0 + ∞∑ n=1(n + 2)(n + 1)an+2xn − ∞∑ n=1 nanxn = 1 + ∞∑ n=1 (−1) nxn n! . We conclude that { a2 = 1 2 an+2 = (−1)n (n+2)! + n (n+2)(n+1)an, ∀n ≥ 1 For n = 1, a3 = − 1 3! + 1 3 · 2a1, a4 = 1 4! + 2 4 · 3 · 2 = 3 4! For n = 3, a5 = − 1 5! + 3 5 · 4a3 = − 1 5! + 3 5 · 4 [− 1 3! + 1 3 · 2 a1 ] = − 4 5! + 3 5!a1 For n = 4, a6 = 13 6! For n = 5, a7 = −21 7! + 15 7! a1 26 Thus, y = ∞∑ n=0 anxn = a0 + a1x + a2x2 + a3x3 + a4x4 + a5x5 + . . . By substituting the values of an into y, we obtain the general solution of (2.21): y = a0 · 1 + a1 [ x + 1 3!x3 + 3 5!x5 + 15 7! x7 + . . .] + [1 2x2 − 1 3!x3 + 3 4!x4 − 4 5!x5 + . . .] . You can now check using the recurrence formula that R = ∞. 2.2.3 Series solutions at singular points In the last section, we saw how to deal with power series solutions at ordinary points. But the question is, how can we proceed at a singular point? Let us consider the homogeneous ODE: P (x)y′′ + Q(x)y′ + R(x)y = 0. (2.22) We observe the following: Remark 2.2.1 If in (2.22), P, Q and R are polynomials without common factors then singular points are points x0 at which P (x0) = 0. At singular points the solution is not necessarily analytic. Now, we deﬁne a regular singular Point about which a Taylor series will not work. Deﬁnition 2.2.3: Regular singular points (polynomial coeﬃcients) Consider the equation (2.22). If P, Q and R are polynomials and suppose P (x0) = 0 then x0 is a regular singular point if lim x→x0 (x − x0) Q(x) P (x) and lim x→x0 (x − x0)2 R(x) P (x) are ﬁnite. Otherwise, x0 is an irregular singular point. Example 2.2.7 (a) Considering (1 − x2) y′′ − 2xy′ + 4y = 0, we have P (x) = 1 − x2, P (±1) = 0, Q(x) = −2x, R(x) = 4 and lim x→1 (x − 1) (−2x) (1 − x)(1 + x) = 1, lim x→1(x − 1) 2 4 (1 + x)(1 − x) = 0. Hence, x = 1 is a regular singular point. (similarly for x = −1 ). (b) Considering the ODE: x3y′′ − y = 0, P (x) = x3 Q = 0 R = −1 and lim x→0 x2 ( −1 x3 ) = ∞. 27 Thus x = 0 is an irregular singular point. (c) Consider the ODE: 2(x − 2) 2xy′′ + 3xy′ + (x − 2)y = 0. We have singular points at x = 0 and at x = 2. x = 0 is a regular singular point and x = 2 is an irregular singular point. In the rest of the chapter, we will only consider regular singular points at x0 = 0, and in all other cases, a change of variable t = x − x0 will be applied, which will translate x0 to the origin. More general deﬁnition of a regular singular point Deﬁnition 2.2.4: Regular singular points (general case) If P, Q, and R are not limited to polynomials then consider P (x)y′′ + Q(x)y′ + R(x)y = 0, (2.23) or x2y′′ + x ( xQ(x) P (x) ) y′ + ( x2R(x) P (x) ) y = 0 (2.24) x = 0 is a regular singular point if p(x) = ( xQ(x) P (x) ) and q(x) = (x2R(x) P (x) ) are analytic at x = 0, i.e., p(x) = xQ(x) P (x) = p0 + p1x + · · · and q(x) = x2R(x) P (x) = q0 + q1x + · · · Example 2.2.8 Consider the diﬀerential equation x2y′′ + 2 (e x − 1) y′ + e−x cos xy = 0. Here, P (x) = x2, Q(x) = 2 (e x − 1) , R(x) = e −x cos x. x = 0 is a singular point. lim x→0 xQ P = lim x→0 x2 (e x − 1) x2 = lim x→0 2 (e x − 1) x 0 0= lim x→0 2e x 1 = 2 (L’Hopital) lim x→0 x2R P = lim x→0 x2 e −x cos x x2 = 1 Since the quotient functions p = xQ(x)/P (x) and q = x2R(x)/P (x) have Taylor Expansions about x = 0, x = 0 is a regular singular point. We note from Deﬁnition 2.2.3 that Ly = x2y′′ + xp0y′ + q0y + small as x→0 z }| { x {p1xy′ + q1y + · · · } = 0. (3.16) Then as x → 0, x2y′′ + xp0y′ + q0y ≈ 0 which is an Euler Equation which has solutions of the form y = xλ. Thus about a regular singular point we look for solutions of the form y = xλ ∞∑ n=0 anxn. 28 Important! If x0 = 0 is a regular singular point of the diﬀerential equation (2.23), then the equation has at least one solution of the form y = xλ ∞∑ n=0 anxn = ∞∑ n=0 anxn+λ, (2.25) where λ and an, (n = 0, 1, . . .) are constants. This solution is valid on any interval 0 < x < R, R is the radius of convergence of the series and is greater than or equal to the distance between x0 = 0 and the nearest singular point in the complex plane. In that case, our task is to determine: (a) λ (b) the coeﬃcients an (c) the radius of convergence R. Solution in power series near regular singular points (Frobenius method) In this section, I will provide an outline of the diﬀerent steps of the Frobenius method. For a complete analysis, refer to Chapter 5 of Boyce and DiPrima. Theorem 2.2.3: Fuchs’ Theorem Consider the ODE: P (x)y′′ + Q(x)y′ + R(x)y = 0, (2.26) Assume that x0 = 0 is a regular singular point. Step 1: Indicial equation λ(λ − 1) + bλ + c = 0, (2.27) where b = lim x→0 x Q(x) P (x) and c = lim x→0 x2 Q(x) P (x) . Step 2: First solution If λ1 > λ2 are roots of the indicial equation (2.27) then a solution of (2.26) is y1(x) = ∞∑ n=0 anxn+λ1 where a0 ̸= 0 ( and can be chosen to be equal to 1). To obtain an, we proceed as in the method of power series. The power series y(x) = ∞∑ n=0 anxn+λ = a0xλ + a1xλ+1 + a2xλ+2 + . . . + anxn+λ + . . . (2.28) and its derivatives given by y′(x) = ∞∑ n=0 an(n + λ)xn+λ−1 = λa0xλ−1 + (λ + 1)a1xλ + . . . + (λ + n)anxn+λ−1 + . . . (2.29) 29 and y′′(x) = ∞∑ n=0 an(n + λ)(n + λ − 1)xn+λ−2 = λ(λ − 1)a0xλ−2 + (λ + 1)λa1xλ−1 + . . . (2.30) are substituted into equation (2.26). The Frobenius method always gives a solution y1(x) = ∞∑ n=0 anxn+λ1, (2.31) and the general solution is y(x) = c1y1(x) + c2y2(x). (2.32) The method for obtaining the second solution depends on the relations between the two roots of the indicial equation. Step 3: Second solution The second linearly independent solution y2 is of the form: Case 1: If λ1 − λ2 is neither 0 nor a positive integer: y2(x) = ∞∑ n=0 bnxn+λ2 where we can choose b0 = 1 The coeﬃcients bn are obtained exactly as an but with λ = λ2. Case 2: If λ1 − λ2 = 0 : y2(x) = y1(x) ln x + ∞∑ n=1 bnxn+λ2 for some b1, b2... where y2 is obtained by assuming y1 = f (x, λ) and y2 = ∂f (x,λ) ∂λ \f \f \fλ=λ1. Case 3: If λ1 − λ2 is a positive integer: y2(x) = ay1(x) ln x + ∞∑ n=0 bnxn+λ2 where we can choose b0 = 1. To calculate this solution, ﬁrst try the Frobenius method with λ2. If we obtain a second solution, then this solution is y2(x) from the previous equation with a = 0. Otherwise, we get inﬁnite coeﬃcients. For this case, we proceed to calculate y2(x) using the following formula: y2 = ∂ ∂λ [(λ − λ2)y(λ, x)] \f \f \f \fλ=λ2 . Note The computations presented previously are tedious and heavy, and they may feel overwhelming. Just relax and move forward with the example to see how easy it is to implement. 30 Example 2.2.9 Solve the following diﬀerential equation: 4xy′′ + 2y′ + y = 0. (2.33) Let P (x) = 4x, Q(x) = 2 and R(x) = 1. Then P (0) = 0, and x0 = 0 is a singular point. Moreover, lim x→0 (x − 0) Q(x) P (x) = lim x→0 x 2 4x = 1 2 and lim x→0 (x − 0) 2 R(x) P (x) = lim x→0 x2 1 4x = lim x→0 1 4x = 0. Therefore, x0 = 0 is a regular singular point. Next, we assume: y(x) = ∞∑ n=0 anxn+λ, y′(x) = ∞∑ n=0 an(n + λ)xn+λ−1, y′′(x) = ∞∑ n=0 an(n + λ)(n + λ − 1)xn+λ−2. Substituting these values into (2.33), we obtain: ∞∑ n=0 4an(n + λ)(n + λ − 1)xn+λ−1 + ∞∑ n=0 2an(n + λ)xn+λ−1 + ∞∑ n=0 anxn+λ = 0, i.e., ∞∑ n=0 2(2n + 2λ − 1)(n + λ)anxn+λ−1 + ∞∑ n=0 anxn+λ = 0. Let us consider in the ﬁrst sum, m + λ = n + λ − 1, i.e., m = n − 1 and n = m + 1. When n = 0, m = −1. In the second sum we just take n = m and we obtain ∞∑ m=−1 2(2m + 2λ + 1)(m + λ + 1)am+1xm+λ + ∞∑ m=0 amxm+λ = 0. We can now expand the ﬁrst term of the ﬁrst sum to match with the second sum. This way, we obtain 2(2λ − 1)λa0xλ−1 + ∞∑ m=0 [2(2m + 2λ + 1)(m + λ + 1)am+1 + am] xm+λ = 0. Hence, 2(2λ − 1)λa0 = 0 and 2(2m + 2λ + 1)(m + λ + 1)am+1 + am = 0, m = 0, 1, 2, . . .. Since a0 ̸= 0, we deduce that 2(2λ − 1)λ = 0, this implies λ = 0 or λ = 1 2. We set λ1 = 1 2 and λ2 = 0. On the other hand, we have the recurrence formula am+1 = −1 2(2m + 2λ + 1)(m + λ + 1) am, m = 0, 1, 2, . . . (2.34) Here, δ = λ1 − λ2 = 1 2 not an integer, so we are in the ﬁrst case. For λ = 1 2, we have: am+1 = −1 2(m + 1)(2m + 3) am, m = 0, 1, 2, . . . 31 For m = 0, a1 = − 1 3 × 2a0 = − 1 3!a0 For m = 1, a2 = − 1 5 × 4 a1 = 1 5 × 4 × 3 × 2 a0 = 1 5!a0 For m = 2, a3 = − 1 7 × 6 a2 = − 1 7 × 6 × 5!a0 = − 1 7!a0 For m = 3, a4 = − 1 9 × 8 a3 = 1 9!a0 Thus, y1(x) = ∞∑ n=0 anxn+1/2 = a0x 1 2 + a1x 3 2 + a2x 5 2 + a3x 7 2 + a4x 9 2 + . . . By substituting the values of an into y1, we obtain the ﬁrst solution of (2.33): y1(x) = a0 [x 1 2 − 1 3!x 3 2 + 1 5! x 5 2 − 1 7!x 7 2 + 1 9!x 9 2 + . . .] . For λ = 0, we have: am+1 = −1 2(2m + 1)(m + 1) am, m = 0, 1, 2, . . . For m = 0, a1 = −1 2 a0 = − 1 2! a0 For m = 1, a2 = − 1 4 × 3a1 = 1 4 × 3 × 2!a0 = 1 4!a0 For m = 2, a3 = − 1 6 × 5 a2 = − 1 6 × 5 × 4!a0 = − 1 6!a0 For m = 3, a4 = − 1 8 × 7 a3 = 1 8!a0 Thus, 32 y2(x) = ∞∑ n=0 anxn+0 = a0 + a1x1 + a2x2 + a3x3 + a4x4 + . . . By substituting the values of an into y2, we obtain the second solution of (2.33): y2(x) = a0 [1 − 1 2!x + 1 4!x2 − 1 6!x3 + 1 8!x4 + . . .] . Therefore, the general solution of (2.33) is a linear combination of y1 and y2. Hence, the general solution of (2.33) is y(x) = c1y1(x) + c2y2(x), with c1 and c2constants. From the recurrence relation (2.34), we can deduce that R = ∞. We can further see that y(x) = c1 sin( √ x) + c2 cos(√ x) x > 0, where c1 and c2 are constants. Example 2.2.10 Solve the following diﬀerential equation: x2y′′ − xy′ + y = 0. (2.35) Let P (x) = x2, Q(x) = −x and R(x) = 1. Then P (0) = 0, and x0 = 0 is a singular point. Moreover, lim x→0 (x − 0) Q(x) P (x) = lim x→0 x (−x) x2 = −1 and lim x→0 (x − 0)2 R(x) P (x) = lim x→0 x2 1 x2 = 1. Therefore, x0 = 0 is a regular singular point. Next, we assume: y(x) = ∞∑ n=0 anxn+λ, y′(x) = ∞∑ n=0 an(n + λ)xn+λ−1, y′′(x) = ∞∑ n=0 an(n + λ)(n + λ − 1)xn+λ−2. Substituting these values into (2.35), we obtain: ∞∑ n=0 an(λ + n)(λ + n − 1)xλ+n − ∞∑ n=0(λ + n)anxλ+n + ∞∑ n=0 anxn+λ = 0, i.e., ∞∑ n=0 an(n + λ − 1) 2xn+λ = 0. Hence, an(n + λ − 1) 2 = 0, n = 0, 1, 2, . . . (2.36) For n = 0: (λ − 1) 2a0 = 0 with a0 ̸= 0 33 Since a0 ̸= 0, we obtain: (λ − 1)2 = 0. (2.37) The equation (2.37) is called the indicial equation. The roots of the equation are: λ1 = λ2 = 1. We see from the formula (2.36) that an = 0, n = 1, 2, . . . Here, δ = 0, so we are in the second case. Thus, the second solution will be of the form: y2(x) = y1(x) ln x + xλ1 ∞∑ n=0 bn (λ1) xn. We have: y1(x) = xλ1 ∞∑ n=0 anxn = a0xλ1 = a0x In particular, if we take a0 = 1, then y1(x) = x. To ﬁnd y2, we use the following formula: y2 = ∂y(x, λ) ∂λ \f \f \f \fλ=λ1=1 We have: y(x, λ) = xλ = eλ ln(x) Thus: ∂y(x, λ) ∂λ = ln(x)e λ ln x Therefore: y2 = x ln x Thus: y(x) = c1x + c2x ln x. Example 2.2.11 Solve the following diﬀerential equation: x2y′′ + x(1 − x)y′ − y = 0. (2.38) Let P (x) = x2, Q(x) = x(1 − x) and R(x) = −1. Then P (0) = 0, and x0 = 0 is a singular point. Moreover, lim x→0 (x − 0) Q(x) P (x) = lim x→0 x x(1 − x) x2 = 1 and lim x→0 (x − 0)2 R(x) P (x) = lim x→0 x2 −1 x2 = −1. 34 Therefore, x0 = 0 is a regular singular point. Next, we assume: y(x) = ∞∑ n=0 anxn+λ, y′(x) = ∞∑ n=0 an(n + λ)xn+λ−1, y′′(x) = ∞∑ n=0 an(n + λ)(n + λ − 1)xn+λ−2. Substituting these values into (2.38), we get: ∞∑ n=0 an(n + λ)(n + λ − 1)xn+λ + ∞∑ n=0 an(n + λ)xn+λ − ∞∑ n=0 an(n + λ)xn+λ+1 − ∞∑ n=0 anxn+λ = 0, i.e., ∞∑ n=0[(n + λ) 2 − 1]anxn+λ − ∞∑ n=0 an(n + λ)xn+λ+1 = 0. Let us consider in the ﬁrst sum, m + λ + 1 = n + λ, i.e., m = n − 1 and n = m + 1. When n = 0, m = −1. In the second sum we just take n = m and we obtain ∞∑ m=−1 [(m + λ + 1)2 − 1]am+1xm+λ+1 − ∞∑ m=0 (m + λ)amxm+λ+1 = 0. We can now expand the ﬁrst term of the ﬁrst sum to match with the second sum. This way, we obtain (λ2 − 1)a0xλ + ∞∑ m=0 [(m + λ + 2)(m + λ)am+1 − (m + λ)am] xm+λ+1 = 0. ∞∑ n=0 an(λ + n + 1)(λ + n − 1)xλ+n − ∞∑ n=1(λ + n − 1)an−1xλ+n = 0. Finally, we obtain the indicial equation: λ2 − 1 = 0 with roots λ1 = +1 and λ2 = −1. And the recurrence relation: am+1 = am m + λ + 1 , m = 0, 1, . . . (2.39) Here, we have δ = λ1 − λ2 = 2 ∈ Z+, so we are in the case 3. Using the recurrence formula (2.39) for λ1 = 1, we obtain y1(x) = xλ1 ∞∑ n=0 an(λ1)xn = x ( 1 + 1 3 x + 1 3 · 4x2 + 1 3 · 4 · 5 x3 + . . .) Moreover, using the recurrence formula (2.39) for λ2 = −1, we obtain y2(x) = xλ2 ∞∑ n=0 an(λ2)xn = x−1 (1 + x + 1 2 x2 + 1 3 · 2x3 + 1 3 · 4 x4 + . . .) Finally, the general solution is: y = c1y1(x) + c2y2(x), where c1 and c2 are constants. In this case also, R = ∞. 35 We conclude this chapter by introducing the Frobenius series solution of the Bessel equation. These equations arise during the process of separation of variables in problems with radial or cylindrical symmetry. Depending on the parameter ν in Bessel’s equation, the roots of the indicial equation can be distinct and real, repeated, or diﬀer by an integer. 2.3 Bessel functions 2.3.1 Bessel’s function of order ν /∈ {. . . , −2, −1, 0, 1, 2 . . .} We consider the following class of ordinary diﬀerential equations: Ly = x2y′′ + xy′ + ( x2 − ν2) y = 0. (2.40) We can easily check that x = 0 is a regular singular point: therefore let us assume that y(x) = ∞∑ n=0 anxn+r, substituting this into the diﬀerential equation (2.40) we have ∞∑ n=0 [ (r + n)(r + n − 1) + (r + n) − ν2] anxn+r + ∞∑ n=0 anxn+r+2 = 0 and reindexing the last sum (m = n + 2, n = m − 2, n = 0 ⇒ m = 2) and the ﬁrst sum (n = m), we have ∞∑ m=0 [ (r + m)(r + m − 1) + (r + m) − ν2] amxr+m + ∞∑ m=2 am−2xr+m = 0 Therefore, ∞∑ m=0 [(r + m) 2 − ν2] amxr+m + ∞∑ m=2 am−2xr+m = 0 that is, (r2 − ν2) a0xr + [(r + 1)2 − ν2] a1xr+1 + ∞∑ m=2 {[(r + m) 2 − ν2] am + am−2} xr+m = 0. This must be an identity in x, hence, all coeﬃcients must vanish, so that (r2 − ν2) a0 = 0 [(r + 1)2 − ν2] a1 = 0 [ (r + m)2 − ν2] am + am−2 = 0, m ≥ 2. Since a0 ̸= 0, we get the indicial equation from the ﬁrst term r2 − ν2 = 0 ⇒ r = ±ν. (2.41) Also, from the second equation, we must have a1 = 0 provided ν ̸= −1 2 and if ν = −1 2 then a1 is arbitrary. (2.42) 36 Finally, we get the recurrence relation am = − am−2 (r + m)2 − ν2 , m ≥ 2. For r = ν : am = − am−2 (m + ν)2 − ν2 = − am−2 m2 + 2mν = − am−2 m(m + 2ν), m ≥ 2. n = 2 a2 = − a0 2(2 + 2ν) = − a0 22(1 + ν), n = 4 a4 = − a2 4(4 + 2ν) = (−1)2a0 2.24(2 + ν)(1 + ν). Therefore, a2m = (−1) ma0 m!22m(1 + ν) . . . (m + ν). Hence, y1(x) = xν ∞∑ m=0 (−1) m(x/2) 2m m!(1 + ν)(2 + ν) . . . (m + ν) x→0 −−→ 0. For r = −ν : am = − am−2 m(m − 2ν), m ≥ 2. n = 2 a2 = − a0 2(2 − 2ν) = − a0 22(1 − ν) n = 4 a4 = − a2 4(4 − 2ν) = (−1) 2a0 224(1 − ν)(2 − ν) Therefore, a2m = (−1) ma0 m!22m(1 − ν) . . . (m − ν). Hence, y2(x) = x−ν ∞∑ m=0 (−1) m(x/2)2m m!(1 − ν) . . . (m − ν) x→0 −−→ ∞. 2.3.2 Bessel’s function of order ν = 0: repeated roots In this case Ly = x2y + xy′ + x2y = 0. 37 y(x) = ∞∑ n=0 anxn+r Ly = ∞∑ n=0 an{(n + r)(n + r − 1) + (n + r)}xn+r + ∞∑ n=0 anxn+r+2 = 0. Let us take m = n + 2 in the ﬁrst sum i.e, n = m − 2. We obtain ∞∑ n=2 [ an(n + r) 2 + an−2] xn+r + a0[r(r − 1) + r]xr + a1[(r + 1)r + r + 1]xr+1 = 0. r2a0 = 0 [(r + 1)r + r + 1] a1 = 0 (r + n) 2an + an−2 = 0, n ≥ 2. Since a0 ̸= 0, we get the indicial equation from the ﬁrst term r2 = 0 ⇒ r = 0 (double root). (2.43) Also, from the second equation, we must have a1 = 0. (2.44) Finally, we get the recurrence relation an = −an−2 n2 , n ≥ 2. Note that an = 0 for n = 3, 5, . . .. a2 = −a0 22 ; a4 = −a2 42 = a0 2242 ; a6 = −a4 62 = − a0 224262 ; a8 = a0 22426282 a2m = (−1)m 22m(m!)2 a0. Hence, y1(x) = { 1 + ∞∑ m=1 (−1) mx2m 22m(m!)2 } = J0(x). To get a second solution y(x, r) =a0xr { 1 − x2 (2 + r)2 + x4 (2 + r)2(4 + r)2 + · · · + (−1) mx2m (2 + r)2(4 + r)2 . . . (2m + r)2 + · · · } . Hence, ∂y ∂r (x, r) \f \f \f \fr=r1 = a0 ln xy1(x) + a0xr ∞∑ m=1 (−1) mx2m ∂ ∂r { 1 (2 + r)2 . . . (2m + r)2 } . Let a2m(r) = 1 (2 + r)2 . . . (2m + r)2 ⇒ ln a2m(r) = −2 ln(2 + r) − . . . − 2 ln(2m + r). 38 Figure 2.1: Zeroth order Bessel functions j0(x) and Y0(x) This implies that a′ 2m(0) = ( − 2 2 + r − 2 4 + r · · · − 2 (2m + r) )\f \f \f \fr=0 a2m(0) = (−1 − 1 2 − . . . − 1 m ) a2m(0) = −Hma2m(0), Where Hm = 1 + 1 2 + · · · + 1 m . Therefore, y2(x) = J0(x) ln x + ∞∑ m=1 (−1) m+1Hm 22m(m!)2 x2m x > 0. It is conventional to deﬁne Y0(x) = 2 π [y2(x) + (γ − ln 2)J0(x)] . where γ = lim n→∞ (Hn − ln n) = 0.5772 Euler’s Constant . Finally y(x) = c1J0(x) + c2Y0(x). 2.3.3 Bessel’s Function of Order ν = 1 2 : Consider the case ν = 1 2 : Ly = x2y′′ + xy′ + ( x2 − 1 4) y = 0. Let 39 y = ∞∑ n=0 anxn+r Ly = ∞∑ n=0 an { (n + r) 2 − 1 4 } xn+r + ∞∑ n=0 anxn+r+2 = 0, (m = n + 2, n = m − 2; n = 0 → m = 2) Ly = a0 { r2 − 1 4 } xr + a1 {(r + 1)2 − 1 4 } xr+1 + ∞∑ n=2 [an { (n + r) 2 − 1 4 } + an−2 ] xn+r = 0. (r2 − 1 4)a0 = 0 [(r + 1)2 − 1 4 ] a1 = 0 an { (n + r)2 − 1 4 } + an−2 = 0, n ≥ 2. Indicial Equation: r2 − 1 4 = 0, r = ± 1 2. Roots diﬀer by an integer. Recurrence: an = − an−2 (n + r)2 − 1 4 n ≥ 2. For r1 = + 1 2 : an = − an−2 (n + 1 2)2 − 1 4 = − an−2 (n + 1)n n ≥ 2 ( 9 4 − 1 4) a1 = 0 ⇒ a1 = 0, and using the recurrence formula, an = 0 for n = 3, 5, . . . a2 = − a0 3.2 a4 = (−1) 2a0 5 · 4.3 · 2 . . . a2n = (−1) na0 (2n + 1)! . Hence, the ﬁrst solution is y1(x) = x 1 2 ∞∑ n=0 (−1)nx2n (2n + 1)! = x− 1 2 ∞∑ n=0 (−1) nx2n+1 (2n + 1)! = x− 1 2 sin x. For r2 = − 1 2 : an = − an−2 (n − 1 2)2 − 1 4 = − an−2 n(n − 1), n ≥ 2, n = 1 ⇒ a1 {(−1 2 + 1)2 − 1 4 } = a1.0 = 0 a1 and a0 arbitrary. a0 : a2 = − a0 2.1 a4 = (−1) 2a0 4.3.2.1 . . . a2n = (−1)na0 (2n)! . a1 : 40 a3 = − a1 3.2 a5 = (−1)2a1 5 · 4.3 · 2 a2n+1 = (−1) na1 (2n + 1)! (5.20) y2(x) = a0x− 1 2 ∞∑ n=0 (−1) nx2n (2n)! + a1x− 1 2 ∞∑ n=0 (−1) nx2n+1 (2n + 1)! =a0x− 1 2 cos x + a1x− 1 2 sin x ↖ included in y1(x). y(x) = c1y1(x) + c2y2(x), where c1 and c2 are constants. 41 Chapter 3 Introduction to partial diﬀerential equations 3.1 Introduction This chapter introduces some basic partial diﬀerential equations (PDEs). A partial diﬀerential equa- tion is a mathematical equation in which the unknown is a function of several variables and involves the partial derivatives of this function with respect to those variables. For example, one might want to determine the temperature at a speciﬁc point in space over time. In this case, the unknown function represents the temperature, and the PDE involves its partial derivatives with respect to time and spatial variables. Partial diﬀerential equations appear in many models in physics, engineering, or biology, such as the propagation of heat or sound, ﬂuid ﬂow, electrodynamics, and the spread of epidemics. They are also used in weather forecasting models and climate models. 3.2 Classiﬁcation of PDEs In the previous chapters, we discussed linear ordinary diﬀerential equations (ODEs). We saw that these are equations that deﬁne functions of a single independent variable by establishing a relationship between the values of the function and its derivatives. Now, let us give an example of nonlinear ODE Example 3.2.1: Examples of nonlinear ODEs Some examples of nonlinear ODEs are given by: 1. x2y′(x) + 2xy(x) = y2(x) (ﬁrst order); 2. y′′(x) + ey(x) = 0 (second order). PDEs involve multivariable functions u(x, t), u(x, y) that are determined by prescribing a rela- tionship between the function value and its partial derivatives. Deﬁnition 3.2.1 The order of a PDE is deﬁned as the order of the highest partial derivative occurring in the equation. A PDE is said to be linear if the dependent variable and its partial derivatives occur only in 42 the ﬁrst degree and are not multiplied, otherwise it is said to be non-linear. In the remainder of the chapter, we will occasionally use ux to denote ∂u ∂x , uxx to denote ∂2u ∂x2 , and uxy to denote ∂2u ∂x∂y = ∂ ∂x ( ∂u ∂y ). Example 3.2.2 Let u be an unknown function dependent on x, y. 1. Linear ﬁrst order PDE: a(x, y)ux+b(x, y)uy +c(x, y)u = d(x, y), a and b are not identically 0; 2. Second order linear PDE: Auxx +Buxy +Cuyy +Dux +Euy +F u = G; A, B, C, D, E, F, G : Constants or functions of x, y; A, B, C not identically 0. If G = 0 the PDE is homoge- neous, if G ̸= 0 the PDE is non homogeneous. Analogous to characterizing quadratic equations AX 2 + BXY + CY 2 + DX + EY = k, as either hyperbolic, parabolic, or elliptic, determined by the discriminant: ∆ = B2 − 4AC, we do the same for partial diﬀerential equations (PDEs). This brings us to the following classiﬁcation. ∆ Type of PDE Quadric (Analogous) Example of PDE PDE Nature ∆ > 0 Hyperbolic T 2 − c2X 2 = k utt = c2uxx Wave equation ∆ = 0 Parabolic T = X 2 ut = uxx Heat equation/ diﬀusion equation ∆ < 0 Elliptic X 2 + Y 2 = k uxx + uyy = f Laplace’s equation if f = 0 Poisson equation iff ̸= 0 All linear and second-order PDEs can be transformed into one of these types. 3.3 A one dimensional conservation law Assume we are looking at the traﬃc ﬂow at a length ∆x of a highway. We denote by u(x, t) the density of cars at position x at time t. [u] = number of cars /unit length. Let q(x, t) be the ﬂux of cars at position x at time t. [q] = number of cars /unit time. x x + ∆x q(x, t) ﬂux in q(x + ∆x, t) ﬂux out u(x, t) u(x + ∆x, t) number of cars: u(x, t)∆x ∆x Figure 3.1: Traﬃc ﬂow along the x axis with density u(x, t) and ﬂux q(x, t) at x and time t. The conservation law tells us that the change in the number of cars over [t, t + ∆t] is equal to: number of cars in − number of cars out. 43 That is u(x, t + ∆t)∆x − u(x, t)∆x = q(x, t)∆t − q(x + ∆x, t)∆t. (3.1) Check dimensions: # cars L · L = # cars T · T. Divide (3.1) by ∆t · ∆x : u(x, t + ∆t) − u(x, t) ∆t = q(x, t) − q(x + ∆x, t) ∆x Now let ∆t → 0, ∆x → 0 : ∂u ∂t = − ∂q ∂x or ∂u ∂t + ∂q ∂x = 0. (3.2) This is a conservation law PDE. In this equation, u(x, t) and q(x, t) are both unknowns and to be able to solve this PDE we need to know how q is related to u. This information comes from the nature of the problem. For instance it can be: an equation of state (thermodynamics) or a constitutive relation (continuum mechanics). Linear ﬂux density relationship Assume that the ﬂux of cars q increases linearly with the density of cars u, i.e., q = cu, c > 0, then it follows that ∂u ∂t + c∂u ∂x = 0. (3.3) Since the PDE has constant coeﬃcients and is a linear combination of time and spatial partial derivatives, we might expect to ﬁnd a solution of the form of an exponential of a linear function of x and t, since either derivative of such a function is in the form of a constant times the exponential. We therefore consider the trial solution of the form: u(x, t) = eikx+σt. (3.4) Substituting (3.4) into (3.3), we obtain ( ∂ ∂t + c ∂ ∂x ) e ikx+σt = (σ + ikc)e ikx+σt which is a solution of (3.3) provided σ and k satisfy the following “dispersion relation” σ = −ikc So, the solution of (3.3) is u(x, t) = e ik(x−ct). You can show that any diﬀerentiable function f with the functional form f (x − ct) is a solution to (3.3): To see this, let u(x, t) = f (x − ct), then ut = −cf ′(x − ct) and ux = f ′(x − ct) and ut + cux = −cf ′ + cf ′ = 0. The PDE (3.3) with the solution u(x, t) = f (x − ct) can be interpreted as a right moving wave using the Galilean transformation (see Figure 3.2). The wave propagates in time to the right: • observer in blue, stationary, sees x; • observer in red, moving with the wave, sees x′ = x − ct. 44 Figure 3.2: The Galilean transformation of coordinates from x to x′ = x − ct [1]. Assume that the ﬂux of cars q decreases linearly with the density of cars u, q = −cu, c > 0, i.e. the wave is moving to the left. Then it follows that ∂u ∂t − c∂u ∂x = 0 (3.5) and the solution is u(x, t) = f (x + ct). The second order wave equation: Here, we consider a wave moving in both directions. If we apply the left ∂ ∂t − c ∂ ∂x and right ∂ ∂t + c ∂ ∂x moving wave operators in succession, we obtain ( ∂ ∂t + c ∂ ∂x ) ( ∂ ∂t − c ∂ ∂x ) u(x, t) = ∂2u ∂t2 − c2 ∂2u ∂x2 = 0, (3.6) which is the second order wave equation that has both left and right moving wave solutions. The convection-diﬀusion equation Consider the traﬃc ﬂowing down the highway as shown in Figure 3.1 and assume that the ﬂux q increases linearly with the car density u. Now what happens if drivers slow down if they see an increase in car density ahead of them? This situation can be represented by a ﬂux function of the form q = cu − Dux. (3.7) # cars T = L T · # Cars L − [D]# Cars L2 , so, D should have dimensions: [D] = L2 T . Combining (3.3) and (3.7) we obtain the convection-diﬀusion equation ut + cux| {z } Convection = Duxx. | {z } Diﬀusion (3.8) So, now in addition to moving at speed c to the right, the wave diﬀuses too, with a diﬀusion coeﬃcient D. Now, if you make a change of variable: z = x − ct, i.e., you move with the center of the wave, 45 and ﬁnd the PDE for U (z) : Ut = DUzz. (3.9) This means the observer that travels with the wave only sees the diﬀusion. Finding the dispersion relation for the Convection-diﬀusion equation Consider a solution: u(x, t) = eikx+σt. Substitute in: ∂u ∂t + c ∂u ∂x = D ∂2u ∂x2 , to obtain (σ + ick)eikx+σt = ( −k2) Deikx+σt. Hence, σ = − ikC|{z} due to convection − k2D|{z} due to diﬀusion (the dispersion relation). Therefore, u(x, t) = eikx−ikct−k2Dt = eik(x−ct) | {z } right moving wave · e −k2Dt | {z } decay in time due to diﬀusion D > 0 3.4 The heat/diﬀusion equation Consider the heat conduction in a length ∆x of a conducting bar: x x + ∆x q(x, t) q(x + ∆x, t) u(x, t) u(x + ∆x, t) ∆x Figure 3.3: Heat conduction along the x axis. • u(x, t) : The temperature at location x, time t, and has units degrees Kelvin, [u] = K; • q(x, t) : The heat ﬂux, or the ﬂux of heat energy per unit area, [q] = J m2·S ; • C : The speciﬁc heat capacity. The amount of energy needed to increase the temperature of one kilogram of the material by one degree Kelvin: [C] = J kg·K (a material property); • ρ : Density of the material, [ρ] = kg m3 ; • A: The cross sectional area of the bar [A] = m 2. 46 Now, let us write down the conservation of energy: The increase in the thermal energy of the bar with length ∆x = thermal energy in − thermal energy out. That is C · [u(x, t + ∆t) − u(x, t)] · ρ · ∆x · A = [q(x, t) − q(x + ∆x, t)]A · ∆t. (3.10) Check the dimensions in equation above: J kg · K · K · kg m3 · m · m2 = J m2 · S · m 2 · S J = J Divide (3.10) by A∆x · ∆t : ρC [u(x, t + ∆t) − u(x, t)] ∆t = [q(x, t) − q(x + ∆x, t)] ∆x Let ∆t → 0 and ∆x → 0, we obtain ρC ∂u ∂t = − ∂q ∂x i.e., ρC ∂u ∂t + ∂q ∂x = 0 (the energy conservation PDE). (3.11) Now, we need to ﬁnd a constitutive relation between u and q. 1. Fourier’s law: Experimental evidence suggests that the ﬂux of heat is proportional to the negative of the spatial gradient of the temperature. This means that heat always ﬂows from higher temperature to lower temperature regions. In this case: q = −k ∂u ∂x , (3.12) where k is the thermal conductivity having dimensions [k] = J S·m·K = W m·K . Substituting (3.12) Figure 3.4: Fourier’s Law of heat Conduction [1]. into (3.11) and dividing by ρC we obtain the heat equation ∂u ∂t = α2 ∂2u ∂x2 (3.13) where α2 = k ρC is the diﬀusion coeﬃcient, which has dimensions [α2] = m2 S . 2. Fick’s law: The heat ﬂux is from regions of high Concentration of energy to regions of low concentration of energy. q = −α2 ∂(ρCu) ∂x , (3.14) 47 Here, ρCu is the concentration of thermal energy, and has units: [ρCu] = kg m3 · J kg·K · K = J m3 . Substituting (3.14) into (3.11), we obtain ∂u ∂t = α2 ∂2u ∂x2 , (3.15) where α2 is the diﬀusion coeﬃcient. A similar line of reasoning for the heat ﬂow in a conduction plate leads to the two dimensional Heat Equation: ∂u ∂t = α2 ( ∂2u ∂x2 + ∂2u ∂y2 ) . Another nice way of arriving at the diﬀusion equation: random walk see lecture 7 [1] of Prof. Peirce’s lectures. 3.5 The Wave Equation: Consider an elastic rod having a density ρ and cross-sectional area A, and let σ(x, t) be the pressure in the rod at x at time t and u(x, t) the displacement of the rod from its equilibrium position. x x + ∆x σ(x, t) σ(x + ∆x, t) u(x, t) u(x + ∆x, t) F • u(x, t) : displacement from equilibrium, [u] = m; • σ(x, t) : the normal stress [σ] = N m2·S ; • ρ : density, [ρ] = kg m3 ; • A: The cross sectional area of the bar [A] = m 2. Now, let us write down Newton second law (F = M a): [σ(x + ∆x, t) − σ(x, t)] · A | {z } net force = ρ · ∆x · A | {z } mass · ∂2u ∂t2 . |{z} acceleration (3.16) Divide (3.10) by A∆x : σ(x + ∆x, t) − σ(x, t) ∆x = ρ ∂2u ∂t2 Let ∆x → 0, we obtain ∂σ ∂x + ρ ∂2u ∂t2 = 0 (balance of linear momentum). (3.17) Now, we need a constitutive law that gives a relation between σ and u to solve the PDE. In order to have suﬃcient information to solve for the unknowns we need an additional equation, which is 48 Figure 3.5: The stress on the bar σ is related to the strain ϵ by Hooke’s Law[1]. provided by a constitutive relation known as Hooke’s Law (see Figure 3.5). Experimental data characterizes the ”stiﬀness” of the material by the parameter E known as the Young’s Modulus, which provides a linear relationship between the stress to which the bar is subjected and the relative displacement ∆u ∆x = u(x+∆x,t)−u(x,t) ∆x ≈ ∂u ∂x := ϵ, or strain ϵ. Substituting the stress strain relationship σ = E ∂u ∂x into (3.17), we obtain the second order wave equation ∂2u ∂t2 = (E ρ ) ∂2u ∂x2 = c2 ∂2u ∂x2 , where c = √E ρ . (3.18) A general form of the solution to this equation is u(x, t) = f (x − ct) + f (x + ct). 3.6 Laplace’s equation: Flow in porous media Consider the steady-state 2D ﬂow in porous media. • u: x component of velocity, [u] = m/S • v: y component of velocity, [V ] = m/S • ρ: density, [p] = kg/m 3 • q: mass ﬂux, [q] = kg/S 49 The Conservation of mass tells us that the sum of ﬂuxes through all boundaries should be zero: We denote by l is a unit length in the y direction. The equation is: ρ[u(x + ∆x, y) − u(x, y)]∆y · l + ρ[v(x, y + ∆y) − v(x, y)]∆x · l = 0. (3.19) Check the dimensions of each term: kg m3 · m S · m · m = kg S (3.20) This ensures that the unit of mass ﬂux is correct. Next, divide equation (3.19) by ρ∆x · ∆y · l: u(x + ∆x, y) − u(x, y) ∆x + v(x, y + ∆y) − v(x, y) ∆y = 0 Let ∆x → 0 and ∆y → 0. This leads to the continuity equation: ∂u ∂x + ∂v ∂y = 0 (3.21) Now, we need to ﬁnd a constitutive relation between u and v. For ﬂow in porous media, you use Darcy’s law as a constitutive law: u = −k ∂h ∂x , v = −k ∂h ∂y (3.22) where: • k: hydraulic conductivity, [k] = m S • h: hydraulic head, [h] = m So, Darcy’s law states that the ﬂow direction is from regions with higher hydraulic head to regions with lower hydraulic head. Note 3.6.1 Darcy’s law is sometimes stated as: u = − x µ ∂P ∂x , where where: • x: permeability, [x] = m 2 • µ: viscosity of ﬂuid, [µ] = Pa · S • P : pore pressure, [P ] = Pa Substituting u = −k ∂h ∂x and v = −k ∂h ∂y into the continuity equation (3.21) gives the 2D Laplace’s equation: ∂2h ∂x2 + ∂2h ∂y2 = 0. (3.23) 50 Chapter 4 Introduction to numerical methods for partial diﬀerential equations 4.1 Introduction Note that numerical methods always involve discretizing analytical problems into numerical problems, and there is an inﬁnite number of discretization methods for an equation. In this chapter, we introduce the ﬁnite diﬀerence method, which is widely used for approximating partial diﬀerential equations (PDEs) using a computer. The ﬁnite diﬀerence method is a common technique for ﬁnding approximate solutions to partial diﬀerential equations. It involves solving a system of relations (numerical scheme) that connects the values of unknown functions at points that are suﬃciently close to each other. At ﬁrst glance, this method seems to be the simplest to implement, as it proceeds in two steps: ﬁrst, the discretization of the diﬀerentiation operators using ﬁnite diﬀerences, and second, the convergence of the resulting numerical scheme as the distance between the points decreases. 4.2 Approximating the derivatives of a function by ﬁnite diﬀerences In previous courses, you have introduced the notion of the derivative for a diﬀerentiable function and the Taylor’s formula. Deﬁnition 4.2.1: Derivative of a function and Taylor’s formula Assume that the function f : R → R is diﬀerentiable, then f ′(x) = lim ∆x→0 f (x + ∆x) − f (x) ∆x . (4.1) If we assume that the function can be diﬀerentiated many times then Taylor’s formula is given by: f (x + ∆x) = f (x) + ∆xf ′(x) + ∆x2 2! f ′′(x) + ∆x3 3! f (3)(x) + . . . (4.2) or, with −∆x instead of +∆x : f (x − ∆x) = f (x) − ∆xf ′(x) + ∆x2 2! f ′′(x) − ∆x3 3! f (3)(x) + . . . (4.3) 51 Three basic types of ﬁnite diﬀerence methods are commonly considered: forward, backward, and central ﬁnite diﬀerences. Deﬁnition 4.2.2: Forward diﬀerence On a computer, derivatives are approximated by ﬁnite diﬀerence expressions; rearranging (4.2) gives the forward diﬀerence approximation f (x + ∆x) − f (x) ∆x = f ′(x) + O(∆x), (4.4) where O(∆x) means ’terms of order ∆x ’, ie. terms which have size similar to or smaller than ∆x when ∆x is small. Technically, a term or function E(∆x) is O(∆x) if lim ∆x→0 E(∆x) ∆x = constant. So the expression on the left approximates the derivative of f at x, and has an error of size ∆x; the approximation is said to be ’ﬁrst order accurate’. Deﬁnition 4.2.3: Forward diﬀerence Rearranging (4.3) similarly gives the backward diﬀerence approximation f (x) − f (x − ∆x) ∆x = f ′(x) + O(∆x), (4.5) which is also ﬁrst order accurate, since the error is of order ∆x. Deﬁnition 4.2.4: Central diﬀerence Combining (4.2) and (4.3) gives the central diﬀerence approximation f (x + ∆x) − f (x − ∆x) 2∆x = f ′(x) + O ( ∆x2) , (4.6) which is ’second order accurate’, because the error this time is of order ∆x2. Deﬁnition 4.2.5: Second derivative, central diﬀerence Adding (4.2) and (4.3) gives f (x + ∆x) + f (x − ∆x) = 2f (x) + ∆x2f ′′(x) + ∆x4 12 f (4)(x) + . . . (4.7) Rearranging this therefore gives the central diﬀerence approximation to the second derivative: f (x + ∆x) − 2f (x) + f (x − ∆x) ∆x2 = f ′′(x) + O (∆x2) , (4.8) which is second order accurate. 52 Note: How many boundary conditions are needed to solve a PDE? Typically, for a PDE, to obtain a unique solution, we need one condition (either boundary or initial) for each derivative in each variable. For instance: • The heat equation: ut = uxx, involves one time derivative and two spatial derivatives, meaning we require: – One initial condition (IC) – Two boundary conditions (BCs) • The wave equation: utt = uxx, involves two time derivatives and two spatial derivatives, meaning we require: – Two initial conditions (ICs) – Two boundary conditions (BCs) • Laplace’s equation: uxx + uyy = 0, involves two spatial derivatives in both the x and y directions, meaning we require: – Four boundary conditions (BCs) 4.3 Solving the heat equation using the method of ﬁnite diﬀerences 4.3.1 Dirichlet boundary conditions Method 4.3.1: Dirichlet boundary conditions To ﬁnd a numerical solution to the heat equation: ∂u ∂t = α2 ∂2u ∂x2 , 0 < x < L, t > 0 BC: u(0, t) = A, u(L, t) = B, IC: u(x, 0) = f (x), (4.9) we approximate the time derivative using forward diﬀerences, and the spatial derivative using central diﬀerences; u(x, t + ∆t) − u(x, t) ∆t = α2 u(x + ∆x, t) − 2u(x, t) + u(x − ∆x, t) ∆x2 + O (∆t, ∆x2) . (4.10) This approximation is second order accurate in space and ﬁrst order accurate in time. The use of the forward diﬀerence means the method is explicit, because it gives an explicit formula for u(x, t + ∆t) depending only on the values of u at time t. 53 Divide the interval 0 < x < L into N + 1 evenly spaced points, with spacing ∆x; ie. xn = n∆x, for n = 0, 1, . . . , N , and divide the time interval [0, T ] into M + 1 equal time levels tk = k∆t for k = 0, 1, . . . , M . Then seek the solution by ﬁnding the discrete values uk n = u (xn, tk) . From (4.10), these satisfy the equations u k+1 n − uk n ∆t = α2 u k n+1 − 2u k n + u k n−1 ∆x2 or, rearranging, u k+1 n = u k n + α2∆t ∆x2 (u k n+1 − 2uk n + u k n−1) . (4.11) If the values of un at time step k are known, this formula gives all the values at time step k + 1, and it can then be iterated again and again. The initial condition gives u 0 n = f (xn) , (4.12) for all n ∈ {0, . . . , N }, and the boundary conditions require u k 0 = A, u k N = B, (4.13) for all k ∈ {0, . . . , M } (equation (4.11) only has to be solved for 1 ≤ n ≤ N − 1 ). Figure 4.1: Mesh points and ﬁnite diﬀerence stencil for the heat equation. Blue points are prescribed the initial condition, red points are prescribed by the boundary conditions. For Neumann boundary conditions, ﬁctional points at x = −∆x and x = L + ∆x can be used to facilitate the method. 54 4.3.2 Neumann boundary conditions Method 4.3.2: Neumann boundary conditions To apply ∂u ∂x (0, t) = C. (4.14) instead of u(0, t) = A in (4.9), notice that the central diﬀerence version of this boundary condition would be u(0 + ∆x, t) − u(0 − ∆x, t) 2∆x = C, (4.15) and therefore u(−∆x, t) = u(∆x, t) − 2∆xC ( i.e, u k −1 = uk 1 − 2∆xC). (4.16) x = −∆x is outside the domain of interest, but knowing the value of u(−∆x, t) there allows the discretised equation (4.11) to be used also for x = 0 (n = 0), and it becomes u k+1 0 = u k 0 + α2∆t ∆x2 ( 2uk 1 − 2uk 0 − 2∆xC) . (4.17) So, in this case we must solve (4.11) for 1 ≤ n ≤ N −1, and (4.17) for n = 0 at each time step. If there is a derivative condition at x = L the same procedure is followed and an equation similar to (4.17) must be solved for n = N too. A handy way to implement this type of boundary condition, which enables the same formula (4.11) to be used for all points, is to introduce ’ﬁctional’ mesh points for n = −1 and n = N + 1, and to prescribe the value u k −1 given by (4.16) (or the equivalent for uk N +1 ) at those points. Stability Theorem 4.3.1: Stability condition Note that, this method will only be stable, provided the condition α2∆t ∆x2 ≤ 1 2 (4.18) is satisﬁed; otherwise it will not work. 4.4 Solving the Wave equation using the method of ﬁnite diﬀerences 4.4.1 Dirichlet boundary conditions 55 Method 4.4.1: Dirichlet boundary conditions For the wave equation, ∂2u ∂t2 = c2 ∂2u ∂x2 , 0 < x < L, t > 0 BC: u(0, t) = 0, u(L, t) = 0, IC: u(x, 0) = f (x), ∂u ∂t (x, 0) = g(x), (4.19) discretise x into N + 1 evenly spaced mesh points xn = n∆x, discretise the time interval [0, T ] into M + 1 equal time levels tk = k∆t for k = 0, 1, . . . , M , and seek the solution at these mesh points; u k n = u (xn, tk). Using central diﬀerence approximations to the two second derivatives, the discrete equation is u k+1 n − 2uk n + u k−1 n ∆t2 = c2 u k n+1 − 2u k n + n k n−1 ∆x2 + O ( ∆x2, ∆t 2) . (4.20) This can be rearranged to give uk+1 n = 2uk n − u k−1 n + c2∆t 2 ∆x2 ( uk n+1 − 2u k n + n k n−1) (4.21) which gives an explicit method to calculate u k+1 n in terms of the values at the previous two time steps k and k − 1. This method is second order accurate in space and time - it is sometimes referred to as the ’leap-frog’ method. To apply Dirichlet boundary conditions given in (4.19), the values of u k+1 0 and uk+1 N are simply prescribed to be 0; there is no need to solve an equation for these end points. 4.4.2 Neumann Boundary conditions Method 4.4.2: Neumann boundary conditions If the boundary conditions are Neumann, on the other hand: ∂u ∂x (0, t) = 0, ∂u ∂x (L, t) = 0 (4.22) then (4.21) can still be solved for n = 0 and n = N if we use the central diﬀerence approxi- mations to the boundary conditions in order to determine the ’ﬁctional’ values u k −1 and u k N +1 respectively. At x = 0, for instance, the discretised condition (4.22) is uk −1 − uk 1 2∆x = 0 (28) and therefore u k −1 = uk 1. Similarly uk N +1 = uk N −1. 56 Figure 4.2: Mesh points and ﬁnite diﬀerence stencil for the wave equation. 4.4.3 Initial conditions Method 4.4.3: Initial conditions To apply the initial conditions, note that to use (4.21) for the ﬁrst time step k = 1, we need to know the values of u 0 n and also u−1 n . The values of u 0 n follow from the initial condition on u(x, 0); u 0 n = f (xn) . (4.23) The values of u −1 n come from considering the central diﬀerence approximation to the derivative condition given in (4.19); u(x, 0 + ∆t) − u(x, 0 − ∆t) 2∆t = g(x), from which we deduce that u −1 n = u 1 n − 2∆tg (xn) . Substituting this into the discrete equation (4.21), and rearranging, gives the formula u1 n = u0 n + 1 2 c2∆t 2 ∆x2 (u 0 n+1 − 2u0 n + n 0 n−1) + ∆tg (xn) (32) for the ﬁrst time step. Once the solution has been initialised in this way, all subsequent time steps can be made using (4.21). 57 Stability Theorem 4.4.1: Stability condition This method is stable provided c∆t ∆x ≤ 1 (33) which is often called the Courant-Friedrichs-Levy (or CFL) condition. 4.5 Solving the Laplace’s equation using the method of ﬁnite diﬀerences 4.5.1 Dirichlet boundary conditions Method 4.5.1: Dirichlet boundary conditions Laplace’s equation on a square domain is ∂2u ∂x2 + ∂2u ∂y2 = 0, 0 < x < L, 0 < y < L (34) with boundary conditions, u(0, y) = 0, u(L, y) = 0, u(x, 0) = f (x), u(x, L) = 0 (35) Choose a mesh with spacing ∆x in the x direction, ∆y in the y direction (often it is sensible to choose ∆x = ∆y ), so grid points are xn = n∆x for n = 0, 1, . . . N , and ym = m∆y for m = 0, 1, . . . M . Then seek solution values unm = u (xn, ym). Using second order accurate central diﬀerences for the two derivatives, the discrete equation is un+1m − 2unm + un−1m ∆x2 + unm+1 − 2unm + unm−1 ∆y2 = O (∆x2, ∆y2) (36) and if ∆x = ∆y this simpliﬁes to unm = 1 4 (un+1m + un−1m + unm+1 + unm−1) . (4.24) Note this equation shows that the solution has the property that the value at each point (xn, ym) is the average of the values at its four neighbouring points. This is an important property of Laplace’s equation. The boundary conditions (35) determine the values unm on each of the four boundaries, so (4.24) does not have to be solved at these mesh points: u0m = 0, uN m = 0, un0 = f (xn) , unM = 0. (4.25) 58 Note 4.5.1: Neumann boundary conditions Neumann boundary conditions can be incorporated by calculating values for u−1m (for instance), as for the heat equation. Figure 4.3: Mesh points and ﬁnite diﬀerence stencil for Laplace’s equation. Jacobi Iteration Note that (4.24) is not an explicit formula, since the solution at each point depends on the unknown values at other points, and it is therefore harder to solve than the previous explicit methods. One way to do it, however, is to take a guess at the solution (eg. unm = 0 everywhere), and then go through each of the mesh points updating the solution according to (4.24) by taking the values of the previous guess on the right hand side. Iterating this process many times, the successive approximations will hopefully change by less and less, and the values they converge to provide the solution. Given an initial guess u (0) nm, the successive iterations u(1) nm, . . . , u(k) nm, u (k+1) nm , . . ., are given by u (k+1) nm = 1 4 (u (k) n+1m + u (k) n−1m + u (k) nm+1 + u (k) nm−1) . (39) Here the superscript ( k ) denotes the values for the k th iteration. The process is continued until the change between successive iterations is less than some desired tolerance. 59 Bibliography [1] Lectures notes of Prof. Anthony Peirce, https://personal.math.ubc.ca/~peirce/math257_ 316_2018_NA.htm. [2] Abada Nadjet. Equations diﬀ´erentielles du second ordre. Cours 4 `eme ann´ee, 2019-2020. [3] Boyce & DiPrima. Elementary Diﬀerential Equations and Boundary Value Problems. 60","libVersion":"0.2.1","langs":""}