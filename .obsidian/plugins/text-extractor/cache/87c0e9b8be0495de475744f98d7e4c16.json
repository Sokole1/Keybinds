{"path":".obsidian/plugins/text-extractor/cache/87c0e9b8be0495de475744f98d7e4c16.json","text":"4 Softmax and Decision Stumps Consider the dataset below, which has 10 training examples and 2 features: 01 1 00 1 10 1 11 2 11 2 X=1g ol\" ¥=|af> 10 3 10 3 11 3 10 3 and consider a single test example: i=[1 1]. (a) Suppose we fit a multi-class linear classifier using the softmax loss, and we obtain the following weight matrix: -1 +2 0 W= {+2 0 +3} Under this model, what class label would we assign to the test example? (Show your work.) (b) What is the cost of prediction on t test examples with an already-trained softmax model? State your result in O() notation in terms of the number of training examples n, the number of test examples ¢, the number of features d, and the number of classes k? (c) What is the decision stump that minimizes the classification error?","libVersion":"0.2.1","langs":"eng"}