{"path":".obsidian/plugins/text-extractor/cache/cc10d268ea2481099a1ce997e034408c.json","text":"5 5] 134 1 [ 2o All three matrices have rank r = 1 A=|1 2 5 |=(1 =CR P Column Rank = Row Rank 125 1 5 The number of independent columns equals the number of independent rows This rank theorem is true for every matrix. Always columns and rows in linear algebra ! The m rows contain the same numbers a;; as the n columns. But different vectors. The theorem is proved by A = CR. Look at that differently—by rows instead of columns. The matrix R has rows. Multiplying by C takes combinations of those rows. Since A = CR, we get every row of A from the r rows of R. And those r rows are independent, so they are a basis for the row space of A. The column space and row space of A both have dimension r, with r basis vectors—columns of C' and rows of R. One minute : Why does R have independent rows ? Look again at Example 4. i 1 3 8 I 1 0 2 | « independent A=11 2 6 |=|1 2 0 1 2|« rowsof R 01 2 0 1 W g ones and zeros - It is those ones and zeros in R that tell me: No row is a combination of the other rows. The big factorization for data science is the “SVD” of A—when the first factor C' has r orthogonal columns and the second factor R has r orthogonal rows.","libVersion":"0.2.1","langs":"eng"}