{"path":".obsidian/plugins/text-extractor/cache/8e7a3e61b8fe891448696e04f13b7ff0.json","text":"Math 318 Solutions to Assignment #4 Total marks = [30]. 1. (a) FX(x)= x \u0000 2 for 2  x  3 so [1] FT(t)= P(T  t)= P( 1 2 X2  t)= P(X  p2t)= 8 >< >: 0 (t < 2) p2t \u0000 2 (2  t  9/2) 1 (t \u0000 9/2). (b) fT(t)= F0 T(t)= 8 >< >: 0 (t < 2) 1/p2t (2  t  9/2) 0 (t \u0000 9/2). [1] (c) (i) ET = R 9/2 2 t(2t)\u00001/2dt = 19 6 . [2] VarT = ET2 \u0000 (ET)2 = R 9/2 2 t2(2t)\u00001/2dt \u0000 ( 19 6 )2 = 211 20 \u0000 ( 19 6 )2 = 0.5222, so s = pVarT = 0.7226. (ii) ET = R 3 2 1 2 x2dx = 19 6 . VarT = ET2 \u0000 (ET)2 = R 3 2 ( 1 2 x2)2dx \u0000 ( 19 6 )2 = 211 20 \u0000 ( 19 6 )2. The results are of course the same as in (i). 2. (a) FM(x)= P(M  x)= P(Xi  x for some i)= 1 \u0000 P(X1 > x,. . . , Xn > x). By [2] independence, FM(x)= 1 \u0000 P(X1 > x) ·· · P(Xn > x). For 0  x  1, this gives FM(x)= 1 \u0000 (1 \u0000 x)n. (b) f M(x)= F0 M(x)= n(1 \u0000 x)n\u00001 for 0  x  1. [1] (c) EM = R 1 0 xn(1 \u0000 x)n\u00001dx = 1/(n + 1), and [2] VarX = EM2 \u0000 (EM)2 = Z 1 0 x2n(1 \u0000 x)n\u00001dx \u0000 (n + 1)\u00002 = 2 (n + 1)(n + 2) \u0000 1 (n + 1)2 = n (n + 1)2(n + 2) . 3. EX = 1 2 , EX2 = R 1 0 x2dx = 1 3 , EX3 = R 1 0 x3dx = 1 4 , so Cov(X, X2)= EX3 \u0000 (EX)(EX2)= 1 12 . A similar calculation gives Cov(Y, Y2)= EY3 \u0000 (EY)(EY2)= \u0000 1 12 . [4] 4. (a) f (t, b)= fT(t) fB(b)= (5e\u00005t3e\u00003b t, b \u0000 0 0 otherwise [1] (b) P(T < B)= RR t<b f (t, b)dtdb = R • t=0 R • b=t 5e\u00005t3e\u00003b db dt = 5/8. [1] (c) X = min(T, B) is the waiting time. By independence, P(X > y)= P(T > y, B > y)= P(T > y)P(B > y)= e\u00005ye\u00003y = e\u00008y for y \u0000 0. Hence X ⇠ Exp(8). [2] [1] 5. (a) R x2+y2r2 1 p dxdy = r2. 1 [1] (b) Let R be its distance from the origin. We know from (a) that FR(r)= r2 so fR(r)= 2r and ER = R 1 0 r2rdr = 2/3. [2] (c) fX(x)= R p1\u0000x2 \u0000p1\u0000x2 1 p dy = 2p\u00001p1 \u0000 x2, for \u00001  x  1. The marginal of Y is the same function, and their product is not the constant 1 p on the disk, so X, Y are dependent. (This dependence should be intuitively clear.) (d,e) Here is a sample script to perform the tasks in parts (d) and (e): [1]: import numpy as np import matplotlib.pyplot as plt import math [2]: #(d) To generate uniform random points on the square, we can % generate￿ ,!their coordinates separately. num_points = 5000; #% Create a num_points x 2 matrix; the first column will be x %￿ ,!coordinates, and the second column will be y coordinates. square_points = np.random.uniform(low=-1,high=1,size=(num_points,2)) #% Now plot the points: fig=plt.figure() ax=fig.add_axes([-1,-1,1,1]) ax.scatter(square_points[:,0], square_points[:,1], color='r',s=0.5) ax.set_title('scatter plot') ax.set_aspect('equal') plt.show() #% In the above, square_points[:,i] picks out the ith column. 2 [4]: #addback inscatterpoints fig=plt.figure() ax=fig.add_axes([-1,-1,1,1]) ax.scatter(square_points[:,0], square_points[:,1], color='r',s=0.5) ax.set_title('scatter plot') ax.set_aspect('equal') #% We can draw a circle by doing the following: circle_angles = np.arange(0,2*math.pi,0.01) circle_x = np.cos(circle_angles); circle_y = np.sin(circle_angles); plt.plot(circle_x,circle_y); plt.title(\"Uniformly random points on a unit circle\"); plt.show() 3 [6]: #% (e) Now let’s generate uniformly random R’s and T’s. polar_points_R = np.random.uniform(low=0,high=1,size=(num_points)) polar_points_T = np.random.uniform(low=0,high=2*math. ,!pi,size=(num_points)) #% Convert these to standard Cartesian coordinates: polar_points_X = polar_points_R * np.cos(polar_points_T); polar_points_Y = polar_points_R * np.sin(polar_points_T); #% Plot these points in standard Cartesian coordinates: figure; fig=plt.figure() ax=fig.add_axes([-1,-1,1,1]) ax.scatter(polar_points_X,polar_points_Y, color='b',s=0.5) ax.set_title('Points with uniformly random radius and angle'); ax.set_aspect('equal') 4 Notice that points are much more concentrated in the centre in this plot; as such it appears these points are not uniformly randomly distributed on the circle. 5 (f) In standard coordinates, the density f (x, y) of the uniform random points would simply be 1/p, because ZZ A 1 p dx dy = area of A p . To convert to polar coordinates, one uses the Jacobian and replaces dx dy with rdr dq, so that the above equals ZZ A 1 p rdr dq. Thus we see that the density f (r, q) must be r/p. [1] 6. Here is a Jupyter notebook to calculate the running averages: [3]:7. import numpy as np import matplotlib.pyplot as plt import math [10]: #% Let N be the number of terms we will try. N = 10000; #% Build a vector of N standard normals. X = np.random.normal(0,1,N); #% Now compute the running average of the Xs: running_average = np.cumsum(X) / np.arange(1,N+1) #% Plot the running average plt.plot(running_average); plt.title(\"Running average of standard normal distributed numbers\"); plt.xlabel(\"n\"); plt.ylabel('average of first n terms'); The plot will look different for you, but here is a sample plot produced by the above code. As you can see from this one, it appears that it does converge to 0. 6 [13]: #% Let N be the number of terms we will try. N = 10000; #% Build a vector of N standard normals. Y = np.random.uniform(low=-math.pi/2,high=math.pi/2,size=N) X = np.tan(Y) #% Now compute the running average of the Xs: running_average = np.cumsum(X) / np.arange(1,N+1) #% Plot the running average plt.plot(running_average); plt.title(\"Running average of Cauchy distributed numbers\"); plt.xlabel(\"n\"); plt.ylabel('average of first n terms'); [2] As you can see from this one, it does not appear that it converges to 0 or converges at all. This is a consequence of the “fat tail” of the Cauchy distribution: the jumps arise from single observations of the random variable that dominate the running average. These large observations are rare, but not so rare that they do not occur. The fat tail is also responsible for the fact that the expectation of the Cauchy random variable is undeﬁned. (We will study the convergence question from a different perspective in Assignment 5.) 7","libVersion":"0.2.1","langs":""}