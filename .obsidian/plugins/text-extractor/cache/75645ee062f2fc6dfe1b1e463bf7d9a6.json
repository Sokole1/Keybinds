{"path":".obsidian/plugins/text-extractor/cache/75645ee062f2fc6dfe1b1e463bf7d9a6.json","text":"Question 10. (?? points) Consider a supervised learnix}g problem where we have training examples X with associated labels y, and test examples X. Let Z denote a matrix obtained from a change of basis of X, and similarly let Z be the same change of basis applied to X. Let n be the number of training examples, ¢ be the number of test examples, d be the number of features, and k be the number of features after the change of basis from X to Z. What is the cost in O() notation of the following operations in terms of n, d, ¢, and k? (a) Fitting an L2-regularized least squares model on the training data {X,y} and then apply- ing it to the test data X, §=Xw, where w=(XTX+A)\"XTy. (b) Performing the same two operations under a change of basis (you can assume that forming each element z;; of Z costs O(1), and forming an element of Z has the same cost), 9=2Zw, where w=(2TZ+A)\"'Z7y. (c) Computing the same prediction using the “other” normal equations, 9=2Zw, where w=ZT(ZZT + ) ly.","libVersion":"0.2.1","langs":"eng"}