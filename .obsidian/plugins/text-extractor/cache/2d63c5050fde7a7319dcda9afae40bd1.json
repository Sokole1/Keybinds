{"path":".obsidian/plugins/text-extractor/cache/2d63c5050fde7a7319dcda9afae40bd1.json","text":"CPSC 320: Memoization and Dynamic Programming II Solutions ∗ 1 Memoization: If I Had a Nickel for Every Time I Computed That Here you’ll use a technique called memoization to improve the runtime of the recursive brute force algorithm for making change. Memoization avoids making a recursive call on any subproblem more than once, by using an array to store solutions to subproblems when they are ﬁrst computed. Subsequent recursive calls are then avoided by instead looking up the solution in the array. Memoization is useful when the total number of diﬀerent subproblems is polynomial in the input size. 1. Rewrite Brute-Force-Change, this time storing—which we call \"memoizing\", as in \"take a memo about that\"—each solution as you compute it so that you never compute any solution more than once. SOLUTION: function Memo-Change(n) create a new array Soln[1..n] for i from 1 to n do Soln[i] ← −1 ▷ or any other \"ﬂag\" value return Memo-Change-Helper(n) function Memo-Change-Helper(i) if i < 0 then return inﬁnity else if i = 0 then return 0 else if i > 0 then if Soln[i] == −1 then Soln[i] ← the minimum of: Memo-Change-Helper(i − 25) + 1, Memo-Change-Helper(i − 10) + 1, Memo-Change-Helper(i − 1) + 1. return Soln[i] ∗Copyright Notice: UBC retains the rights to this document. You may not distribute this document without permission. 1 2. We want to analyze the runtime of Memo-Change. In what follows, we’ll refer back to this illustra- tion of two levels of recursive calls for Memo-Change-Helper. How much time is needed by a call to Memo-Change-Helper, not counting the time for recursive calls? That is, how much time is needed at each node of a recursion tree such as the one above? (Note: this is similar to the analysis we did of QuickSort’s recursion tree where we labelled the cost of a node (call) without counting the cost of subtrees (recursive calls). Here, however, we won’t sum the work per level.) SOLUTION: Θ(1) time is needed, to check which case of the If statement applies, the time to return the result, and, if in the third case when Soln[n] is −1, the time to take the min of three values. 3. Which nodes at level two of the above recursion tree are leaves, that is, have no children (corresponding to further recursive calls) at level three? Assume that we draw recursion trees with the ﬁrst recursive call on the left. SOLUTION: The leaves are the node labeled 46 that is in the middle subtree of the root, as well as nodes labeled 55 and 70 in the right subtree of the root. For example, since a node labeled 55 appears further to the left, Soln[55] is no longer equal to −1, and no recursive call is made. 4. Give an upper bound on the number of internal nodes of the recursion tree on input n. SOLUTION: There are at most n internal nodes, since each node is labeled by a distinct number between 1 and n. 5. Give a big-O upper bound on the number of leaves of the recursion tree on input n. SOLUTION: Each internal node can have at most three children that are leaves. So, there are O(n) leaves. 6. Using the work done so far, give a big-O bound on the run-time of algorithm Memo-Change(n). SOLUTION: The recursion tree has O(n) nodes, and the time per node is O(1). So the total time is O(n). 2 2 Dynamic programming: Growing from the leaves The recursive technique from the previous part is called memoization. Turning it into dynamic programming requires avoiding recursion by changing the order in which we consider the subproblems. Here again is the recurrence for the smallest number of coins needed to make n cents in change, renamed to Soln: Soln[i] = inﬁnity, for i < 0 Soln[0] = 0, Soln[i] = 1 + min{Soln[i − 25], Soln[i − 10], Soln[i − 1]} otherwise. 1. Which entries of the Soln array need to be ﬁlled in before we’re ready to compute the value for Soln[i]? SOLUTION: We need Soln[i − 25], Soln[i − 10], and Soln[i − 1] (assuming that i > 25). 2. Give a simple order in which we could compute the entries of Soln so that all previous entries needed are already computed by the time we want to compute a new entry’s value. SOLUTION: We can calulate the entries in increasing order. 3. Take advantage of this ordering to rewrite Brute-Force-Change without using recursion: SOLUTION: function Soln’(i) ▷ Note: It would be handy if Soln had 0 and negative entries. ▷ We use this function Soln’ to simulate this. if i < 0 then return inﬁnity else if i = 0 then return 0 else return Soln[i] function DP-Change(n) if n ≤ 0 then return Soln’(n) else ▷ Assumes n > 0; otherwise, just run Soln’ create a new array Soln[1..n] for i from 1 to n do Soln[i] ← the minimum of Soln’(i − 25) + 1, Soln’(i − 10) + 1, and Soln’(i − 1) + 1 return Soln[n] 3 4. Assume that you have already run algorithm Memo-Change(n) or DP-Change(n) to compute the array Soln[1..n], and also have access to the Soln’ function above. Write an algorithm that uses the values in the Soln array to return the number of coins of each type that are needed to make change with the minimum number of coins. SOLUTION: function Calculate-Change(n) NumQuarters ← 0; NumDimes ← 0; NumPennies ← 0 NumCoins ← Soln[n] while n > 0 do if Soln’(n − 25) == NumCoins −1 then NumQuarters ← NumQuarters + 1 n ← n − 25 else if Soln’(n − 10) == NumCoins −1 then NumDimes ← NumDimes + 1 n ← n − 10 else NumPennies ← NumPennies + 1 n ← n − 1 return \"Use\" NumQuarter \"quarters,\" NumDimes \"dimes and\" NumPennies \"pennies.\" 5. Both Memo-Change and DP-Change run in the same asymptotic time. Asymptotically in terms of n, how much memory do these algorithms use? SOLUTION: They both store an entry in Soln for each value from 1 to n. Assuming each entry takes one \"unit\" of memory, that’s O(n) memory. 6. Imagine that you only want the number of coins returned from Brute-Force-Change, and don’t need to actually calculate change. For the DP-Change algorithm, how much of the Soln array do you really need at one time? If you take advantage of this, how much memory does the algorithm use, asymptotically? SOLUTION: In DP-Change, we refer back to only the last 25 entries when computing Soln[i]. So, we could keep a record of only those most recent 25 entries and update this record (discarding the oldest entry) each time we compute a new entry. A queue data structure provides a handy way to implement this. With this implementation, we use a constant number of \"units\" of memory: O(1). 4","libVersion":"0.2.1","langs":""}