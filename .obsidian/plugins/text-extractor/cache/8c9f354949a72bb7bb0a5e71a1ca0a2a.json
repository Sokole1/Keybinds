{"path":".obsidian/plugins/text-extractor/cache/8c9f354949a72bb7bb0a5e71a1ca0a2a.json","text":"[2.6] [6 points| In the textbook where this data came from (Johnson and Albert, “Ordinal Data Modeling”), they suggest using an independent hyper-prior over m and k of the form p(m) o« m (1 —m)*07L p(k) o< 1/(1 + k)2 The hyper-prior over m is biased towards low values (since we expect the cancer to be rare) but not particularly strong, while the prior over k is similar to what is called a “Jeffreys prior” over scale variables (which would satisfy a particular definition of being an “uninformative prior”). In the pooled data model, find the value of @ and 3 that optimize the marginal likelihood with this hyper-prior (or equivalently, optimize the log of the marginal likelihood with the log of this prior as the regularizer). Up to one decimal place, what are the optimal values of @ and 3 under this hyper-prior? 7 What values of m and k does this correspond to choosing? Hand in your code for computing the objective function that is being optimized. Hint: It may be helpful to parameterize the beta distribution in terms of m = a/(a+ ) (the proportion of 1s) and k = (a+ B) (the “strength” of our belief in this ratio).? Try setting m to the MLE value of 6 and varying k.","libVersion":"0.2.1","langs":"eng"}