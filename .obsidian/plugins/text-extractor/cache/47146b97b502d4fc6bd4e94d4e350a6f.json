{"path":".obsidian/plugins/text-extractor/cache/47146b97b502d4fc6bd4e94d4e350a6f.json","text":"highly structured: the colours each roughly follow a Gauslan distribution plus some noisy samples. Since we have an idea of what the features look like for each class, we might consider classifying inputs z using a generative classifier. In particular, we are going to use Bayes rule to write pzly=c0) ply=c|O) —cl|lz @ =221Y=Y) PY=CcIY) p(y=clz,0) 2@ 0) . where © represents the parameters of our model. To classify a new example Z, we get §= argmax p(y=c|Z6)= argmax p(y=c|O)p(Z|y=c,0)= argmax mN(Z| pe,2c), ce{1,2,....k} ce{1,2,....k} ce{1,2,....k} where we’ve assumed that y | © ~ Categorical(m,...,mx), and z ~ (y = ¢) ~ N(¢, X¢); the notation N(z | u, E) means the density of N'(p, X) evaluated at z. Recall that the maximum likelihood estimate for . is simply n./n, where n, = 31 1(y® = ¢) is the number of data points in class c. Given a dataset (X,y), the MLE for the mean and covarance parameters is then arg max Hry<,> .N‘(z(l) [y, Byo) s bk Bse Bk 1) “ : T i = arg minz (log ‘Eym‘ + (z(l) - ;Ly(()) )];(%) (z(l) - ;Lym)) i=1 L . T . = arg minz Z (log || + (x“) - u,c) »t (z“) - y,c>) . e=1 iyl =c In class, we discussed the general GDA/QDA model, which allows any value for the p. and .. The objective above then separates for the different ¢, and the MLE becomes just the per-class MLE. We also discussed linear discriminant analysis (LDA), which enforces that all the covariance matrices agree, 3. = X. In this case the classifier becomes linear, with 3 corresponding to a “pooled covariance.”","libVersion":"0.2.1","langs":"eng"}