{"path":".obsidian/plugins/text-extractor/cache/bce4365f8c84cd1e45d94269cacb6ee5.json","text":"Math 318 Assignment 9: Due April 6 at 5pm on Canvas I. Problems to be handed in: 1. In each of (a,c,d), determine whether or not the given Markov chain is irreducible, and identify each state as recurrent or transient, and as periodic or aperiodic. (a) The Markov chain with transition matrix: P = 0 1 2 3 4 5 0 1 2 0 0 0 1 2 0 1 0 0 1 2 1 2 0 0 2 0 1 0 0 0 0 3 0 0 0 0 1 0 4 0 0 0 0 0 1 5 0 0 0 2 3 0 1 3 (b) For the Markov chain of part (a), suppose the current state is 5. What is the probability that it will be in state 5 after 4 steps? (c) The simple symmetric random walk on Z d (answer for each d ≥ 1). (d) The branching process with Bin(3, 1 2 ) oﬀspring distribution. (Recall the deﬁnition given in class, or see Section 4.7.) 2. Suppose we have two urns and 2d balls, of which d are black and d are white. Initially, d of the balls are placed in urn 1, and the remainder of the balls are placed in urn 2. At each trial a ball is chosen at random from each of the urns, and the two balls are put back in the opposite urns. Let X0 denote the number of black balls initially in urn 1 and, for n ≥ 1, let Xn denote the number of black balls in urn 1 after the nth trial. Find the transition matrix of the Markov chain (Xn)n≥0. 3. Consider a climate where each day is either rainy or sunny. Suppose that on average only one out of every four rainy days is followed by a sunny day, whereas ﬁve out of six sunny days are followed by a rainy day. View this as a 2-state Markov chain and write down the transition matrix. Using its stationary distribution, determine the long run proportion of sunny days. 4. Smith drives a taxi that serves the city and the airport. A trip that originates in the city has a destination in the city with probability 0.9, and has the airport as destination with probability 0.1. A trip that originates in the airport always goes to the city. Smith makes an average proﬁt of $8 for trips that remain in the city, and an average proﬁt of $12 for trips that involve the airport. What is his overall average proﬁt per trip? View this as a 2-state Markov chain where Xn denotes Smith’s location (city or airport) after his nth trip. Consider, e.g., what fraction of trips originate in the city in the long run, and what fraction of all trips are trips from the city to the airport. 5. Recall the Ehrenfest chain from class (or see pp. X.252-253 or XI.240). Now we consider a lazy version of this chain, in which half the time the selected ball is not moved. Rather than n balls in two urns, we consider n coins, each showing either heads (H) or tails (T ). At each time step, one of the coins is chosen uniformly at random and then ﬂipped, so that the coin now has probability 1 2 of being either H or T . The state of the chain is the number of heads among the n coins. We will call this the “Ehrenfest coin chain.” For i = 0, 1, . . . , n, the Ehrenfest coin chain has transition probabilities Pii = 1 2 , Pi,i−1 = i 2n , Pi,i+1 = n − i 2n . Guess the stationary distribution and verify that your guess is correct. In this problem, we use Python to simulate the lazy Ehrenfest coin chain. (a) In Python, write a function nextStepEhr(X, M) which simulates the ﬁrst step of the (lazy) Ehrenfest coin chain started from the state in which X coins are heads and M − X coins are tails. Here M ∈ {1, 2, 3, . . .} and X ∈ {0, 1, . . . , M }. The function should return a value Y equal to the number of heads in the chain at time 1. One way to generate Y is to take independent variables U uniformly distributed on {0, 1} and V uniformly distributed on [0, 1], and let Y =    X if U = 0; X − 1 if U = 1 and V ≤ X/M ; X + 1 if U = 1 and V > X/M. (b) Simulate the stationary distribution of the coin chain with M = 1000 coins via Markov Chain Monte Carlo. To do this, start the chain in state 0 (all coins tails), and run it 10000 steps using nextStepEhr. After this many steps, the chain is “approximately stationary,” so that at each step from then on, the location of the chain approximately follows the stationary distribution. After this “burn-in,” run the chain for 60000 more time steps. Once you’ve done this, compute the proportion of time that the chain has spent in each of the states 0, 1, . . . , 1000 in the steps it took after the burn-in. Create a bar graph of these proportions. Submit your code and your plot. (c) Write a function called matrixEhr(M ), which generates the transition matrix for the (lazy) Ehrenfest chain with M coins. More speciﬁcally, the function returns an (M + 1) × (M + 1) matrix A such that A(i, j) = P(Xn+1 = j − 1 | Xn = i − 1). (Note the −1 terms on the right-hand side; they are present because the states of the chain are {0, 1, . . . , M } and the matrix is indexed by A(i, j) with 1 ≤ i, j ≤ M + 1.) Now let A denote the transition matrix for the chain with 20 coins, and consider the initial distribution µ = (1, 0, 0, . . . , 0) (there are 20 zero components). On a 3-d plot, show 0, 1, . . . , 20 on the x-axis, k = 1, . . . , 60 on the y-axis and µA k(x) on the z-axis. In order to do so, construct a matrix F such that the i-th row of F is the row vector µA i. Do the same with µ replaced by ν = (1/2, 0, . . . , 0, 1/2). Submit your code and your plots. In order to obtain more informative images, you may want to manually rotate the graph and use a screen capture tool from your computer rather than using the regular Python command to save pictures. II. Required problems but not to be handed in: The topics on Markov chains have few problems to be handed in for marking. It is essential that the following problems on Markov chains be done before the ﬁnal exam: A. For the lazy Ehrenfest coin chain of #5, guess the stationary distribution and verify that your guess is correct by checking that πiPij = πjPji. Compare your plot in #5(b). B. Chapter 4: #20, 64, 67 [for (f), it is easiest to verify that πiPij = πjPji], 70, 76 [168]. III. Recommended problems: These provide additional practice but are not to be handed in. Chapter 4: #1*, 16*, 18[5/9, .44440], 32*, 35[12/37,6/37,4/37,3/37,12/37], 54. Quote of the week: It is seen in this essay that the theory of probabilities is at bottom only common sense reduced to calculus; it makes us appreciate with exactitude that which exact minds feel by a sort of instinct without being able ofttimes to give a reason for it. It leaves no arbitrariness in the choice of opinions and sides to be taken; and by its use can always be determined the most advantageous choice. Thereby it supplements most happily the ignorance and the weakness of the human mind. If we consider the analytical methods to which this theory has given birth; the truth of the principles which serve as a basis; the ﬁne and delicate logic which their employment in the solution of problems requires; the establishments of public utility which rest upon it; the extension which it has received and which it can still receive by its application to the most important questions of natural philosophy and the moral science; if we consider again that, even in the things which cannot be submitted to calculus, it gives the surest hints which can guide us in our judgments, and that it teaches us to avoid the illusions which ofttimes confuse us, then we shall see that there is no science more worthy of our meditations, and that no more useful one could be incorporated in the system of public instruction. Pierre Simon Laplace in A Philosophical Essay on Probabilities","libVersion":"0.2.1","langs":""}