{"path":".obsidian/plugins/text-extractor/cache/ee2b0811e4f10aec280ad33ba5dfd28d.json","text":"CPSC 320 2023W1: Tutorial 5 Solutions 1 A spanning algorithm Let G = (V, E) be a connected, undirected graph with n ≥ 2 nodes and m weighted edges, where w(e) denotes the weight of edge e. The following algorithm is similar but not identical to Kruskal’s minimum spanning tree algorithm (if you have not read that yet, you should still be able to complete these problems). procedure Spanning(G = (V, E), w()) G′ = (V, E′) where E′ = ∅ ▷ initially there are no edges in the output produced while G′ is not connected do E-new = ∅ for each connected component C of G′ = (V, E′) do choose any edge e = (u, v) ∈ E of minimum weight w(e) that connects a node u in C to a node v that is not in C E-new = E-new ∪{e} E′ = E′ ∪ E-new ▷ edges in E-new are added to the output return G′ = (V, E′) 1. For the following graph, when the edge weights are all 1, describe edge choices in the for loop of the ﬁrst iteration of the while loop, which ensure that the algorithm halts after that ﬁrst iteration. SOLUTION: In the ﬁrst iteration of the while loop, each node is initially in its own connected component. In the for loop, let the connected component containing node i choose the edge (i, i + 1), for 1 ≤ i ≤ 7, and the component containing node 8 chooses the edge (7, 8). Then when the for loop completes, all edges of E are in E-new, and therefore in E′. So the graph G = (V, E′) is connected at the end of the ﬁrst iteration of the while loop and the algorithm halts. 2. For the same graph above, describe alternative edge choices in the ﬁrst iteration of the while loop, that result in more than one iteration of the while loop. SOLUTION: Let the connected component containing node i choose the edge (i, i + 1) if i is odd, and choose (i, i − 1) if i is even. Then, at the end of the ﬁrst iteration of the while loop, the sets E-new and E′ are {(1, 2), (3, 4), (5, 6), (7, 8)}. So the resulting graph has four connected components and the algorithm needs more iterations of the while loop. 3. Consider the“line” graph with nodes 1,2, ...n and edges (1, 2), (2, 3), ..., (n − 1, n). On this graph, how many iterations of the while loop will be executed in the worst case? 1 SOLUTION: If n is a power of 2, then in the worst case the components after the ﬁrst iteration each have two nodes, because the chosen edges are {(1, 2), (3, 4), ..., (n−1, n)}. After two iterations the components have four nodes, with the new edges being {(2, 3), (6, 7), ..., (n − 2, n − 1)}. Con- tinuing in this way, after i iteration there are 2i nodes in each component. So log2 n = Θ(log n) iterations of the while loop are needed. More generally, when n is not necessarily a power of 2, the number of components after the ith iteration is at least ⌊n/2i⌋, and again Θ(log n) iterations are needed. This is the worst case for this graph, because the number of connected components must reduce by at least a factor of 2 on each iteration of the while loop, as each newly-added edge “merges” two previously unconnected components. So the number of iterations must be O(log n). (As is usual in this class, we ignore constants, using our asymptotic analysis notation. Ignoring ﬂoors and ceilings by assuming that n is a power of two gives us the correct bounds.) 4. For the same line graph as in the previous part, how many iterations of the while loop will be executed in the best case? SOLUTION: In the best case, only one iteration of the while loop is needed; this happens when the chosen edges in the ﬁrst iteration are all edges in the graph. 5. Provide an example of a graph G and weight function w() on which the algorithm may not produce a tree. SOLUTION: Our example graph has three nodes, 1,2, and 3, and edges (1, 2), (2, 3), and (3, 1) all of which have weight 1. If in the ﬁrst iteration, the connected component containing node 1 picks edge (1, 2), the connected component containing node 2 picks the edge (2, 3), and the connected component containing node 3 picks the edge (3, 1), then the algorithm will produce the original graph G, which is has a cycle and so is not a tree. 2 2 Knapsack with Structured Weights: Part 2 Let’s continue with the Knapsack problem we saw in Tutorial 5. A problem instance is a set of n items, numbered 1, ..., n. Each item i has a positive weight wi > 0 and a positive value vi > 0. Furthermore, we’re given an overall weight capacity C. The problem is to select a subset S ⊆ {1, ..., n} that maximizes the total value of S, but keeps the total weight below C. Formally, we want to maximize V (S) = ∑ i∈S vi, subject to ∑ i∈S wi ≤ C. We’re considering the special case of the problem where the capacity as C is 1, and restrict the weights to be either 1/2, 1/4, 1/8, or 1/16. We showed last time that if we sort the 1/16-weight items in decreasing order of value, and then pair up the items in sequence (i.e. the 1st and 2nd items form a pair, then the 3rd and 4th items, then the 5th and 6th, etc.). then there is an optimal solution that uses that uses the c highest-valued pairs, for some c. Now here’s the key idea of our greedy algorithm. Given an instance I of the problem, create a new instance I ′ as follows. Initially I ′ = I. Sort the 1/16-weight items in decreasing order of value, and pair them up. Now, for each pair of items (i, j) delete the items from I ′ and replace them with a new item whose weight is wi + wj and whose value is vi + vj. Instance I ′ has no 1/16-weight items. There’s a natural correspondence between solutions for I and I ′, where each ”paired” item in a solution S′ for I ′ is replaced by the two individual items in the corresponding solution S for I, and vice versa. Note also that corresponding solutions S and S′ have the same total value, i.e., V (S) = V (S′) Use this to show that: 1. The value of an optimal solution for instance I is less than or equal to the value of an optimal solution for instance I ′. SOLUTION: Let S be an optimal solution for instance I and let S′ be the corresponding solution for I ′. Then V (S) = V (S′), and so the optimal solution for I ′ must have value at least V (S). 2. The value of an optimal solution for instance I ′ is less than or equal to the value of an optimal solution for instance I. SOLUTION: This follows by similar reasoning to part (a). Given an original problem instance, we’ve seen how to eliminate the 1/16-weight items to create an equivalent problem without 1/16-weight instances. 3. How do we now solve the resulting problem instance that has no 1/16-weight items? SOLUTION: The exact same reasoning allows us to create an equivalent problem instance without 1/8-weight items! Once the 1/8-weight items are gone, we can eliminate the 1/4-weight items. Then, we solve the problem simply by picking the top two 1/2-weight items. This is the eﬃcient greedy algorithm for this problem, and we’ve already proven that it is optimal using an exchange arguments approach! 3","libVersion":"0.2.1","langs":""}