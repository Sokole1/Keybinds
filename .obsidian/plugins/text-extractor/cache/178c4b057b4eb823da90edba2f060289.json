{"path":".obsidian/plugins/text-extractor/cache/178c4b057b4eb823da90edba2f060289.json","text":"CPSC 340: Machine Learning and Data Mining Robust Regression Last Time: Gradient Descent and Convexity • We introduced gradient descent: – Uses sequence of iterations of the form: – Converges to a stationary point where ∇ f(w) = 0 under weak conditions. • Will be a global minimum if the function is convex. • We discussed ways to show a function is convex: – Second derivative is non-negative (1D functions). – Closed under addition, multiplication by non-negative, maximization. – Any [squared-]norm is convex. – Composition of convex function with linear function is convex. Least Squares with Outliers • Height vs. weight of NBA players: https://www.youtube.com/watch?v=i4eYWl1ewFo Least Squares with Outliers • Consider least squares problem with outliers in ‘y’: http://setosa.io/ev/ordinary-least-squares-regression Least Squares with Outliers • Consider least squares problem with outliers in ‘y’: • Least squares is very sensitive to outliers. Least Squares with Outliers • Squaring error shrinks small errors, and magnifies large errors: • Outliers (large error) influence ‘w’ much more than other points. https://seeing-theory.brown.edu/regression-analysis/index.html Least Squares with Outliers • Squaring error shrinks small errors, and magnifies large errors: • Outliers (large error) influence ‘w’ much more than other points. – Good if outlier means ‘plane crashes’, bad if it means ‘data entry error’. Robust Regression • Robust regression objectives focus less on large errors (outliers). • For example, use absolute error instead of squared error: • Now decreasing ‘small’ and ‘large’ errors is equally important. • Instead of minimizing L2-norm, minimizes L1-norm of residuals: Least Squares with Outliers • Absolute error is more robust to outliers: Regression with the L1-Norm • Unfortunately, minimizing the absolute error is harder. – We don’t have “normal equations” for minimizing the L1-norm. – Absolute value is non-differentiable at 0. – Generally, harder to minimize non-smooth than smooth functions. • Unlike smooth functions, the gradient may not get smaller near a minimizer. – To apply gradient descent, we’ll use a smooth approximation. Smooth Approximations to the L1-Norm • There are differentiable approximations to absolute value. – Common example is Huber loss: – Note that ‘h’ is differentiable: h’(ε) = ε and h’(-ε) = -ε. – This ‘f’ is convex but setting 𝛻f(x) = 0 does not give a linear system. • But we can minimize the Huber loss using gradient descent. Very Robust Regression • Non-convex errors can be very robust: – Not influenced by outlier groups. Very Robust Regression • Non-convex errors can be very robust: – Not influenced by outlier groups. – But non-convex, so finding global minimum is hard. – Absolute value is “most robust” convex loss function. Very Robust RegressionMotivation for Modeling Outliers https://xkcd.com/937/ • What if the “outlier” is the only non-male person in your dataset? – Do you want to be robust to the outlier? – Will the model work for everyone if it has good average case performance? Accuracy vs. Fairness Trade-Off? • Improving test error might need to make fairness worse? – If you chase you outliers you might worsen generalization. – If you do not chase the outliers you might worsen fairness. • Recent related paper: https://www.jmlr.org/papers/v23/21-1427.html “Brittle” Regression • What if you really care about getting the outliers right? – You want to minimize size of worst error across examples. • For example, if in worst case the plane can crash or you perform badly on a group. • In this case you could use something like the infinity-norm: • Very sensitive to outliers (“brittle”), but minimizes highest error. – Different than previous errors, which were all some sort of average. Log-Sum-Exp Function • As with the L1-norm, the L∞-norm is convex but non-smooth: – We can again use a smooth approximation and fit it with gradient descent. • Convex and smooth approximation to max function is log-sum-exp function: – We will use this several times in the course. – Notation alert: when I write “log” I always mean “natural” logarithm: log(e) = 1. • Intuition behind log-sum-exp: – ∑𝑖 exp 𝑧𝑖 ≈ max 𝑖 exp(𝑧𝑖), as largest element is magnified exponentially (if no ties). – And notice that log(exp(zi)) = zi. Log-Sum-Exp Function Examples • Log-sum-exp function as smooth approximation to max: • If there aren’t “close” values, it’s really close to the max. • Comparison of max{0,w} and smooth log(exp(0) + exp(w)): Part 3 Key Ideas: Linear Models, Least Squares • Focus of Part 3 is linear models: – Supervised learning where prediction is linear combination of features: • Regression: – Target yi is numerical, testing ( ො𝑦i == yi) doesn’t make sense. • Squared error: – Can find optimal ‘w’ by solving “normal equations”. Part 3 Key Ideas: Change of Basis, Gradient Descent • Change of basis: replaces features xi with non-linear transforms zi: – Add a bias variable (feature that is always one). – Polynomial basis. – Other basis functions (logarithms, trigonometric functions, etc.). • For large ‘d’ we often use gradient descent: – Iterations only cost O(nd). – Converges to a critical point of a smooth function. – For convex functions, it finds a global optimum. Part 3 Key Ideas: Error Functions, Smoothing • Error functions: • Squared error is sensitive to outliers. • Absolute (L1) error and Huber error are more robust to outliers. • Brittle (L∞) error is more sensitive to outliers. • L1 and L∞ error functions are convex but non-differentiable: • Finding ‘w’ minimizing these errors is harder than squared error. • We can approximate these with differentiable functions: • L1 can be approximated with Huber. • L∞ can be approximated with log-sum-exp. • With these smooth (convex) approximations, we can find global optimum with gradient descent. End of Scope for Midterm Material. (we are not done Part 3, but nothing after this point will be tested on the midterm) Finding the “True” Model • To measure performance we have focused on minimize test error. – This is good if our goal is to predict on well on new IID data – But this is a weird way to do science! • “It's true there's been a lot of work on trying to apply statistical models to various linguistic problems. I think there have been some successes, but a lot of failures. There is a notion of success ... which I think is novel in the history of science. It interprets success as approximating unanalyzed data.” Noam Chomsky. Finding the “True” Model • To measure performance we have focused on minimize test error. – This is good if our goal is to predict on well on new IID data – But this is a weird way to do science! • We normally want to design simple models that explain the world. – Might work even if new data is not IID! – Next topic: finding the“true” model. • Hint: it is hard unless things are simple! https://www.discovermagazine.com/the-sciences/the-5-most-important-scientific-equations-of-all-time Finding the “True” Model • Consider a simple case of trying to find the “true” model? – We believe that yi really is a polynomial function of xi. – We want to find the degree of the polynomial ‘p’. • Should we choose the ‘p’ with the lowest training error? – No, this will pick a ‘p’ that is too large. (training error always decreases as you increase ‘p’) http://www.cs.ubc.ca/~arnaud/stat535/slides5_revised.pdf Finding the “True” Model • Consider a simple case of trying to find the “true” model? – We believe that yi really is a polynomial function of xi. – We want to find the degree of the polynomial ‘p’. • Should we choose the ‘p’ with the lowest validation error? – This will also often choose a ‘p’ that is too large (due to optimization bias). – Consider a case where the true model has p=2 (quadratic function). • We fit a quadratic function yi = 2xi 2 – 5, and a cubic function yi = 0.00001xi 3 + 2xi 2 - 5. • Cubic is wrong, but by chance might get a lower error on a particular validation set. – If we try many models, there are more “chances” to randomly get a lower validation error. Complexity Penalties • There are a lot of “scores” people use to find the “true” model. • Basic idea behind them: put a penalty on the model complexity. – Want to fit the data and have a simple model. • For example, minimize training error plus the degree of polynomial. – If we use p=4, use “training error plus 4” as error. • If two ‘p’ values have similar error, this prefers the smaller ‘p’. Choosing Degree of Polynomial Basis • How can we optimize this score? – Form Z0, solve for ‘v’, compute score(0) = ½||Z0v – y||2 + 0. – Form Z1, solve for ‘v’, compute score(1) = ½||Z1v – y||2 + 1. – Form Z2, solve for ‘v’, compute score(2) = ½||Z2v – y||2 + 2. – Form Z3, solve for ‘v’, compute score(3) = ½||Z3v – y||2 + 3. – Choose the degree with the lowest score. • “You need to decrease training error by at least 1 to increase degree by 1.” Information Criteria • There are many scores, usually with the form: – The value ‘k’ is the “number of estimated parameters” (“degrees of freedom”). • For polynomial basis, we have k = (p+1). – The parameter λ > 0 controls how strong we penalize complexity. • “You need to decrease the training error by least λ to increase ‘k’ by 1”. • Using (λ = 1) is called Akaike information criterion (AIC). • Other choices of λ (not necessarily integer) give other criteria: – Mallow’s Cp. – Adjusted R2. – ANOVA-based model selection. Choosing Degree of Polynomial Basis • How can we optimize this score in terms of ‘p’? – Form Z0, solve for ‘v’, compute score(0) = ½||Z0v – y||2 + λ. – Form Z1, solve for ‘v’, compute score(1) = ½||Z1v – y||2 + 2λ. – Form Z2, solve for ‘v’, compute score(2) = ½||Z2v – y||2 + 3λ. – Form Z3, solve for ‘v’, compute score(3) = ½||Z3v – y||2 + 4λ. – So we need to improve by “at least λ” to justify increasing degree. • If λ is big, we’ll choose a small degree. If λ is small, we’ll choose a large degree. Summary • Outliers in ‘y’ can cause problem for least squares. • Robust regression using L1-norm is less sensitive to outliers. • Brittle regression using Linf-norm is more sensitive to outliers. • Smooth approximations: – Let us apply gradient descent to non-smooth functions. – Huber loss is a smooth approximation to absolute value. – Log-Sum-Exp is a smooth approximation to maximum. • Information criteria are scores that penalize number of parameters. – When we want to find the “true” model. • Next time: – Can we find the “true” features? Random Sample Consensus (RANSAC) • In computer vision, a widely-used generic framework for robust fitting is random sample consensus (RANSAC). • This is designed for the scenario where: – You have a large number of outliers. – Majority of points are “inliers”: it’s really easy to get low error on them. https://en.wikipedia.org/wiki/Random_sample_consensus Random Sample Consensus (RANSAC) • RANSAC: – Sample a small number of training examples. • Minimum number needed to fit the model. • For linear regression with 1 feature, just 2 examples. – Fit the model based on the samples. • Fit a line to these 2 points. • With ‘d’ features, you’ll need ‘d+1’ examples. – Test how many points are fit well based on the model. – Repeat until we find a model that fits at least the expected number of “inliers”. • You might then re-fit based on the estimated “inliers”. https://en.wikipedia.org/wiki/Random_sample_consensus Log-Sum-Exp for Brittle Regression • To use log-sum-exp for brittle regression: Log-Sum-Exp Numerical Trick • Numerical problem with log-sum-exp is that exp(zi) might overflow. – For example, exp(100) has more than 40 digits. • Implementation ‘trick’: Gradient Descent for Non-Smooth? • “You are unlikely to land on a non-smooth point, so gradient descent should work for non-smooth problems?” – Consider just trying to minimize the absolute value function: – Norm(gradient) is constant when not at 0, so unless you are lucky enough to hit exactly 0, you will just bounce back and forth forever. – We didn’t have this problem for smooth functions, since the gradient gets smaller as you approach a minimizer. – You could fix this problem by making the step-size slowly go to zero, but you need to do this carefully to make it work, and the algorithm gets much slower. Gradient Descent for Non-Smooth? • Counter-example from Bertsekas’ “Nonlinear Programming” where gradient descent for a non-smooth convex problem does not converge to a minimum.","libVersion":"0.2.1","langs":""}