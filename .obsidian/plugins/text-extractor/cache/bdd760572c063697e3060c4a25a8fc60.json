{"path":".obsidian/plugins/text-extractor/cache/bdd760572c063697e3060c4a25a8fc60.json","text":"Selected Solutions to Exercises - Chapter 4 CPSC 302 Fall 2023 Question 4.5 Since Ax = b, we have that T Ax = T b, and because T A = LU with L and U given, all we need to do is ﬁnd x from LU x = T b. The steps of the algorithm are, then: ﬁrst, form the matrix-vector product d = T b, which is O(n2) ﬂops, and then solve LU x = d by forward and backward substitutions, which take O(n2) ﬂops each. Question 4.10 Given A = B − BT , it is immediate to see that all diagonal elements of A are zero. (Try a 2 × 2 or 3 × 3 example to convince yourself.) Thus, immediately upon the ﬁrst step of Gaussian elimination we encounter a zero pivot, and pivoting must be applied. (A is known as a skew-symmetric matrix: AT = −A.) Question 4.14 (a) Let G = U ΣV T . Then A = GG T = V ΣT ΣV T . We just formed an eigendecomposition or an SVD for A (the two are equivalent because A is SPD), and the largest singular value here is σ2 1. Recall that the 2-norm of a matrix is its largest singular value, and this gives us the desired result. (b) From (a) with a small additional step it follows that κ2(A) = κ 2 2(G). (c) To be clear, the above does not fully establish that no pivoting is required. But it shows that there is no growth in the entries of the Cholesky factors. Fully showing that there is no need for pivoting is slightly subtle and requires arguments of the sort that appear on page 131 in the textbook. There is no need for you to be overly concerned about this. Question 4.18 (a) ∥A∥∞ = a + 2b. (b) The matrix A is obviously symmetric. We are given that λj = a + 2b cos ( πj n+1 ) and since cos α ≥ −1 for all α, it follows that λj ≥ a − 2b. But because A is diagonally dominant and a > 0 we have a > 2b. Therefore λj > 0 for all j and A is SPD. (c) κ2(A) = maxj{λj} minj{λj} = a + 2b cos ( π n+1 ) a − 2b cos ( π n+1 ) . 1","libVersion":"0.2.1","langs":""}