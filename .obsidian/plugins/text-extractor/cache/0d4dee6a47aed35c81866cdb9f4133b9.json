{"path":".obsidian/plugins/text-extractor/cache/0d4dee6a47aed35c81866cdb9f4133b9.json","text":"2 Learning with Weights [5 points]| We often use categorical (or Bernoulli) distributions as parts of more complicated distributions. In these cases we often to need to maximize a weighted log-likelihood of the form 1) =30 1ogp=? 10), = where each v is a non-negative weight for example . Derive the MLE for this model when we use a categorical likelihood with k categories for p(z(?) | 6). You can take as given that f is concave (so that any stationary point is a global optimum). Answer: TODO","libVersion":"0.2.1","langs":"eng"}