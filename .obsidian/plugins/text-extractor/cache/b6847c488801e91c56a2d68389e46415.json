{"path":".obsidian/plugins/text-extractor/cache/b6847c488801e91c56a2d68389e46415.json","text":"CPSC 340 Assignment 3 (Due 2023-10-13 at 11:59pm) Important: Submission Format [5 points] Please make sure to follow the submission instructions posted on the course website. We will deduct marks if the submission format is incorrect, or if you’re not using LATEX and your handwriting is at all diﬃcult to read – at least these 5 points, more for egregious issues. 1 Matrix Notation and Minimizing Quadratics [12 points] 1.1 Converting to Matrix/Vector/Norm Notation [6 points] Using our standard supervised learning notation (X, y, w) express the following functions in terms of vectors, matrices, and norms (there should be no summations or maximums). 1. maxi∈{1,2,...,n} |wT xi − yi|. This is “brittle regression”. 2. ∑n i=1 vi(wT xi − yi) 2 + λ 2 ∑d j=1 w2 j . This is regularized least squares with a weight vi for each training example: Hint: You can use V to denote a diagonal matrix that has the values vi along the diagonal. What does a T V b look like in summation form (for some arbitrary vectors a, b)? 3. (∑n i=1 |wT xi − yi|)2+ 1 2 ∑d j=1 λj|wj|. This is L1-regularized least squares with a diﬀerent regularization strength for each dimension: Hint: You can use Λ to denote a diagonal matrix that has the λj values along the diagonal. Note: you can assume that all the vi and λi values are non-negative. 1.2 Minimizing Quadratic Functions as Linear Systems [6 points] Write ﬁnding a minimizer w of the functions below as a system of linear equations (using vector/matrix notation and simplifying as much as possible). Note that all the functions below are convex, so ﬁnding a w with ∇f (w) = 0 is suﬃcient to minimize the functions – but show your work in getting to this point. 1. f (w) = 1 2 ∥w − v∥2 (projection of v onto real space). 2. f (w) = 1 2 ∥Xw − y∥2 + 1 2 wT Λw (least squares with weighted regularization). 3. f (w) = 1 2 ∑n i=1 vi(wT xi − yi) 2 + λ 2 ∥w − w(0)∥ 2 (weighted least squares shrunk towards non-zero w(0)). Above we assume that v and w(0) are d × 1 vectors, and Λ is a d × d diagonal matrix (with positive entries along the diagonal). You can use V as a diagonal matrix containing the vi values along the diagonal. Hint: Once you convert to vector/matrix notation, you can use the results from class to quickly compute these quantities term-wise. As a spot check, make sure that the dimensions match for all quantities/operations: to do this, you may need to introduce an identity matrix. For example, X T Xw + λw can be re-written as (X T X + λI)w. 1 2 Robust Regression and Gradient Descent [41 points] If you run python main.py 2, it will load a one-dimensional regression dataset that has a non-trivial number of ‘outlier’ data points. These points do not ﬁt the general trend of the rest of the data, and pull the least squares model away from the main downward trend that most data points exhibit: 0.0 0.2 0.4 0.6 0.8 1.0 5 0 5 10 15 20 25 Least Squares Note: we are ﬁtting the regression without an intercept here, just for simplicity of the homework question. In reality one would rarely do this. But here it’s OK because the “true” line passes through the origin (by design). In Q3.1 we’ll address this explicitly. A coding note: when we’re doing math, we always treat y and w as column vectors, i.e. if we’re thinking of them as matrices, then shape n × 1 or d × 1, respectively. This is also what you’d usually do when coding things in, say, Matlab. It is not what’s usually done in Python machine learning code, though: we usually have y.shape == (n,), i.e. a one-dimensional array. Mathematically, these are the same thing, but if you mix between the two, you can really easily get confusing answers: if you add something of shape (n, 1) to something of shape (n,), then the NumPy broadcasting rules give you something of shape (n, n). This is a very unfortunate consequence of the way the broadcasting rules work. If you stick to either one, you generally don’t have to worry about it; we’re assuming shape (n,) here. Note that you can ensure you have something of shape (n,) with the utils.ensure 1d helper, which basically just uses two d array.squeeze(1) (which checks that the axis at index 1, the second one, is length 1 and then removes it). You can go from (n,) to (n, 1) with, for instance, one d array[:, np.newaxis] (which says “give me the whole ﬁrst axis, then add another axis of length 1 in the second position”). 2.1 Weighted Least Squares in One Dimension [8 points] One of the most common variations on least squares is weighted least squares. In this formulation, we have a weight vi for every training example. To ﬁt the model, we minimize the weighted squared error, f (w) = 1 2 n∑ i=1 vi(wT xi − yi)2. 2 In this formulation, the model focuses on making the error small for examples i where vi is high. Similarly, if vi is low then the model allows a larger error. Note: these weights vi (one per training example) are completely diﬀerent from the model parameters wj (one per feature), which, confusingly, we sometimes also call “weights.” The vi are sometimes called sample weights or instance weights to help distinguish them. Complete the model class, WeightedLeastSquares (inside linear models.py), to implement this model. (Note that Q1.2.3 asks you to show how a similar formulation can be solved as a linear system.) Apply this model to the data containing outliers, setting v = 1 for the ﬁrst 400 data points and v = 0.1 for the last 100 data points (which are the outliers). Hand in your code and the updated plot. 2.2 Smooth Approximation to the L1-Norm [8 points] Unfortunately, we typically do not know the identities of the outliers. In situations where we suspect that there are outliers, but we do not know which examples are outliers, it makes sense to use a loss function that is more robust to outliers. In class, we discussed using the sum of absolute values objective, f (w) = n∑ i=1 |wT xi − yi|. This is less sensitive to outliers than least squares, but it is non-diﬀerentiable and harder to optimize. Nevertheless, there are various smooth approximations to the absolute value function that are easy to optimize. One possible approximation is to use the log-sum-exp approximation of the max function1: |r| = max{r, −r} ≈ log(exp(r) + exp(−r)). Using this approximation, we obtain an objective of the form f (w)= n∑ i=1 log (exp(wT xi − yi) + exp(yi − wT xi) ) . which is smooth but less sensitive to outliers than the squared error. Derive the gradient ∇f of this function with respect to w. You should show your work but you do not have to express the ﬁnal result in matrix notation. 2.3 Gradient Descent: Understanding the Code [5 points] Recall gradient descent, a derivative-based optimization algorithm that uses gradients to navigate the param- eter space until a locally optimal parameter is found. In optimizers.py, you will see our implementation of gradient descent, taking the form of a class named GradientDescent. This class has a similar design pattern as PyTorch, a popular diﬀerentiable programming and optimization library. One step of gradient descent is deﬁned as wt+1 = wt − αt∇wf (wt). Look at the methods named get learning rate and step() and break yes(), and answer each of these questions, one sentence per answer: 1. Which variable is equivalent to αt, the step size at iteration t? 2. Which variable is equivalent to ∇wf (wt) the current value of the gradient vector? 3. Which variable is equivalent to wt, the current value of the parameters? 4. What is the method break yes() doing? 1Other possibilities are the Huber loss, or |r| ≈ √r2 + ϵ for some small ϵ. 3 2.4 Robust Regression [20 points] The class LinearModel is like LeastSquares, except that it ﬁts the least squares model using a gradient descent method. If you run python main.py 2.4 you’ll see it produces the same ﬁt as we obtained using the normal equations. The typical input to a gradient method is a function that, given w, returns f (w) and ∇f (w). See fun obj.py for some examples. Note that the fit function of LinearModel also has a numerical check that the gradient code is approximately correct, since implementing gradients is often error-prone.2 An advantage of gradient-based strategies is that they are able to solve problems that do not have closed- form solutions, such as the formulation from the previous section. The class LinearModel has most of the implementation of a gradient-based strategy for ﬁtting the robust regression model under the log-sum-exp approximation. 2.4.1 Implementing the Objective Function [15 points] Optimizing robust regression parameters is the matter of implementing a function object and using an opti- mizer to minimize the function object. The only part missing is the function and gradient calculation inside fun obj.py. Inside fun obj.py, complete RobustRegressionLoss to implement the objective function and gradient based on the smooth approximation to the absolute value function (from the previous section). Hand in your code, as well as the plot obtained using this robust regression approach. 2.4.2 The Learning Curves [5 points] Using the same dataset as the previous sections, produce the plot of “gradient descent learning curves” to compare the performances of GradientDescent and GradientDescentLineSearch for robust regression, where one hundred (100) iterations of gradient descent are on the x-axis and the objective function value corresponding to each iteration is visualized on the y-axis (see gradient descent lecture). Use the default learning rate for GradientDescent. Submit this plot. According to this plot, which optimizer is more “iteration-eﬃcient”? 2Sometimes the numerical gradient checker itself can be wrong. See CPSC 303 for a lot more on numerical diﬀerentiation. 4 3 Linear Regression and Nonlinear Bases In class we discussed ﬁtting a linear regression model by minimizing the squared error. In this question, you will start with a data set where least squares performs poorly. You will then explore how adding a bias variable and using nonlinear (polynomial) bases can drastically improve the performance. You will also explore how the complexity of a basis aﬀects both the training error and the validation error. 3.1 Adding a Bias Variable [8 points] If you run python main.py 3, it will: 1. Load a one-dimensional regression dataset. 2. Fit a least-squares linear regression model. 3. Report the training error. 4. Report the validation error. 5. Draw a ﬁgure showing the training data and what the linear model looks like. Unfortunately, this is an awful model of the data. The average squared training error on the data set is over 7000 (as is the validation error), and the ﬁgure produced by the demo conﬁrms that the predictions are usually nowhere near the training data: 10.0 7.5 5.0 2.5 0.0 2.5 5.0 7.5 10.0 100 50 0 50 100 150 200 Least Squares, no bias The y-intercept of this data is clearly not zero (it looks like it’s closer to 200), so we should expect to improve performance by adding a bias (a.k.a. intercept) variable, so that our model is yi = wT xi + w0. instead of yi = wT xi. In ﬁle linear_models.py, complete the class LeastSquaresBias, that has the same input/model/predict format as the LeastSquares class, but that adds a bias variable (also called an intercept) w0 (also called β in lecture). Hand in your new class, the updated plot, and the updated training/validation error. Hint: recall that adding a bias w0 is equivalent to adding a column of ones to the matrix X. Don’t forget that you need to do the same transformation in the predict function. 5 3.2 Polynomial Basis [10 points] Adding a bias variable improves the prediction substantially, but the model is still problematic because the target seems to be a non-linear function of the input. Complete LeastSquarePoly class, that takes a data vector x (i.e., assuming we only have one feature) and the polynomial order p. The function should perform a least squares ﬁt based on a matrix Z where each of its rows contains the values (xi)j for j = 0 up to p. E.g., LeastSquaresPoly.fit(x,y) with p = 3 should form the matrix Z =      1 x1 (x1) 2 (x1) 3 1 x2 (x2) 2 (x2) 3 ... 1 xn (xn) 2 (xN ) 3      , and ﬁt a least squares model based on it. Submit your code, and a plot showing training and validation error curves for the following values of p: 0, 1, 2, 3, 4, 5, 10, 20, 30, 50, 75, 100. Clearly label your axes, and use a logarithmic scale for y by plt.yscale(\"log\") or similar, so that we can still see what’s going on if there are a few extremely large errors. Explain the eﬀect of p on the training error and on the validation error. NOTE: large values of p may cause numerical instability. Your solution may look diﬀerent from others’ even with the same code depending on the OS and other factors. As long as your training and validation error curves behave as expected, you will not be penalized. Note: you should write the code yourself; don’t use a library like sklearn’s PolynomialFeatures. Note: in addition to the error curves, the code also produces a plot of the ﬁts themselves. This is for your information; you don’t have to submit it. 6 4 Very-Short Answer Questions [24 points] Answer the following questions (in a sentence or two). 1. Suppose that a training example is global outlier, meaning it is really far from all other data points. How is the cluster assignment of this example set by k-means? And how is it set by density-based clustering? 2. Why do need random restarts for k-means but not for density-based clustering? 3. Can hierarchical clustering ﬁnd non-convex clusters? 4. For model-based outlier detection, list an example method and problem with identifying outliers using this method. 5. For graphical-based outlier detection, list an example method and problem with identifying outliers using this method. 6. For supervised outlier detection, list an example method and problem with identifying outliers using this method. 7. If we want to do linear regression with 1 feature, explain why it would or would not make sense to use gradient descent to compute the least squares solution. 8. Why do we typically add a column of 1 values to X when we do linear regression? Should we do this if we’re using decision trees? 9. Why do we need gradient descent for the robust regression problem, as opposed to just using the normal equations? Hint: it is NOT because of the non-diﬀerentiability. Recall that we used gradient descent even after smoothing away the non-diﬀerentiable part of the loss. 10. What is the problem with having too small of a learning rate in gradient descent? What is the problem with having too large of a learning rate in gradient descent? 11. What is the purpose of the log-sum-exp function and how is this related to gradient descent? 12. What type of non-linear transform might be suitable if we had a periodic function? 7","libVersion":"0.2.1","langs":""}