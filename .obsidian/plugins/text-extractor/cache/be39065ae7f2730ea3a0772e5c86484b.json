{"path":".obsidian/plugins/text-extractor/cache/be39065ae7f2730ea3a0772e5c86484b.json","text":"UBC CPSC 340 2019W1 MIDTERM EXAM Oct 17th, 2018 Instructor: Mark Schmidt TIME: 80 minutes We are providing a copy of this exam to help you prepare for the style of questions we may ask during the midterm and ﬁnal. However, the solution ﬁle is meant for you alone and we do not give permission to share these solution ﬁles with anyone. Both distributing solution ﬁles to other people or using solution ﬁles provided to you by other people are considered academic misconduct. Please see UBC’s policy on this topic if you are not familiar with it: http://www.calendar.ubc.ca/vancouver/index.cfm?tree=3,54,111,959 http://www.calendar.ubc.ca/vancouver/index.cfm?tree=3,54,111,960 • Do not open the exam until you are directed to do so. • Once you open the exam, make sure that it contains this cover page plus 8 pages of exam questions. • One letter-size sheet (both sides) of notes is allowed. No other material or accessories may be used. • You may use either pen or pencil, but exams written in pencil may not be eligible for regrading. • Please be prepared to present, upon request, a student card for identiﬁcation. • If you need more space, use the blank page at the end of the exam, and clearly indicate that your work continues there. • Most questions require a short answer. Work eﬃciently and avoid writing lengthy answers. • The exam uses the notation from class (n refers to the number of training examples, d is the number of features, and so on). • If anything is unclear or seems ambiguous, state your assumptions. Question: 1 2 3 4 5 6 7 Total Points: 10 15 6 6 8 6 9 60 Score: CPSC 340 Midterm Exam Question 1. (10 points) (a)6 pts Using the notation from class, give the size of the following quantities in terms of n, d, and t. And in one short sentence, describe what the notation represents in this course. For example, for y you could write “n × 1: label of training example i”. i. xij ii. xi iii. ˆyi iv. ˜yi v. X vi. ˜X (b)4 pts Which of the following methods are examples of supervised learning? Circle all that apply. i. Hierarchical clustering ii. KNN classiﬁcation iii. k-medians iv. Linear regression v. Naive Bayes vi. Outlierness ratio vii. Random forests viii. Robust regression Page 1 of 8 CPSC 340 Midterm Exam Question 2. (15 points) (a)5 pts Which of the following methods are non-parametric? Circle all that apply. i. Random forests with depth-20 random trees ii. k-means clustering using k = log(n). iii. Density-based clustering with ϵ = 0.1, minNeighbours = 10. iv. Density-based clustering with ϵ = 0.1, minNeighbours = log(n). v. Linear regression with degree p = 7 polynomial basis. (b)10 pts Which of the following changes would typically reduce training error? Circle all that apply. Note: for regression and unsupervised models, assume we use the squared training error (squared distance to cluster mean for k-means, and squared prediction error for regression). i. using the fast decision stump ﬁtting method based on sorting, instead of the naive approach ii. increasing k in KNN classiﬁcation iii. increasing the maximum tree depth in a random forest iv. increasing k in k-means clustering v. using a higher degree polynomial basis for linear regression vi. running more iterations of gradient descent when ﬁtting least squares (assuming α is small enough) vii. adding some relevant features to your model viii. adding some irrelevant features to your model ix. switching from the squared error to the absolute error when ﬁtting a linear regression model x. increasing the parameter ϵ in the Huber loss Page 2 of 8 CPSC 340 Midterm Exam Question 3. (6 points) Answer the questions below using 1-2 short sentences. (a)2 pts What is a setting where using a validation set to choose hyper-parameters can lead to overﬁtting? (b)2 pts What is the diﬀerence between using a validation set and using cross-validation? (c)2 pts Consider an ensemble clustering method that generates m diﬀerent bootstraps of the data. It then ﬁts a k-means model (with a random initialization) to each of the boostraps. To form the ﬁnal clustering for example xi, it chooses the yi that is most common across the m clusterings. Would this be an eﬀective or an inneﬀective ensemble method? (Brieﬂy explain.) Page 3 of 8 CPSC 340 Midterm Exam Question 4. (6 points) Answer the questions below using 1-2 short sentences. (a)2 pts Suppose we have a supervised learning problem where we think the examples xi form clusters. To deal with this, we combine our training and test data together and cluster the combined data using k-means. We then add the cluster number as an extra feature, ﬁt our supervised learning model based on the training data, then evaluate it on the test data. What have we done wrong? (b)2 pts We considered ﬁtting decision stumps by ﬁnding the stump that maximizes the number of times ˆyi = yi in the training data. Why do we not try to maximize this quantity when we ﬁt the regression weights w in linear regression models? (c)2 pts We argued that penalizing the L1-norm of the residuals makes linear regression less sen- sitive to outliers. This is also true of the Huber loss, so why did we introduce the Huber loss? Page 4 of 8 CPSC 340 Midterm Exam Question 5. (8 points) Answer the following questions using big-O notation. Your answers may involve n, d, and perhaps additional quantities deﬁned in the question. As an example, (linear) least squares has O(d) parameters, requires O(nd2 + d3) time to train, and requires O(td) time to predict on t test examples. (a)2 pts What is the storage space required for a naive Bayes classiﬁer with binary features and k class labels? (b)2 pts What is the prediction cost for classifying t test examples using a random forest classiﬁer, if each tree has a maximum depth of k and we use m trees? (c)2 pts What is the training time for linear regression with d = 1 using a polynomial basis of degree p? (d)2 pts What is the cost of computing the gradient of the Huber loss function? Recall that the gradient of the Huber loss has the form ∇f (w) = ∑n i=1 h′(wT xi − yi)xi, where it costs O(1) to evaluate h′(ri) for a given scalar ri. Page 5 of 8 CPSC 340 Midterm Exam Question 6. (6 points) Consider the dataset below, which has 10 training examples and 2 features: X =                 0 0 0 0 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1                 , y =                 −1 −1 −1 +1 +1 −1 +1 +1 +1 −1                 . Suppose you want to classify the following test example: ˜xi = [ 1 1 ] . (a)2 pts What value of yi would a 4-nearest neighbour classiﬁer predict for this test example? (b)2 pts If we treated the yi as numerical values, what value of yi would a linear regression model predict on the test example ˜xi if it had the below weights? w = [ 1.5 −2.3 ] (c)2 pts If we ﬁt a decision stump to maximize the classiﬁation accuracy score, what stump would we choose? Page 6 of 8 CPSC 340 Midterm Exam Question 7. (9 points) For this question you may ﬁnd it helpful to use the next page, which is blank. (a)3 pts Consider the following objective, which considers a weighted absolute error with a penalty on the maximum coordinate-wise deviation away from some target value w0 (that has elements w0 1, w0 2, . . . w0 d), f (w) = n∑ i=1 vi|wT xi − yi| + λ max j∈{1,2,...,d} |wj − w0 j |, where λ is a non-negative scalar. Re-write this objective function in matrix and norm notation. You can use V as a diagonal matrix with the (non-negative) elements vi along the diagonal. Make sure your dimensions match. (b)3 pts Consider an L2-regularized least squares objective, with a non-diagonal regularizer, f (w) = 1 2 ∥Xw − y∥2 + 1 2 wT Λw, where Λ is a symmetric matrix. Write down a linear system whose solution gives a sta- tionary point of this objective function. Make sure your dimensions match. (c)3 pts Which of the following functions are convex? Circle all that apply. i. f (w) = ∑n i=1 λiwT xi (where each scalar λi > 0). ii. f (w) = max{w, w3}. iii. f (w) = ∥Xw − y∥3 + λ∥w∥1 (where λ > 0 and the “3-norm” is ∥r∥3 = (∑n i=1 |ri|3)1/3, which is a norm). Page 7 of 8 CPSC 340 Midterm Exam This page is intentionally blank. You can use it for scratch work or to continue an answer if you run out of space somewhere. End of exam Page 8 of 8 End of exam","libVersion":"0.2.1","langs":""}