{"path":".obsidian/plugins/text-extractor/cache/f466ebbdc970ec0f049085bda0a77319.json","text":"Selected Solutions to Exercises - Chapter 3 CPSC 302 Fall 2023 Question 3.2 If all row-sums are zero it means that a vector of all 1s, let us denote it by ⃗1, gives us A⃗1 = 0, and therefore there is a nontrivial solution of the homogeneous linear system Ax = 0, namely x = ⃗1. Therefore A is singular. Question 3.3 True. If Ax = λx then by multiplying both sides by 1 λ A−1 we get A−1x = 1 λ x. Question 3.10 False. All we need is a counterexample. Suppose for simplicity that A is symmetric positive deﬁnite with eigenvalues λ1 ≥ λ2 · · · ≥ λn > 0. Then in the 2-norm, ∥A∥ = max λi = λ1, ∥A∥ −1 = λ −1 1 , ∥A−1∥ = max λ −1 i = λ −1 n . So, ∥A∥ −1 ≤ ∥A−1∥, but no equality is guaranteed even in this case. Question 3.14 (a) true (b) false (c) false (d) true (e) false (f) false (g) false Question 3.17 (a) Note that the eigenvalues may be complex even if the matrix is real. Let Q be an orthogonal matrix with an eigenpair (λ, x). Then, ∥Qx∥2 = ∥λx∥2 = |λ| · ∥x∥2 = ∥x∥2, where the equality sign on the right follows from orthogonality (preservation of norm). There- fore, |λ| = 1 as required. (b) If P x = λx then the corresponding eigenvalue of P 2 is λ2. Since P 2 = P we have λ 2 = λ and therefore λ is either 0 or 1. 1 Question 3.26 (a) They are all equal to 1. Let us show this using the spectral decomposition. Let Q be orthogonal with SVD given by Q = U ΣV T . Then Q T Q = I = V ΣT U T U ΣV T = V ΣT ΣV T , from which it follows that ΣT Σ = I and hence all singular values are 1. (b) Not quite unique, for example U and V are only determined up to sign. There is a bit more to say here, but let’s leave it at this. 2","libVersion":"0.2.1","langs":""}