{"path":".obsidian/plugins/text-extractor/cache/37136438a0ca4b9b03b839afb292a9dd.json","text":"Math 318 Solutions to Assignment #8 March 20, 2020 Total marks = [30]. 1. Let X be the initial number of passengers and let S be the number of stops. Then S =∑N i=1 Ii where Ii is as in the hint, so ES = ∑N i=1 EIi = N EI1, where we used symmetry in the last step. We condition on X: ES = N EI1 = N ∞∑ n=0 E[I1 | X = n]P (X = n) = N ∞∑ n=0 P [I1 = 1 | X = n]P (X = n) = N ∞∑ n=0 (1 − P [I1 = 0 | X = n]) P (X = n). Since P [I1 = 0 | X = n] = [(N − 1)/N ]n and P (X = n) = λ n n! e−λ, this gives [5] ES = N ∞∑ n=0 (1 − ( N − 1 N )n) λn n! e−λ = N e −λ [ ∞∑ n=0 λ n n! − ∞∑ n=0 ( 1 − 1 N )n λ n n! ] = N e−λ [ eλ − e(1− 1 N )λ] = N (1 − e−λ/N ). 2. (a) A 2n-step walk ends at the origin if and only if the number of East steps equals the number of West steps and the number of North steps equals the number of South steps. If k is the number of East steps then there are ( 2n k,k,n−k,n−k) = (2n)!/(k!k!(n − k)!(n − k)!) (multinomial coeﬃcient) such walks. By taking into account the possible values of k, and noting that each 2n-step walk has probability 4 −2n we obtain p2n = 1 42n n∑ k=0 (2n)! k!k!(n − k)!(n − k)! = 1 42n ( 2n n ) n∑ k=0 ( n k )2. [2] (b) There are (2n n ) ways to choose n balls from 2n. On the other hand, there are (n k) ways to choose k white balls and ( n n−k) ways to choose n − k black balls, so [2] (2n n ) = n∑ k=0 (n k )( n n − k ) = n∑ k=0 (n k )(n k ). (c) By Stirling’s formula, p2n = 1 42n ( 2n n )2 ∼ 1 42n [(2n) 2ne−2n√2π2n] 2 [nne−n√2πn]4 = 1 πn . [1] (d) 1/n is not summable, so the walk is recurrent. [1] 3. (a) By deﬁnition, ϕ1(⃗k) = E(e i⃗k· ⃗X1). The expectation is a sum of twelve terms and reduces to [2] ϕ1(⃗k) = 1 6 [cos(k1 + k2) + cos(k1 − k2) + cos(k1 + k3) + cos(k1 − k3) + cos(k2 + k3) + cos(k2 − k3)] = 1 3 [cos k1 cos k2 + cos k1 cos k3 + cos k2 cos k3] . (b) Singularities occur when ϕ1(⃗k) = 1. Since the cosines are in [−1, 1], this occurs if and only if cos k1 cos k2 = cos k1 cos k3 = cos k2 cos k3 = 1. The solutions are ⃗k = ⃗0 and the eight corners [±π, ±π, ±π] of [−π, π] 3. [2] 1 (c) Using cos ki ∼ 1 − 1 2 k2 i and (a), and dropping all terms beyond quadratic, gives 1 − ϕi(⃗k) ∼ 1 − 1 3 [3 − k2 1 − k2 2 − k2 3] = 1 3 |⃗k| 2. Apart from the unimportant constant, this is the same singularity that was shown to be integrable in dimensions d > 2 in class. [2] 4. (a) Since the walk is recurrent, it will return inﬁnitely often to the origin. Each time it does, there is a positive probability that the walk will subsequently reach x, and therefore eventually this will happen. But then the walk must return to the origin, and the process will repeat itself, so x is visited inﬁnitely often. [1] (b) ϕ1(k) = ( 1 2 )(1) + 1 4 e2k + 1 4 e−2k = 1 2 (1 + cos 2k), so m = π−1 ∫ π −π(1 − cos 2k) −1dk. Now 1 − cos 2k = 0 for k = 0 and k = ±π. For k near zero, 1 − cos 2k ∼ 2k2 and the integral diverges, so m = ∞ and the walk is recurrent. [2] (c) Let Sn denote the diﬀerence in position after n steps of the walker started at +2 and the walker started at 0. Note that at each step, Sn changes by 0 with probability 1 2 , by +2 with probability 1 4 , and by −2 with probability 1 4 . Thus Sn is the recurrent walk of part (b). By part (a), Sn will eventually visit 0 (the role of the origin in (a) is played by +2 here and x in (a) is 0 here). But Sn = 0 means the two walks collide. [2] 5. (a) function y=tau(n,d) y = inf; #We treat the cases d=1 and d=2 separately if d == 1 S = 0; for i = 1:n # Generate the random vector that increments the random walk in 1 step # This is equal to -1 and 1 each with probability 1/2 r = rand(); if r < 1/2 S = S + 1; elseS = S - 1; end # Stop the walk when the origin is revisited if S == 0 y = i; break end end end if d == 2 S = [0 0]; for i=1:n # Generate the random vector that increments the random walk in 1 step # This is equal to (1,0), (0,1), (-1,0), (0,-1), each with probability 1/4 r = rand(); 2 if r < 1/4 S = S + [1 0]; elseif (r >= 1/4)&(r < 1/2) S = S + [0 1]; elseif (r >= 1/2)&(r < 3/4) S = S + [-1 0]; elseif r >= 3/4 S = S + [0 -1]; end # Stop the walk when the origin is revisited if S == [0 0] y = i; break end end end end [2] (b) and (c) # Generate vectors r and R for i=1:4000 r(i) = tau(5000,1); R(i) = tau(5000,2); end # Generate a and A for n=1:5000 a(n) = sum(r > n)/4000; A(n) = sum(R > n)/4000; end # Define variables for plots N = [1:1:5000]; X = log(N); # Prepare linear regression for 1d walk Yd1 = log(a); pd1 = polyfit(X, Yd1, 1); Ld1 = pd1(2) + pd1(1).*X; # Plot for 1d walk plot(X,Yd1,’:’,X,Ld1,’-’) title([’One-dimensional walk; linear regression slope = ’, mat2str(pd1(1),3),’.’]); xlabel(’log n’); ylabel(’log(a(n)) and line of best fit’); print -dpng rwd1.png; # Prepare linear regression for 2d walk Yd2 = 1./A; pd2 = polyfit(X, Yd2, 1); Ld2 = pd2(2) + pd2(1).*X; 3 # Plot for 2d walk plot(X,Yd2,’:’,X,Ld2,’-’) title([’Two-dimensional walk; linear regression slope = ’, mat2str(pd2(1),3),’.’]); xlabel(’log n’); ylabel(’1/A(n) and line of best fit’); print -dpng rwd2.png; [2] Your solution will be random since it involves simulations. Running the above code produced the following plots: What we expect to see from the above plot for d = 1 is a line with slope −1/2. [2] 4 What we expect to see from the above plot for d = 2 is a line with slope 1/π = 0.318. [2] 5","libVersion":"0.2.1","langs":""}