{"path":".obsidian/plugins/text-extractor/cache/8f01ccf2dbc1136ca3d48681c6b6792e.json","text":"* plat ol el ) = Yo pal o a0, = 2) : =302, 2 40,20 = ) p0, 20 = 2) . = Yopalaf ) [0,20 = 2) p = 2 14) ) . . =Y ez 1) [ ] pa 199,25 the last line uses independence of the features given the cluster. [12 points] Implement the VQNB method (there’s a stub in naive_bayes.py). Hand in your code, and the test error you obtain with this model for k = 2 through k = 5. Hint: The same KMeans class as last time is in the handout code for you to use, or feel free to use scikit-leam’s. Hint: p(y) you can handle just as before. p(z | y) is a categorical variable. p(x; |y, =) is Bernoulli; you'll have one Bernoulli parameter for each (y,z) pair, which it might be convenient to organize in a 10 k array Hint: If you're working with log-probabilities (which is a good idea), scipy. special. Logsumexp might be helpful for the sum operation.","libVersion":"0.2.1","langs":"eng"}