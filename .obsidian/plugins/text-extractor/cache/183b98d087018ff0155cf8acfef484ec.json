{"path":".obsidian/plugins/text-extractor/cache/183b98d087018ff0155cf8acfef484ec.json","text":"Math 318 Solutions to Assignment #5 Feb. 29, 2020 Total marks = [30]. 1. Since, for a ≥ 0, P(X > a|X < Y) = P(a < X < Y) P(X < Y) = λ + µ λ P(a < X < Y) = λ + µ λ ∫ ∞ a dx ∫ ∞ x dyλe−λxµe−µy = e−(λ+µ)a, we ﬁnd that the conditional density is (for a ≥ 0) f (a) = d da P(X ≤ a|X < Y) = d da (1 − e−(λ+µ)a) = (λ + µ)e−(λ+µ)a, so the conditional distribution is Exp(λ + µ). [2] 2. (a) N5 is Poisson(5λ) so its mean is 5λ. [1] (b) S3 is Gamma(3, λ) so its mean is 3/λ. [1] (c) P(N5 < 3) = e−5λ(1 + 5λ + 25λ2/2). [1] (d) If you like doing integrals you can integrate the Gamma density but it is easier to use the fact that {S3 > 5} is the same event as {N5 < 3} so the answer is the same as in part (c), namely: e−5λ(1 + 5λ + 25λ2/2) [1] (e) By the no memory property the conditional probability is equal to P(S2 > 3) and as in (d) and (a) this equals P(N3 < 2) = e−3λ(1 + 3λ). [1] 3. (a) The number of orders by time t is Mt + Vt, which has a Poisson((µ + ν)t) distribution. [1] (b) For k = 0, 1, . . . , n, P(Mt = k | Mt + Vt = n) = P(Mt = k, Vt = n − k) P(Mt + Vt = n) = P(Mt = k)P(Vt = n − k) P(Mt + Vt = n) = (µt)ke−µt k! (νt)n−ke−νt (n−k)! ((µ+ν)t)ne−(µ+ν)t n! = (n k ) ( µ µ + ν )k ( ν µ + ν )n−k . The conditional distribution of the number of meat orders is therefore Bin(n, µ µ+ν ). [3] 4. (a) ϕSn (t) = ϕX1 (t) · · · ϕXn (t) = exp[i ∑n k=1 µkt − ∑n k=1 σ2 k t2/2], so Sn ∼ N(µ1 + · · · + µn, σ2 1 + · · · + σ2 n). [1] (b) Let S = X1 + X2 + X3 − X4 ∼ N(5 + 5 + 5 − 5, 4 + 4 + 4 + 4) = N(10, 16) (since −X4 ∼ N(−5, 4) and by (a)), so P(X1 + X2 + X3 < X4) = P(S < 0) = P( S−10 4 < 0−10 4 ) = P(Z < −2.5) = P(Z > 2.5) = 1 − Φ(2.5) = 0.0062 [2] (c) ϕYn (t) = ϕSn (t/n) = eiµte−σ2t2/2n, so X ∼ N(µ, σ2/n). Similarly, ϕZn (t) = ϕSn (t/√n) = eiµ√nte−σ2t2/2, so X ∼ N(µ√n, σ2). (In particular, if µ = 0 then Zn ∼ N(0, σ2) has the same distribution as Xi, for all n.) [2] (d) limn→∞ ϕYn (t) = limn→∞ eiµte−σ2t2/2n = eiµt. [1] (e) With µ = 0 and σ = 1, by (c) we have √nYn ∼ N(0, 1), so P(|Yn| ≤ 0.1) = P(|Z| ≤ (0.1)(√n)) = Φ(√n/10) − Φ(−√n/10) = 2Φ(√n/10) − 1. The table then gives the values: .0796 (n = 1), .1742 (n = 5), .5222 (n = 50), .9750 (n = 500). [2] 1 5. (a) The left and right derivatives of ϕ at t = 0 are +1 and −1, respectively, so ϕ is not differentiable at t = 0. [1] (b) ϕn−1Sn (t) = (ϕ(t/n))n = (e−|t|/n)n = e−|t| = ϕ(t), so n−1Sn has the same distribution as X1, namely a Cauchy distribution. [2] (c) The weak law of large numbers does not apply to the Cauchy distribution, since its expectation is undeﬁned. [1] 6. (a) The number of earthquakes in 100 decades is a Poisson random variable with parameter λt = 100. The following Jupyter notebook performs the simulations and makes the plots for (b) and (c). [11]: import numpy as np import numpy.random as npr [12]: def quakes(L): T = npr.exponential(1); y = 0; while(T < L): y = y + 1; T = T + npr.exponential(1); return y [19]: X = np.zeros(10000) for i in range(10000): X[i] = quakes(100) [35]: import matplotlib.pyplot as plt # Produce histogram plt.hist(X,bins=100,range=(50,150)); plt.title(\"Number of earthquakes in 10000 samples of 100 decades\"); plt.show() # \"X==100\" is a vector with 0’s and 1’s; 1’s mark the indices j such that X(j) == ,→100 % \"cumsum(X==100)\" gives the cumulative sum of this vector, # as required in the definition of M M = np.cumsum(X==100); # Finally, create a vector N such that N(i) = M(i)/i and plot it N = np.zeros(10000) for i in range(10000): N[i] = M[i] / (i+1) plt.plot(N); plt.title(\"Plot of M(i)/i\"); 2 (d) By the Law of Large Numbers, the limiting value should be P(Y = 100), where Y ∼ Poisson(100). 3 Thus, using Sterling’s formula, P(Y = 100) = 100100 100! e−100 ≈ 100100 100100e−100√200π e−100 = 0.040. 4","libVersion":"0.2.1","langs":""}