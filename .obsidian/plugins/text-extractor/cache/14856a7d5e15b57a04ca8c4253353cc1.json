{"path":".obsidian/plugins/text-extractor/cache/14856a7d5e15b57a04ca8c4253353cc1.json","text":"contributed articles 74 CoMMuniCations of the aCM | feBRuARy 2014 | voL. 57 | No. 2 aTTac Kers commonLy eXpLoIT buggy programs to break into computers. security-critical bugs pave the way for attackers to install trojans, propagate worms, and use victim computers to send spam and launch denial-of-service attacks. A direct way, therefore, to make computers more secure is to find security- critical bugs before they are exploited by attackers. Unfortunately, bugs are plentiful. For example, the Ubuntu Linux bug-management database listed more than 103,000 open bugs as of January 2013. specific widely used programs (such as the Firefox Web browser and the Linux 3.x kernel) list 7,597 and 1,293 open bugs in their public bug trackers, respectively. a Other projects, including those that are closed-source, likely involve similar statistics. These are just the bugs we know; there is always the persistent threat of zero-day exploits, or attacks against previously unknown bugs. Among the thousands of known bugs, which should software developers fix first? Which are exploitable? a All bug counts exclude bugs tagged as “wishlist,” “unknown,” “undecided,” or “trivial.” How would you go about finding the un- known exploitable ones that still lurk? Given a program, the automatic ex- ploit generation (AEG) research chal- lenge is to both automatically find bugs and generate working exploits. The generated exploits unambigu- ously demonstrate a bug is security- critical. Successful AEG solutions pro- vide concrete, actionable information to help developers decide which bugs to fix first. Our research team and others cast AEG as a program-verification task but with a twist (see the sidebar “His- tory of AEG”). Traditional verification takes a program and a specification of safety as inputs and verifies the pro- gram satisfies the safety specification. The twist is we replace typical safety properties with an “exploitability” property, and the “verification” pro- cess becomes one of finding a pro- gram path where the exploitability property holds. Casting AEG in a veri- fication framework ensures AEG tech- niques are based on a firm theoretic foundation. The verification-based approach guarantees sound analysis, and automatically generating an ex- ploit provides proof that the reported bug is security-critical. Verification involves many well- known scalability challenges, several of which are exacerbated in AEG. Each new branch potentially doubles the number of possible program paths, possibly leading to an explosion of paths to check for exploitability. Tra- ditional verification takes advantage of source code, models, and other ab- stractions to help tackle the state ex- plosion and scale. Unfortunately, ab- automatic exploit Generation Doi:10.1145/2560217.2560219 The idea is to identify security-critical software bugs so they can be fixed first. By thanassis avGeRinos, sanG kiL Cha, aLexanDRe ReBeRt, eDWaRD J. sChWaRtZ, MaveRiCk Woo, anD DaviD BRuMLey key insights this research formalizes the notion of an exploit, allowing for automated reasoning about exploitation. the technology can be used to identify and prioritize security-critical bugs. improvements for verifying programs safe may also lead to improvements for automatically generating exploits. iiMage CoLLage by iWona USaKieWiCZ/andriJ boryS aSSoCiateS feBRuARy 2014 | voL. 57 | No. 2 | CoMMuniCations of the aCM 75 contributed articles 76 CoMMuniCations of the aCM | feBRuARy 2014 | voL. 57 | No. 2 exploiting Programs Suppose a developer is interested in finding and fixing exploitable bugs in the /usr/bin directory of the latest Debian operating system. For instance, in June 2012 we downloaded the then- current Debian 6.0.5, with (in our in- stallation) 1,168 executables in /usr/ bin to analyze for exploitable bugs. A typical approach to finding ex- ploitable bugs is to first find them and then determine which ones are exploitable. One popular way to find bugs is to perform “black-box fuzz- ing.” Fuzzing is a program-testing technique that runs a program on inputs from a fixed alphabet, often either modifying at random a known input or trying extreme values (such as 0 and the native maximum inte- ger), and the “black-box” refers to the program itself, which is not analyzed at all. The fuzzer chooses the inputs and observes the program, looking for hangs, crashes, buggy outputs, or other indications of a bug. We fuzzed each program using the following script: for letter in {a..z} {A..Z}; do timeout -s 9 1s <program> -$letter <path> done The script tries all single-letter com- stractions often leak by not perfectly encapsulating all security-relevant details, and the leaky points tend to affect the quality of security analysis. For example, writing 12B to an array declared to be 11B long is wrong in C but is also unlikely to be exploitable because most compilers would pad the array with extra bytes to word- align memory operations. In order to provide high fidelity, most AEG work analyzes raw execut- able code. Executable code analysis is needed because many exploits rely on low-level details that are abstract in source code (such as CPU semantics and memory layout). Executable code analysis is also attractive because it is widely applicable; users typically have access to the executable code of the programs they run (as opposed to source code) and thus can audit the code for security-critical bugs. Throughout this article, we focus on AEG as a defensive tool for priori- tizing exploitable bugs. However, we are also cognizant of the obvious of- fensive computing implications and applications as well. Governments worldwide are developing computer- warfare capabilities, and exploits have become a new type of ammuni- tion. At present, exploit generation in practice is mostly a manual process. Therefore, techniques that help re- duce the time and effort for exploit generation can potentially affect a na- tion’s operational capabilities. AEG research is in its infancy and not yet at the point of automatically churn- ing out weapons-grade exploits for an arbitrary program. Most reported research results generate exploits against bugs up to a few thousand lines deep in execution and for rela- tively straightforward bugs, while typ- ical offensive needs include exploits for complicated bugs and large pro- grams like Internet Explorer and Ado- be Reader. Nonetheless, current AEG results show promise, and a conserva- tive defensive security position must consider the possibility of real-world offensive AEG capabilities. This article describes our AEG re- search at Carnegie Mellon University, its successes, as well as its current limitations. We focus primarily on control-flow hijack exploits that give an attacker the ability to run arbitrary code. Control-flow hijacks are a seri- ous threat to defenders and coveted by attackers.3,35 Although most current research focuses on control-flow hi- jacks due to their immediate danger, AEG is not limited to only this class of attacks. Exploitable bugs are found in programs in all languages, and the verification-based approach to AEG still applies. our running example of a buffer overflow in acpi-listen. 1. int main(int argc, char **argv) { 2. char *name; int i; 3. for (;;) { 4. i = getopt(argc, argv, \"c:s:t:vh\"); 5. if (i == -1) break; 6. switch (i) { 7. case 'c': ...; break; 8. case 's': name = optarg; break; 9. ... 10. } 11. } 12. sock_fd = ud_connect(name); 13. ... 14. } 15. int ud_connect(const char *name) { 16. int fd; 17. struct sockaddr_un { 18. sa_family_t sun_family; 19. char sun_path[108]; 20. } addr; 21. ... 22. sprintf(addr.sun_path, \"%s\", name); 23. ... 24. return fd; 25. } 00000000 31 c9 f7 e1 51 68 2f 2f 73 68 68 2f 62 69 6e 89 |1...Qh//shh/bin.| 00000010 e3 b0 0b cd 80 41 41 41 41 41 41 41 41 41 41 41 |.....AAAAAAAAAAA| 00000020 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 41 |AAAAAAAAAAAAAAAA| * 00000080 41 41 41 41 41 41 41 41 74 f2 ff bf |AAAAAAAAt...| … 0xbffff274 0xbffff28f 0xbffff28c – 0xbf 0xff 0xf2 0x74 After sprintf … A (0x41) A (0x41) shellcode[20] … shellcode[0] lower address higher address… 28 bytes of … sun_path[107] sun_path[0] sequential access Before sprintfmainud_connect … ret addr LSB ret addr MSB saved values locals & contributed articles feBRuARy 2014 | voL. 57 | No. 2 | CoMMuniCations of the aCM 77 mand-line options from a to Z, fol- lowed by a valid 6,676B filename. The timeout command limited total exe- cution time to one second, after which the program was killed. The script took about 13 minutes to fuzz all programs on our test ma- chine, yielding 756 total crashes. We identified 52 distinct bugs in 29 pro- grams by analyzing the calling con- text and faulting instruction of each crash. Which bugs should a developer fix first? The answer is the exploit- able ones. For now, we forgo several important issues relevant in practice we tackle later (such as whether the buggy program is a realistic attack tar- get and whether additional operating system defenses would protect the otherwise exploitable program from attack). We first describe simple manual exploit generation to introduce ter- minology and give a flavor of how exploits work. We focus on control- flow hijack exploits, which have been a staple class of exploits in the computer-security industry for de- cades.3,35 Well-known examples of control-flow hijacks range from ex- ploits in the Morris worm in 1988 to the more recent Stuxnet and Flame worms (though the latter exploits are much more complicated than those described here). The figure here shows a bug discov- ered in acpi _ listen (now patched in Debian testing) we use as our run- ning example. A buffer overflow oc- curs on line 22. The program reads in a command-line argument; if it is -s (line 8), it assigns the subsequent argument string to the name variable. On line 22, the sprintf function copies name into sun _ path, a field in a local instance of the networking sockaddr _ un data type, a standard data structure in Unix for sockets. The bug is that sun _ path is a fixed-size buffer of 108B, while the command-line argument copied through name into sun _ path can be any length. The C standard says the execution behavior is undefined if more than 108B are written. When ex- ecuted, something will happen; with the fuzzing script described earlier, the program crashed. Unfortunately, this crashing bug can be exploited. All control-flow hijack exploits have two goals: hijack control of the instruction pointer (IP) and then run an attacker’s computation. For acpi _ listen, some of the details an attacker must understand in- depth include: the hardware execu- tion model (such as how instructions are fetched from memory and ex- ecuted; how function calls are imple- mented; how writing outside the allo- cated space can hijack control of the IP; and how to redirect the IP to run the attacker’s code). Since any discus- sion of creating exploits against vul- nerable C programs assumes a basic understanding of these facts, we offer the following overview. During runtime, computer hard- ware implements a fetch-decode- execute loop to run a program. The hardware maintains an IP register that contains the memory address of the next instruction to be executed. During the fetch phase, the hardware loads the data pointed to by the IP register. The data is then decoded as an instruction that is subsequently executed. The IP is then set to the next instruction to be executed. Control is hijacked by taking control of the IP, which is then used to fetch, decode, and execute the attack- er’s computation. A straightforward exploit for acpi _ listen hijacks control by overwriting data used to implement function returns. Exploits can also overwrite other control data (such as function pointers and the global off- set table, as in Muller29), but we omit these details here. Function calls, returns, and local variables are not supported directly by hardware. The compiler implements the semantics of these abstractions using low-level assembly instructions and memory. An attacker must be proficient in many details of code execution (such as how arguments are passed and registers are shared between caller and callee). For simplicity, we assume a standard C calling convention known as cdecl. Functions using it implement a stack abstraction in memory where func- tions push space for local variables, arguments to future calls, and other data onto the stack immediately after being called. A function return pops the allocated space off the stack. Thus, the stack grows a bit for each call and shrinks a bit on each return. the twist is we replace typical safety properties with an “exploitability” property, and the “verification” process becomes one of finding a program path where the exploitability property holds. contributed articles 78 CoMM uniCations of the aCM | feBRuARy 2014 | voL. 57 | No. 2 being overwritten in a variable up- date. Control-flow hijacks are an in- stance of a channeling vulnerability that arise when the control and data planes are not rigorously separated. For this particular example, an out- of-bound write can clobber the return address. When sprintf executes, it copies data sequentially from name up the stack, starting from the ad- dress for sun _ path, as shown. The copy stops only when a zero integer, or ASCII NULL, is found, which is not necessarily when sun _ path runs out of space. A long name will clobber the saved local variables and eventu- ally the saved return address. Since an attacker controls the values in name, and those values overwrite the return address, the attacker ultimately con- trols which instructions are executed when ud _ connect returns. Attackers must analyze the program to figure out exactly how many bytes to write, what constraints may be on the bytes, and what would be a good value with which to overwrite the return ad- dress. For acpi _ listen, a string of length 140 will overwrite the return ad- dress. The first 108B will be copied into space allocated for sun _ path. The next 28B on the stack are intended to hold local variables and saved register values. The final 4B overwrite the saved return address. When ud _ connect returns, the overwritten return address is popped off the stack into the IP register. The machine continues executing the in- struction starting at the overwritten address. While this example overwrites the return address, a variety of other control data structures can be used to seize control; examples include func- tion pointers, heap metadata, and C++ virtual function tables. Control is typically hijacked to run an attacker-supplied computation. The most basic attack is to inject execut- able code into the vulnerable process. More advanced techniques (such as command injection, return-to-libc, and return-oriented programming) are also possible 29,33 (and in some cases can be automated as well 31), but we omit such discussion here. A natural choice for the computa- tion is to execute the command-line shell /bin/sh so the attacker is able to subsequently run any command When f calls g, f first puts g’s argu- ments onto the stack, then invokes g, typically through a call assembly instruction. The semantics of call includes pushing f’s return address onto the stack; that is, the address in f where execution (normally) continues once g terminates. Upon entrance, g creates space for its variables and other run-time information (such as saved register values). After g com- pletes, g returns control to f by shrink- ing the created stack space for g and popping off the saved address into the IP register, typically through a ret in- struction. A critical detail is that the popped value, regardless of whether it was the original value pushed by f or not, is used as the address of the next instruction to execute. If an attacker can overwrite that address, the attack- er can gain control of execution. The stack frame just before sprintf is called on line 22 in the Fig- ure. The flow of execution for creating the depicted stack includes six steps: Return address pushed onto the stack. When main called ud _ con- nect, main pushed the address of the next instruction to be executed (corre- sponding to line 13) onto the stack; Control transfer. main transferred control to ud _ connect; Local variable space allocated. ud _ connect allocated space for its local variables. On our computer, 108B were allocated for sun _ path and an addi- tional 28B for other data (such as ad- ditional local variables and saved reg- ister values); Function body executed. The body of ud _ connect ran. When sprintf is called, a similar flow pushes a new return address on the stack and new space onto the stack for sprintf’s lo- cal variables; Local variable space deallocated. When ud _ connect returns, it first deallocates the local variable space, then pops off the saved return address into the IP register; and Return to caller. Under normal op- eration, the return address points to the instruction for line 13, and main resumes execution. The crux of a control-flow hijack is that memory is used to store both control data (such as return address- es) and program-variable values, but the control data is not protected from Governments worldwide are developing computer-warfare capabilities, and exploits have become a new type of ammunition. contributed articles feBRuARy 2014 | voL. 57 | No. 2 | CoMMuniCations of the aCM 79 Our research vision is to automate it. AEG uses verification techniques to transform the process of finding and deciding exploitability to reasoning in logic. At a high level, AEG consists of three steps: It first encodes what it means to exploit a program as a logi- cal property; it then checks whether the exploitability property holds on a program path; and finally, for each path the property holds, it produces a satisfying input that exploits the pro- gram along the path. These steps are the cornerstones of AEG research. First, what exploit- ability properties do we encode, and how? In industry, an exploit could mean control-flow hijack, while an intelligence agency might also in- clude information disclosures, and a safety board could include denial of service for critical services. Any single property may have many en- codings, with some more efficient for automated tools to check than others. Second, what techniques and algorithms should a programmer em- ploy to check a program? The general problem of checking programs for properties is called “software model checking,”24 encompassing a num- ber of techniques (such as bounded model checking, symbolic execution, and abstract interpretation). Third, what does it take to implement real systems, and how do these systems perform on real software? The theory of AEG can be de- scribed with a small number of opera- tions on a well-defined programming language that interacts with its envi- ronment in a few predicable, easy-to- model ways. However, a real system must also contend with hundreds of CPU instructions and the tricky and complex ways programs interact with their environments. Sometimes even pedestrian yet necessary details are difficult to get right; for example, it took our team almost a year to stop finding bugs in our internal seman- tics for the x86 shift instructions (such as shl). The developers of Mi- crosoft’s SAGE tool reported similar difficulties for the same instructions.4 Current AEG research primar- ily uses symbolic execution25 to check program paths for exploitability prop- erties. At a high level, symbolic execu- tion represents all possible inputs as with the privileges of the exploited process. In fact, executing a shell is so popular that colloquially any attacker code is called “shellcode.” A classic approach is to give executable code as input to the program and redirect con- trol flow to the given executable code. The executable code itself can be cre- ated by mimicking the assembly for execve(\"/bin/sh\", args, NULL). Attackers introduce the shellcode to the vulnerable program as a normal string program input that is eventu- ally decoded and executed as code. The final step of the attack is to overwrite the return address with the address of the shellcode. On our ma- chine, sun _ path is at memory ad- dress 0xbffff274. The complete exploit for acpi _ listen (gener- ated automatically by our AEG tools) is shown in the figure, where: Shellcode. The first bytes of the com- mand line argument are the shellcode; the shellcode is 21B, and, in this case, the first 21B are copied into bytes 0–20 of sun _ path; Padding. The next 115B of input can be any non-zero, or non-NULL ASCII, value; the bytes are copied into bytes 21–107 of sun _ path and the addi- tional space for other locals; and Shellcode address. The last 4B of input are the hex string 0x74 0xf2 0xff 0xbf. They overwrite the return address. When the return address is popped, the bytes become the address 0xbffff274 (because x86 is little en- dian), which is the address of the shell- code after it is copied to sun _ path. The figure shows the stack frame after supplying this string as a com- mand-line argument following -s. When ud _ connect returns, the ad- dress 0xbffff274 is popped into the IP register, and the hardware fetches, decodes, and executes the bytes in sun _ path that, when interpreted as executable code, runs /bin/sh. When the shellcode runs, the attacker is able to run any command with the same privileges as the exploited program. Research vision Manual exploit generation requires a developer to reason about an enor- mous number of details (such as size of the stack, location of control flow critical data, like return address, and precise semantics of each instruction). a set of symbolic input variables. Sym- bolic execution then picks a program path through a predefined path-selec- tion algorithm. The path is then “ex- ecuted,” except, instead of executing on a real, concrete input, a symbolic input stands in for any possible con- crete value. Symbolic execution builds up a path formula in terms of the sym- bolic inputs based on the instructions executed. The path formula is satis- fied, meaning made true, by any con- crete input that executes the desired path. If the path formula is unsatisfi- able, there is no input that executes the path, and the path is called infea- sible. The satisfiability check itself is done through automated solvers (such as Satisfiability Modulo Theories, or SMT).15 By construction, free variables correspond to program inputs, and any satisfying assignment of values to free variables (called a model) is an input that executes the selected path. SMT solvers enumerate satisfying an- swers when needed. In acpi _ listen, the symbolic inputs are the first two arguments argv[1] and argv[2]. (Although we have shown source code for acpi _ listen for clarity, our AEG tool Mayhem requires only the program executable.12) Executing the -s op- tion program path generates the con- straint that the first 3B of argv[1] correspond to the NULL-terminated string -s. At each subsequent branch point, symbolic execution adds more constraints to the formula. Next, acpi _ listen calls sprintf, which copies bytes from name to addr. sun _ path until it encounters a NULL character. Symbolic execution captures this logic by adding the con- straint that each copied byte is non- NULL. Symbolically executing the -s program path where argv[1] is three symbolic bytes and argv[2] is 140 non-NULL symbolic bytes generates the constraints: argv[1][0:2]= \"−s\" ∧∀i∈[0,139]. argv[2][i]≠0∧argv[2][140]=0 (1) Note that a formula may have many satisfying answers; for example, bytes 0–139 of argv[2] can be “A,” “B,” or any other non-NULL character. Each feasible path can be checked for exploitability by adding a set of con- contributed articles 80 CoMM uniCations of the aCM | feBRuARy 2014 | voL. 57 | No. 2 be placed anywhere in memory. In our experiment, our AEG tool Mayhem 12 found the exploitable path and solved the exploitability formula in 0.5 sec- onds. Mayhem is also able to enumer- ate satisfying answers to automatically generate multiple exploits. Managing state explosion. AEG is a type of software verification, albeit for a very special property. As such, it inherits benefits but also well-known scalability challenges (such as path ex- plosion and the NP-hardness of solving SMT queries in general). They are often dress of our shellcode. The full formula to reach and exploit the acpi _ lis- ten bug is: (Equation 1)∧mem[ar]=as ∧mem[as:as+len(shellcode)−1]= 〈shellcode〉 (3) The mem[ar] constraint requires the re- turn address to contain the address of the shellcode as. The final constraint re- quires the shellcode to start at address as. The variable as is left unconstrained since the shellcode could potentially straints that are satisfied only by ex- ploiting inputs. Most research tackles control-flow hijack exploits, where the exploitability constraints specify the IP register holds a value that corresponds to some function f of user input i (such as, f may be a call to tolower on the input i) and the resulting IP points to shellcode: IP=f(i)∧mem[IP]=〈shellcode〉 (2) Now let ar be the memory address for the return address and as be the ad- symbolic execution was invented around 1975 independently by several researchers.5,23,25 around 2005, the field exploded. hundreds of papers have now been published describing advanced techniques and applications; see cadar and sen11 for a description and the main challenges of symbolic execution. modern tools (such as KLee,9 eXe,10 sage,20 and others7,13,32,37) find inputs that can crash or hang a system. such inputs may well be viewed as exploits in safety-critical systems where uptime is critical. more generally, work in symbolic execution is directly applicable to making aeg more efficient. as of 2012, most symbolic-execution work followed one execution path at a time. since then, more work has looked at generalizing over multiple paths (such as to loops30). others have also investigated alternatives to symbolic execution that tame path explosion (such as brumley and Jager6 and flanagan and saxe16,18,26). more generally, any verification technique that can produce example inputs (such as bounded model checking) is likely usable for aeg. modern aeg research dates to at least ganapathy et al.,17 who explicitly connected verification to exploit generation, modeling how format string specifiers are parsed by functions like printf that take a variable number of arguments and use the model to automatically generate exploits. They also demonstrated automatically generating an exploit against a key integrity property for a cryptographic co-processor.17 however, they considered only apI-level exploits, which do not include running shellcode or the conditions necessary to reach a vulnerable apI call site. In 2007, medeiros28 and grenier et al.21 proposed techniques based on pattern matching for aeg. In 2008, brumley et al.8 developed automatic patch- based exploit generation (apeg). The apeg challenge is, given a buggy program P and a patched version P′, generate an exploit for the bug present in P but not present in P′. The idea is the difference between P and P′ reflects where the original bug occurs and under what conditions it might be triggered. attackers have long known the value of analyzing patches to find non- public bugs; for example, attackers have been known to joke microsoft’s “patch Tuesday” is followed by “exploit Wednesday.” our techniques automatically found the differences between P and P′ and generated inputs that triggered the bugs in P using symbolic execution. one main security implication is that attackers can potentially use apeg to exploit bugs before patches can be distributed to a large number of users. We generated exploits for five microsoft security patches, including triggering an infinite loop in the Tcp/Ip driver and stealing files on microsoft Web servers. one limitation was that our work on apeg only proposed, but did not implement, techniques for executing shellcode for memory-safety bugs.8 heelan’s 2009 thesis22 was the first to comprehensively describe and implement techniques for automatically generating control-flow hijack exploits that execute shellcode. In heelan’s problem setting, the attacker is given an input that executes an exploitable program path, and the goal is to output a working control-flow-hijack exploit. This setting is the same as in our running example where we first fuzzed to find bugs, then checked exploitability. heelan proposed using symbolic execution and taint analysis to derive the conditions necessary to transfer control to shellcode and demonstrated a tool that produced exploits for several synthetic and for one real vulnerability. he also used a technique called return-to-register to improve exploit robustness. heelan’s thesis also presented a history of aeg work through 2009. In 2011, we proposed aeg techniques that find bugs and generate exploits, demonstrating them on 16 vulnerabilities.1 The initial work performed symbolic execution on source code to find bugs, then used dynamic binary analysis to generate control- flow hijack exploits. Included were a number of optimizations for searching the state space (such as preconditioned symbolic execution and the buggy- path first optimizations discussed earlier). In 2012, we introduced mayhem, a tool and set of techniques for aeg on executable code.12 With mayhem, we proposed techniques for actively managing symbolically executed program paths without exhausting memory and reasoning about symbolic memory addresses efficiently. both papers1,12 targeted control-flow hijacks for buffer overflows and format-string vulnerabilities. mayhem generated exploits for seven Windows and 22 Linux vulnerabilities. disregarding one long-running outlier, the average exploit-generation time in all experiments was 165 seconds. as of July 2013, mayhem was able to generate exploits for buffer overflows, format strings, command injection, and some information-leak vulnerabilities. aeg1 and mayhem12 were designed to demonstrate a bug is exploitable but do not try to bypass defenses that may otherwise protect a system. In 2011, we proposed techniques for bypassing the dep and asLr defenses implemented in Windows 7 and Linux, as well as exploit hardening and maintenance.31 History of AEG contributed articles feBRuARy 2014 | voL. 57 | No. 2 | CoMMuniCations of the aCM 81 amplified in AEG because AEG tech- niques reason about both low-level code and large inputs, along with a few abstractions. However, specific charac- teristics of AEG also afford researchers unique opportunities. Consider the affect of path prioriti- zation on this program: int x = get _ int(); if((x % 2) == 0) { if(x > 10) vuln1(); else if(x == 3) vuln2(); else safe(); } else { safe(); } Let xo be ao explore the program and find the vulnerability: ( x0% 2) = 0 ∧ ¬( x0 > 10) ∧ ¬( x0 = 3) ( x0% 2) = 0 ∧ ¬( x0 > 10) ∧ x0 = 3 ¬(( x0% 2) = 0) ( x0% 2) = 0 ∧ x0 > 10 The first formula for the first path is satisfiable (such as when xo = 4), in- dicating the path can be executed but is safe (unexploitable). The second formula corresponds to the infeasible path up to vuln2() and is unsatisfi- able because the constraint (xo % 2) = 0 and xo =3 cannot both be true simul- taneously. Since vuln2 will never be executed, it can never be exploited. The third formula corresponds to a feasible, safe path. Only the fourth formula corresponding to the path up to vuln1() is satisfiable, where a satisfying assignment (such as xo =42) corresponds to an exploit. In general, the number of paths and formulas is infinite for programs with loops and exponential in terms of number of branches for any acyclic portion, making effective path selection a fun- damental issue in AEG research. Path-selection heuristics guide execution so vulnerable paths are se- lected early in exploration. Symbolic execution research is filled with a vari- ety of approaches. For example, KLEE has options for depth-first traversal of the control-flow graph, as well as a randomized strategy.9 Microsoft uses generational search,20 which priori- tizes symbolically executing program paths that branch off a known path taken by a fixed concrete seed input. Godefroid et al.’s research20 suggests generational search is more effective than either breadth-first search or depth-first search. Two techniques that proved effec- tive in our experiments at Carnegie Mellon are “preconditioned symbolic execution” and “buggy-path first.”1 Preconditioned symbolic execution first performs lightweight analysis to determine the necessary condi- tions to exploit any lurking bugs, then prunes the search space of paths that do not meet these conditions. For ex- ample, a lightweight program analy- sis may determine the minimum length input string needed to trigger possible buffer overflows, and paths corresponding to inputs smaller than the minimum length can be pruned or skipped. The idea of buggy-path first is that any bug is a sign of programmer con- fusion, increasing the likelihood of an exploitable bug being nearby. For example: char buf[1024]; memset(buf, 0, strlen(input)); ... strncpy(buf, input, strlen(input)); The second line contains a mistake where potentially more than 1,024B of buf are zeroed. This bug would likely not lead to a control-flow hijack, but does signal confusion that the length of input is somehow related to the size of buf. Buggy-path first would priori- tize further exploration of the buggy path over other possible paths and thus discover the subsequent exploit- able code more quickly in our tests. Note that a unique aspect of buggy- path first is that execution continues under the assumption the bug has been triggered (such as in the example when nearby stack variables may have been zeroed inadvertently). A second core challenge of AEG research is optimizing SMT satisfi- ability checks. In theory, each satisfi- ability check is an NP-hard problem instance, but in practice many queries are resolved quickly. For example, in an experiment involving 5.6 million SMT queries, 99.98% of all solved que- ries took one second or less. Domain- specific optimizations in symbolic ex- ecution (such as arithmetic and logical simplifications, strength reduction, a sound aeG technique says a bug is exploitable if it really is exploitable, while a complete technique reports all exploitable bugs. contributed articles 82 CoMMuniCations of the aCM | feBRuARy 2014 | voL. 57 | No. 2 automatically generating an exploit provides proof that the reported bug is security-critical. concrete execution, and caching) all help speed queries. 9,10,13,19,32 In 2006 when we started using sym- bolic execution and SMT solvers, we treated the SMT solver as a black box, focusing only on the symbolic execu- tor. In hindsight, that approach was naive. In our research group we now believe it is more fruitful to view the SMT solver as a search procedure and use optimizations to guide the search. For example, one recurring challenge in AEG is checking satisfiability of for- mulas that operate on memory with symbolic memory addresses. A sym- bolic memory address occurs when an index into an array or memory is based on user input, as in: ...; y = mem[i % 256]; if(y == 2) vuln(); ... Without more information, the SMT solver must do a case split over all pos- sible values of i that may reach down- stream statements (such as vuln). Case splits can quickly push an SMT solver off an exponential cliff. Sym- bolic memory references often crop up in commonly occurring library calls (such as conversion functions like tolower and toascii) and pars- ing functions (such as sscanf). Many symbolic executors mitigate the case split by concretizing symbolic ad- dresses to a specific value (such as by picking i=42). Unfortunately, in our experiments with dozens of exploitable bugs we found concretization overconstrains formulas, leading our initial AEG techniques to miss 40% of known ex- ploitable bugs in our test suite;12 for example, AEG may need to craft an input that becomes valid shellcode after being processed by tolower (such as tolower is f in Equation 2). In Mayhem, we proposed a number of optimizations for symbolic memory;12 for example, one performs a type of strength reduction where symbolic memory accesses are encoded as piecewise linear equations.12 Example application: Exploiting /usr/bin. Recall we fuzzed Debian /usr/bin and found 52 distinct bugs in 29 programs, including acpi _ listen. One goal was to determine which bugs are exploitable. We ran our binary-only AEG tool called Mayhem 12 on each crash to de- termine if we could automatically gen- erate an exploit from the crashing path. We also manually checked whether it was possible to exploit the bug. Five of the 52 bugs were vulnerable to a con- trol-flow hijack, and Mayhem generat- ed exploits for four of them. The exploit for acpi _ listen took 0.5 seconds to generate, and the remaining three took 8, 12, and 28 seconds, respectively. These results on /usr/bin offer three insights: First, current AEG tools like Mayhem are sound but incom- plete. A sound AEG technique says a bug is exploitable if it really is exploit- able, while a complete technique re- ports all exploitable bugs. Unfortunate- ly, Rice’s theorem implies developing a sound and complete analysis for any nontrivial program property is in gen- eral undecidable. Second, AEG can be very fast when it succeeds. And finally, there is ample room for improving AEG in particular and symbolic execu- tion and software model checking in general. For example, we analyzed why Mayhem failed on the last vulnerability, finding the problem was a single con- straint that pushed the SMT solver (we use Z3) off an exponential cliff. Perhaps comically, manual analysis showed the constraint was superfluous but was not recognized as such by the automatic formula optimizer. Once the constraint was removed from the formula, exploit generation took less than five seconds. Real-World Considerations Security practitioners often focus only on exploits for programs on the at- tack surface of a system.27 The attack surface consists roughly of the set of programs, files, protocols, services, and other channels available to an attacker; examples include network daemons, programs called from Web servers on untrusted inputs, privileged programs, and media players. Our ex- ample acpi _ listen is not on the at- tack surface. We chose acpi _ listen because it highlights the steps of AEG, yet disclosing the exploit would do lit- tle damage because it is not on the at- tack surface. Interestingly, the acpi _ listen vulnerability is remarkably similar to a recent PHP vulnerability that performs an unchecked copy on the same data structure. 14 Overall, AEG techniques are valu- able because they show whether a pro- contributed articles feBRuARy 2014 | voL. 57 | No. 2 | CoMMuniCations of the aCM 83 gram can be exploited regardless of whether it is on the attack surface or not. For example, a program not on the attack surface in one deployment may be on the surface for another. More generally, programs on the attack surface are simply a subset of all pro- grams; if we can handle all programs we can surely handle the subset on the attack surface. Current techniques have found exploits on the attack sur- face, albeit not in widely used large ap- plications like Internet Explorer. For example, as we wrote this article we ran Mayhem on additional examples that are on the attack surface, finding a number of zero-day exploits for media applications (such as ezstream and imview) and network applications (such as latd and ndtpd). Another consideration is additional layers of defense that might protect otherwise exploitable programs. Two popular operating-system-level de- fenses against control-flow hijacks are data-execution prevention, or DEP, and address space layout randomization, or ASLR. DEP marks memory pages either “writable” or “executable” but forbids a memory page from being both. DEP prevents an exploit that requires writ- ing and then executing shellcode on a memory page from working (such as the shellcode mentioned earlier). Unfortunately, attackers have devel- oped techniques to bypass DEP. One such method is called return-to-libc where the attacker shellcode executes code already present in memory (such as by running system (“/bin/sh”) in libc directly) rather than writing new code to memory. Return-oriented pro- gramming, or ROP, uses instruction sequences already present in memo- ry, called “gadgets.” Shacham et al.33 showed it is possible to find a Turing- complete set of gadgets in libc. ASLR prevents control-flow hijacks by randomizing the location of ob- jects in memory. Recall that to exploit acpi _ listen, the attacker needs to know the address of the shellcode. ASLR randomizes addresses so vul- nerable programs likely crash instead of successfully redirecting control to the shellcode. ASLR is an important defense but does not fix the underly- ing vulnerabilities and thus may pro- vide limited protection; for example, Windows and Linux systems running on 32b processors may have insuffi- cient randomness to provide strong security,34 though 64b architectures can address this problem. Particular deployments of ASLR may have weak- nesses as well; for example as of Janu- ary 2013 the program image of Linux executables is often not randomized. Even when randomized well, addi- tional vulnerabilities may disclose information that can subsequently be used in a control-hijack exploit. Schwartz et al.31 proposed exploit hardening, which takes an exploit that works against an undefended system and hardens it to bypass defenses. One step in exploit hardening is to automatically generate ROP payloads (to bypass DEP) that take advantage of small portions of unrandomized memory (to bypass ASLR on the 2013 implementations of ASLR on Windows 7 and Linux). In particular, Schwartz et al. showed ROP payloads can be gener- ated for most programs in Windows and Linux that have at least 20KB of unrandomized code, which is true for many programs. Exploit hardening can be paired with AEG to check the end-to-end security of a program run- ning on a specific system. Finally, DEP and ASLR defend only against memory overwrite attacks. Other vulnerabilities (such as informa- tion disclosure, denial of service, and command injection) are also critical in practice; for example, DEP and ASLR do not protect against exploits for the command-injection vulnerability found by Mayhem in ezstream. Conclusion AEG is far from being solved. Scalabil- ity will always be an open and inter- esting problem. As of February 2013, AEG tools typically scale to finding buffer overflow exploits in programs the size of common Linux utilities. In Mayhem, one current bottleneck is driving the symbolic executor to the buggy portion of the state space. As a result, programs with deep bugs are typically beyond the scope of our cur- rent Mayhem AEG tool. Examples in- clude large programs with bugs deep in the program (such as Internet Ex- plorer and Adobe Reader), as well as those with large protocol state (such as first authenticate, then send mul- tiple fragmented messages to exploit a bug). In addition, programs with complex functions (such as hashes) are often a bottleneck for SMT solv- ers. One promising data point is that Microsoft’s SAGE tool routinely finds bugs in large applications,20 though automatically generating exploits for those bugs is an open challenge with huge potential rewards. More fundamentally, AEG must expand to involve a wider variety of exploitability properties and scale to new program domains. While buffer overflows continue to be exploited3,35 integer overflows, use-after-free, heap overflows, and Web vulnerabilities are also important (and popular) targets;3 for example, heap overflows against modern operating systems like Win- dows 8 pose difficult challenges (such as modeling internal heap metadata and new heap allocators with built-in defenses). In our experience, the prob- lem is often not coming up with some formalism, but with the right formal- ism and optimizations that make AEG efficient and practical on real-world programs and vulnerabilities. Except for a few examples (such as Ganapathy et al.’s17 exploits against a particular cryptographic API), most work in AEG has focused on exploiting programs in type-unsafe languages, though type safety is no panacea. In- formation flow, command injection, and many other common exploitable bugs can all occur in typical type-safe languages. Moreover, the runtime environment itself may have security- critical flaws. For example, the most commonly exploited vulnerabilities in 2011 were in Java.2 AEG can be modeled as a verifica- tion task; therefore, the better pro- grammers and researchers get at soft- ware verification, the better they will likely get at automatically generating exploits. Some security researchers are pessimistic about the practicality of AEG in many application settings,36 rightfully pointing out significant scal- ability hurdles and the lack of exploits against vulnerabilities like use-after- free. We are more optimistic. Eight years ago, AEG techniques were re- stricted to analyzing a single API call. Today, AEG can both automatically find and generate exploits in com- mon binaries. In an effort to improve contributed articles 84 CoMMuniCations of the aCM | feBRuARy 2014 | voL. 57 | No. 2 security in Debian, we started a proj- ect in 2013 to check all programs in /usr/bin for exploitable bugs and so far have found more than 13,000 with more than 150 exploitable. Advance- ments will continue to be fueled by better tools, techniques, and improve- ments in verification and security. acknowledgments This research is partially supported by grants and support from the Na- tional Science Foundation, the De- fense Advanced Research Projects Agency, Lockheed Martin, Northrop Grumman, and the Prabhu and Poo- nam Goel Fellowship. Any opinions, findings, and conclusions or recom- mendations expressed in this mate- rial are those of the authors and do not necessarily reflect the views of the funding agencies. References 1. avgerinos, t., Cha, S.K., Lim, b.t.h., and brumley, d. aeg: automatic exploit generation. in Proceedings of the Network and Distributed System Security Symposium (San diego, Ca, Feb. 6–9). internet Society, reston, va, 2011, 283–300. 2. batchelder, d., bawany, S., blackbird, J., blakemore, e., Faulhaber, J., Fayyaz, S., Felstead, d., henry, P., goel, n.K., Jones, J., Kuo, J., Lauricella, M., Malcolmson, K., ng, n., oram, M., Peccelj, d., Probert, d., rains, t., Simorjay, F., Stewart, h., thomlinson, M., Wu, S., and Zink, t. Microsoft Security Intelligence Report 12 (July–dec. 2011). Microsoft, redmond, Wa; http:// www.microsoft.com/security/sir/archive/default.aspx 3. bilge, L. and dumitras, t. before we knew it: an empirical study of zero-day attacks in the real world. in Proceedings of the ACM Conference on Computer and Communications Security (raleigh, nC, oct. 16–18). aCM Press, new york, 2012, 833–844. 4. bounimova, e., godefroid, P., and Molnar, d. Billions and Billions of Constraints: Whitebox Fuzz Testing in Production. technical report MSr-tr-2012-55. Microsoft, redmond, Wa, May 2012; http://research. microsoft.com/apps/pubs/?id=165861 5. boyer, r. S., elspas, b., and Levitt, K. n. SeLeCt—a formal system for testing and debugging programs by symbolic execution. in Proceedings of the International Conference on Reliable Software (Los angeles, apr). aCM Press, new york, 1975, 234–245. 6. brumley, d. and Jager, i. Efficient Directionless Weakest Preconditions. technical report CMU- CyLab-10-002. Carnegie Mellon University, Pittsburgh, Pa, July 14, 2010; https://www.cylab.cmu.edu/ research/techreports/2010/tr_cylab10002.html 7. brumley, d., Jager, i., avgerinos, t., and Schwartz, e.J. baP: a binary analysis platform. in Proceedings of the International Conference on Computer Aided Verification (Snowbird, Ut, July 14–20). Springer, berlin, heidelberg, germany, 2011, 463–469. 8. brumley, d., Poosankam, P., Song, d., and Zheng, J. automatic patch-based exploit generation is possible: techniques and implications. in Proceedings of the IEEE Symposium on Security and Privacy (San Francisco, May 18–21). ieee Press, Los alamitos, Ca, 2008, 143–157. 9. Cadar, C., dunbar, d., and engler, d. KLee: Unassisted and automatic generation of high-coverage tests for complex systems programs. in Proceedings of the USENIX Symposium on Operating System Design and Implementation (San diego, Ca, dec. 8–10). USeniX association, berkeley, Ca, 2008, 209–224. 10. Cadar, C., ganesh, v., Pawlowski, P.M., dill, d.L., and engler, d.r. eXe: automatically generating inputs of death. in Proceedings of the ACM Conference on Computer and Communications Security (alexandria, va, oct. 30–nov. 3). aCM Press, new york, 2006, 322–335. 11. Cadar, C. and Sen, K. Symbolic execution for software testing: three decades later. Commun. ACM 56, 2 (Feb 2013), 82–90. 12. Cha, S.K., avgerinos, t., rebert, a., and brumley, d. Unleashing Mayhem on binary code. in Proceedings of the IEEE Symposium on Security and Privacy (San Francisco, May 21–23). ieee Press, Los alamitos, Ca, 2012, 380–394. 13. Chipounov, v., Kuznetsov, v., and Candea, g. the S2e platform. ACM Transactions on Computer Systems 30, 1 (Feb. 2012). 14. Cert/niSt. PHP socket_connect() Stack Buffer Overflow. National Vulnerability Database, entry CVE-2011-1938. national institute of Standards and technology, gaithersburg, Md, May 31, 2011; http://web.nvd.nist.gov/view/vuln/ detail?vulnid=Cve-2011-1938 15. de Moura, L. and bjørner, n. Satisfiability Modulo theories: introduction and applications. Commun. ACM 54, 9 (Sept. 2011), 69–77. 16. Flanagan, C. and Saxe, J.b. avoiding exponential explosion: generating compact verification conditions. in Proceedings of the ACM Symposium on Principles of Programming Languages (London, U.K., Jan. 17–19). aCM Press, new york, 2001, 193–205. 17. ganapathy, v., Seshia, S.a., Jha, S., reps, t.W., and bryant, r.e. automatic discovery of aPi-level exploits. in Proceedings of the International Conference on Software Engineering (St. Louis, Mo, May 15–21). ieee Press, Los alamitos, Ca, 2005, 312–321. 18. godefroid, P. Compositional dynamic test generation. in Proceedings of the ACM Symposium on the Principles of Programming Languages (nice, France, Jan. 17–19). aCM Press, new york, 2007, 47–54. 19. godefroid, P., Klarlund, n., and Sen, K. dart: directed automated random testing. in Proceedings of the ACM Conference on Programming Language Design and Implementation (Chicago, June 12–15). aCM Press, new york, 2005, 213–223. 20. godefroid, P., Levin, M.y., and Molnar, d. Sage: Whitebox fuzzing for security. Commun. ACM 55, 3 (Mar. 2012), 40–44. 21. grenier, L. (Pusscat and Lin0xx). byakugan: automating exploitation. in ToorCon Seattle (Seattle, Wa, May 2007); http://seattle.toorcon.net/ 22. heelan, S. Automatic Generation of Control Flow Hijacking Exploits for Software Vulnerabilities. M.Sc. thesis. University of oxford, oxford, U.K., Sept. 3, 2009; http://solo.bodleian.ox.ac.uk/primo_library/ libweb/action/dldisplay.do?vid=oXvU1&docid=oxfale ph017069721 23. howden, W.e. Methodology for the generation of program test data. IEEE Transactions on Computers C-24, 5 (May 1975), 554–560. 24. Jhala, r. and Majumdar, r. Software model checking. ACM Computing Surveys 41, 4 (oct. 2009). 25. King, J.C. Symbolic execution and program testing. Commun. ACM 19, 7 (July 1976), 385–394. 26. Kuznetsov, v., Kinder, J., bucur, S., and Candea, g. efficient state merging in symbolic execution. in Proceedings of the ACM Conference on Programming Language Design and Implementation (beijing, June 11–16). aCM Press, new york, 2012, 193–204. 27. Manadhata, P.K. and Wing, J.M. an attack surface metric. IEEE Transactions on Software Engineering 37, 3 (May–June). ieee Press, Los alamitos, Ca, 2011, 371–386. 28. Medeiros, J. Automated Exploit Development, The Future of Exploitation Is Here. technical report. grayscale research, 2007; http://www.grayscale- research.org/new/pdfs/toorcon_whitepaper.pdf 29. Muller, t. ASLR Smack & Laugh Reference Seminar on Advanced Exploitation Techniques. technical report. rWth aachen University, aachen, germany, Feb. 2008. 30. Saxena, P., Poosankam, P., McCamant, S., and Song, d. Loop-extended symbolic execution on binary programs. in Proceedings of the International Symposium on Software Testing and Analysis (Chicago, July 19–23). aCM Press, new york, 2009, 225–236. 31. Schwartz, e.J., avgerinos, t., and brumley, d.Q: exploit hardening made easy. in Proceedings of the USENIX Security Symposium (San Francisco, aug. 8–12). USeniX association, berkeley, Ca, 2011, 379–394. 32. Sen, K., Marinov, d., and agha, g. CUte: a Concolic Unit testing engine for C. in Proceedings of the ACM International Symposium on Foundations of Software Engineering (St. Petersburg, russia, aug. 18–26). aCM Press, new york, 2005, 263–272. 33. Shacham, h. the geometry of innocent flesh on the bone: return-into-libc without function calls (on the x86). in Proceedings of the ACM Conference on Computer and Communications Security (alexandria, va, oct. 29–nov. 2). aCM Press, new york, 2007, 552–561. 34. Shacham, h., Page, M., Pfaff, b., goh, e., Modadugu, n., and boneh, d. on the effectiveness of address-space randomization. in Proceedings of the ACM Conference on Computer and Communications Security (Washington, d.C., oct. 25–29). aCM Press, new york, 2004, 298–307. 35. van der veen, v., dutt-Sharma, n., Cavallaro, L., and bos, h. Memory errors: the past, the present, and the future. in Proceedings of the International Symposium on Research in Attacks, Intrusions, and Defenses (amsterdam, the netherlands, Sept. 12–14). Springer, berlin, heidelberg, germany, 2012, 86–106. 36. vanegue, J., heelan, S., and rolles, r. SMt solvers for software security. in Proceedings of the USENIX Workshop on Offensive Technologies (bellevue, Wa, aug. 6–7). USeniX association, berkeley, Ca, 2012. 37. Wang, X., Chen, h., Jia, Z., Zeldovich, n., and Kaashoek, M.F. improving integer security for systems with Kint. in Proceedings of the USENIX Conference on Operating Systems Design and Implementation (hollywood, Ca, oct. 8–10). USeniX association, berkeley, Ca, 2012, 163–177. Thanassis Avgerinos (thanassis@cmu.edu) is a Ph.d. candidate in the electrical and Computer engineering department at Carnegie Mellon University, Pittsburgh, Pa, and a founder of ForallSecure.com. Sang Kil Cha (sangkilc@cmu.edu) is a Ph.d. candidate in the electrical and Computer engineering department at Carnegie Mellon University, Pittsburgh, Pa. Alexandre Rebert (alexandre@cmu.edu) is a Ph.d. student in the electrical and Computer engineering department at Carnegie Mellon University, Pittsburgh, Pa, and a founder of ForallSecure.com. Edward J. Schwartz (edmcman@cmu.edu) is a Ph.d. candidate in the electrical and Computer engineering department at Carnegie Mellon University, Pittsburgh, Pa. Maverick Woo (pooh@cmu.edu) is a systems scientist in CyLab at Carnegie Mellon University, Pittsburgh, Pa. David Brumley (dbrumley@cmu.edu) is an assistant professor in the electrical and Computer engineering department at Carnegie Mellon University, Pittsburgh, Pa, and Ceo of ForallSecure.com. Copyright held by owner/author(s). Publication rights licensed to aCM. $15.00","libVersion":"0.2.1","langs":""}